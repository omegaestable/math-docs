\documentclass[11pt, reqno]{amsart}
\usepackage[utf8]{inputenc}

%\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\usepackage{amscd}        % Package used to produce simple commutative diagrams
\usepackage{float}
\usepackage{amssymb}
\usepackage[english,spanish]{babel}
\usepackage{nomencl}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{cite}
\usepackage{multirow}
 \usepackage{ragged2e}
\usepackage{tikz-cd}
%\setlength\parindent{0pt}

%\geometry{letterpaper}                   % ... or a4paper or a5paper or ...
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{diagbox}\usepackage{comment}
\usepackage{fullpage} 
\usepackage{fancyvrb}
\usepackage{epsfig}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{listings}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{longtable}
\usepackage{epstopdf}
\usepackage{tikz}
\definecolor{mintgreen}{RGB}{152,255,152}
\definecolor{pinksalmon}{RGB}{255,102,102}
\definecolor{hueso}{RGB}{245,245,220}
\definecolor{marfil}{RGB}{255,253,208}
\definecolor{amarillo}{RGB}{255,255,0}
\usetikzlibrary{decorations.markings,arrows}
\setlength{\parindent}{0pt}
%\usetikzlibrary{er}
\usetikzlibrary{decorations.pathreplacing}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\usepackage[inner=1.0in,outer=1.0in,bottom=1.0in, top=1.0in,headheight=3ex,     
  headsep=2ex,]{geometry}
  


\numberwithin{equation}{section}
%\numberwithin{theorem}{section}

\newtheorem{theorem}{Teorema}[section]
%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{proposition}[theorem]{Proposición}
\newtheorem{corollary}[theorem]{Corolario}
\newtheorem{conjecture}[theorem]{Conjetura}
\renewenvironment{proof}{\paragraph{\textbf{Prueba: }}}{\hfill$\blacksquare$}
\theoremstyle{definition}
\newtheorem{remark}[theorem]{Observación}
\newtheorem{definition}[theorem]{Definición}
\newtheorem{example}[theorem]{Ejemplo}


%\newcommand{\cupdot}{\mathbin{\mathaccent\cdot\bigcup}}
%\newcommand{\dotcup}{\ensuremath{\mathaccent\cdot\bigcup}}
\newcommand{\disjoint}{\cdot\!\!\!\!\!\bigcup}

%---------------------------------------
\makeatletter
\def\moverlay{\mathpalette\mov@rlay}
\def\mov@rlay#1#2{\leavevmode\vtop{%
   \baselineskip\z@skip \lineskiplimit-\maxdimen
   \ialign{\hfil$\m@th#1##$\hfil\cr#2\crcr}}}
\newcommand{\charfusion}[3][\mathord]{
    #1{\ifx#1\mathop\vphantom{#2}\fi
        \mathpalette\mov@rlay{#2\cr#3}
      }
    \ifx#1\mathop\expandafter\displaylimits\fi}
\makeatother

\newcommand{\cupdot}{\charfusion[\mathbin]{\cup}{\cdot}}
\newcommand{\bigcupdot}{\charfusion[\mathop]{\bigcup}{\cdot}}

%-------------------------------------
\newcommand{\suchthat}{\;\ifnum\currentgrouptype=16 \middle\fi|\;}
\newcommand{\spec}[1]{\operatorname{Spec}\   #1}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\IL}{\LL^{-1}}
\newcommand{\Gal}[1]{\operatorname{Gal}#1}
\newcommand{\op}[1]{\operatorname{#1}}
\newcommand{\cal}[1]{\mathcal{#1}}
\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\fr}[1]{\mathfrak{#1}}
\newcommand{\Tr}[1]{\operatorname{Tr}#1}
\newcommand{\Nr}[1]{\operatorname{N}#1}
\newcommand{\e}{\varepsilon}
\newcommand{\CM}{\mathcal{CM}}
\renewcommand{\baselinestretch}{1.5}

%\newtheorem{assumption}[theorem]{Assumption}
%\newtheorem{question}[theorem]{claim}



\newcommand{\cd}[4]{
\begin{CD}
#1    @>>>    #2\\
@VVV    @VVV\\
#3    @>>>    #4
\end{CD}
}


\newcommand{\shortmod}{\ensuremath{\negthickspace \negthickspace \negthickspace \pmod}}





\begin{document}

\title{%
Ecuaciones Diferenciales  \\ Notas del curso \\}
                                        
\author{J. Ignacio Padilla Barrientos \\ Universidad de Costa Rica 
}

  

\pagestyle{fancy}

\fancyhead[]{}
\lhead{MA-1005 Ecuaciones Diferenciales}
\rhead{J. Ignacio Padilla Barrientos}
\setlength{\headheight}{15pt}

\address{Escuela de Matem\'atica, Universidad de Costa Rica, San Jos\'e 11501, Costa Rica}

\email{juan.padillabarrientos@ucr.ac.cr}



\maketitle
\section{Introducción: }
¡Bienvenidos/as al curso de ecuaciones diferenciales! A manera de introducción, adjuntaré algunos detalles y observaciones generales del curso. Toda la siguiente información estará detallada a fondo en la carta al estudiante. Nuestro objetivo principal en el curso será el desarrollo de la destreza matemática necesaria para la resolución de ecuaciones diferenciales.\\
 Los requisitos formales del curso son MA-1002 Cálculo II y MA-1004 Álgebra Lineal.

\section{Un breve repaso}
\subsection{Derivadas}
Trabajaremos principalmente con funciones diferenciables $f:\mathbb{R} \to \mathbb{R}$, es decir, funciones de una variable real, cuyas derivadas (primera, segunda, tercera...) existen. El primer concepto fundamental que debemos recordar es:
$$\text{¿Qué es una derivada?}$$
A lo largo de los cursos de matemática, hemos aprendido varias maneras de darle sentido a la derivada de una función. Más específicamente, si $f(x)$ es una función, podemos dar al menos 3 ideas de qué significa la expresión $f'(x)$, la cual también denotamos $\frac{df}{dx}$:
\begin{enumerate}
\item $f'(x) = \lim_{x \to a} \frac{f(x)-f(a)}{x-a}$. Nuestra defición original de derivada es de la forma de un límite. Sin embargo, esta definición no nos da mucho significado geométrico o físico de la función $f$.
\item $f'(x)$ representa la \textbf{pendiente} de la recta tangente a la gráfica de $f$ en el punto $x$. Por ejemplo, sabemos que la recta pendiente a la parábola $f(x) = 1-x^2$, en el punto $x=0$ viene dada por la recta $y=1$, la cual tiene pendiente $0$. Justamente se cumple que $f'(x) = -2x$, por lo que $f'(0) = 0$.
\item $f'(x)$ también nos dice de cierta forma \textbf{a qué velocidad crece $f(x)$} cuando nos movemos de izquierda a derecha en el eje $x$. Por ejemplo: sabemos intuitivamente que la función $f(x)=e^x$ crece más rápido que la función $g(x) = x+2$ , cuando $x>0$. Esto se evidencia calculando $f'(x)=e^x$ y $g'(x)=1$. Como $f'(x)$ es mayor que 1 (siempre y cuando $x>0$), podemos concluir que $f(x)$ crece más rápido que $g(x)$. Nótese que $f$ crece más rápido de $g$, pero esto no implica que $f(x) > g(x)$ para todo $x$, ya que por ejemplo $f(1)= e \approx 2.7$, mientras que $g(1) = 3$.
\end{enumerate}
Debemos tener siempre en mente estos 3 conceptos, especialmente cuando debamos resolver problemas de aplicaciones.

\centering En palabras simples, la derivada de una función $f(x)$ nos dice \textbf{cómo cambia f(x)} cuando $x$ cambia.

\justify
La motivación principal para estudiar las ecuaciones diferenciales, es que no importa si no conocemos el valor de alguna función $f(x)$, nos basta con conocer cómo ella cambia (o sea, conocer su derivada) para poder deducir bastante información. Veamos ésto con un ejemplo:
\vspace{10pt}
\\
\textbf{Ejemplo: Hay 1 bacteria en un jarro. Sabemos que cada minuto, las bacterias que estén en el jarro se duplican. Entonces, ¿Cuántas bacterias habrán en $m$ minutos?}
\vspace{10pt}
\\
En este ejemplo, nos están pidiendo que encontremos la función $f(m)$ que recibe como entrada los minutos que han pasado, y devuelva cuántas bacterias hay dentro del jarro. Solamente tenemos como información el hecho de que cada minuto, sea cual sea la cantidad $f(m)$, el siguiente minuto habrá el doble, es decir:
$$f(m+1) = 2f(m)$$
Sabiendo que al minuto $0$ hay 1 bacteria, no es difícil deducir que la función que describe esta situación es precisamente
$$f(m) = 2^m.$$
\newpage
Hemos podido deducir el valor exacto de $f$ sólo sabiendo cómo ella cambia (aunque no hayamos usado su derivada de manera explícita). Sin embargo, hemos usado una pieza de información adicional, a saber, la \textbf{cantidad inicial} de bacterias. Pensemos qué pasaría si al minuto 0, en vez de 1 bacteria, hubiera 2 bacterias. Entonces la solución al problema sería 
$$f(m) = 2^{m+1}.$$
\\
\textbf{Ejercicio: ¿Cuántas bacterias hay al minuto $m$ si iniciamos con algún número $n$ de bacterias?}
\\
La idea que debemos tener presente es que, en general, los únicos ingredientes que necesitamos para resolver este tipo de problemas (los cuales son en el fondo ecuaciones diferenciales), son:
\begin{itemize}
\item Cómo cambia nuestra función $f$.
\item Dónde inicia nuestra función $f$.
\end{itemize}
Podemos pensarlo incluso así: Si sabemos que un tren sale a una hora en punto, y sabemos su velocidad, podremos calcular fácilmente su posición en cualquier momento.
\\
Durante el curso, será absolutamente necesario el conocimiento de cómo calcular derivadas, y de sus propiedades. A manera de resumen, adjuntaré algunas de las derivadas más comunes, y algunas propiedades importantes. Si usted como estudiante considera que no domina (o no recuerda) algunos de estos temas, recomiendo repasarlos, pues se usarán todos los días.

\begin{table}[h]
\begin{tabular}{|c|c|}

\hline

$f(x)$                & $f'(x)$ \\ \hline
$C$                   &     $0$    \\ \hline
$x$                   &      $1$   \\ \hline
$x^n \quad (n \neq 0) $ &     $nx^{n-1}$    \\ \hline
$e^x$                 &     $e^x$    \\ \hline
$a^x \quad (a \in \mathbb{R})$                       &    $a^x \ln(a)$     \\ \hline
   $\ln(x)$                   &   $\frac{1}{x}$      \\ \hline
           $\log_a(x)$           &   $\frac{1}{x \ln(a)}$       \\ \hline
        $\sen(x)$              &     $\cos(x)$    \\ \hline
        $\cos(x)$             &   $-\sen(x)$      \\ \hline
        $\tan(x)$              &    $\sec^2(x)$     \\ \hline
            $\sqrt{x}$          &     $\frac{1}{2\sqrt{x}}$     \\ \hline
            $\sqrt[n]{x}$          &  $\frac{1}{n\sqrt[n]{x^{n-1}}}$       \\ \hline
            $\sec(x)$          &       $\sec(x)\tan(x)$    \\ \hline
            $\csc(x)$          &     $-\csc(x)\cot(x)$    \\ \hline
            $\cot(x)$          &   $-\csc^2(x)$      \\ \hline
            $\arcsen(x)$          &    $\frac{1}{\sqrt{1-x^2}}$       \\ \hline
            $\arccos(x)$           &   $-\frac{1}{\sqrt{1-x^2}}$      \\ \hline
              $\arctan(x)$         &   $\frac{1}{1+x^2}$      \\ \hline

\end{tabular}
\end{table}
 Sean $f,g$ funciones derivables y $C \in \mathbb{R}$. Entonces se cumple que:
\begin{itemize}
\item \textbf{Linealidad: } $(Cf(x) + g(x))' = Cf'(x) + g'(x)$.
\item \textbf{Regla del producto: } $(f(x)g(x))' = f'(x)g(x) + f(x)g'(x)$.
\item \textbf{Regla de la cadena: } $(f(g(x)))' = f'(g(x))g'(x)$.  
\end{itemize}

\newpage
\subsection{Integrales:} Al igual que el concepto de diferenciación, el de integración nos será de gran utilidad a lo largo del curso. Análogamente, si tenemos una función $f(x)$, podemos resumir el concepto de la integral (o antiderivada) de $f(x)$ de 2 formas:
\begin{itemize}
\item $\int f(x)dx$ es una \textbf{función} cuya derivada es exactamente $f(x)$. A este concepto se le conoce como integral indefinida.
\item $\int_a^b f(x)dx$ es un \textbf{número}, el cual corresponde al área debajo de la gráfica de $f$, comenzando a medir desde $x=a$ y terminando en $x=b$. A este concepto le llamamos integral definida.
\end{itemize}
La integral será la herramienta \string#1 en la resolución de ecuaciones diferenciales. Por lo tanto, es indispensable que manejemos completamente todos los métodos de integración que hemos aprendido desde el primer curso de cálculo.
\\
\textbf{Ejercicio: Repasar todos los métodos de integración.}
\\
Al igual que con las derivadas, daré un brevísimo resumen de algunas integrales indefinidas, junto con las técnicas básicas de integración.

\begin{longtable}{|c|c|}
\hline
$f(x)$                       & $\int f(x)dx$                                                                  \\ \hline
\endfirsthead
%
\endhead
%
$1$                          & $x+C$                                                                    \\ \hline
$A$                          & $Ax+C$                                                                    \\ \hline
$x^n \quad n \neq -1 $       & $\frac{x^{n+1}}{n+1}+ C$                                                    \\ \hline
$\frac{1}{x}$                & $\ln(x) + C$                                                             \\ \hline
$\sin(x)$                    & $-\cos(x)+C$                                                             \\ \hline
$\cos(x)$                    & $\sin(x) + C$                                                            \\ \hline
$\tan(x)$                    & $-\ln(\cos(x))+C$                                                        \\ \hline
$\cot(x)$                    & $\ln(\sin(x)) + C$                                                       \\ \hline
$\sec(x)$                    & $\ln(\sec(x) + \tan(x))+C$  \\ \hline
$\csc(x)$                    & $-\ln(\csc(x) + \cot(x))+C$ \\ \hline
$e^x$                        & $e^x + C$                                                                \\ \hline
$a^x$                        & $\frac{a^x}{\ln(a)} + C$                                                 \\ \hline
$\frac{1}{\sqrt{a^2 - x^2}}$ & $\arcsen(\frac{x}{a}) + C$                                               \\ \hline
$\frac{1}{a^2 + x^2}$        & $\frac{1}{a}\arctan(\frac{x}{a}) + C$                                    \\ \hline
\end{longtable}
\textbf{Linealidad: } Si $f,g$ son funciones integrables, y $C \in \mathbb{R}$ entonces
$$\int Cf(x)+g(x) dx  = C \int f(x)dx + \int g(x)dx.$$
\subsection{Métodos de integración} A continuación se presenta un resumen de los distintos métodos de integración. Una vez más, para el entendimiento del curso, es indispensable que el estudiante \textbf{maneje bien todos los métodos}. Recomiendo resolver cada una de las integrales utilizadas como ejemplo.
\\
\textbf{Cambio de variable: } Funciona cuando tenemos que resolver una integral del tipo
$$\int f(u(t))u'(t)dt.$$
Es decir, cuando dentro de la integral, encontramos una expresión cuya derivada está también dentro de la integral (en este caso $u$). Por ejemplo, para resolver la integral
$$\int  \frac{\ln(t)}{t}dt$$
el cambio $u= \ln(t)$ es de gran ayuda. 
\pagebreak
\\
\textbf{Integración por partes: } Nos ayuda cuando tenemos que integrar un producto de funciones de la forma $u(x)v'(x)$, por medio de la identidad:
$$\int u(x) v'(x) dx = u(x)v(x) - \int v(x) u'(x) dx + C$$
O escrita más simple:
$$\int u dv = uv- \int vdu$$
Al enfrentarnos a una integral por partes, la escogencia correcta de $u$ y $v$ es fundamental. Una buena regla para escogerlos es que $u$ sea fácil de derivar y $v$ sea fácil de integrar. Por ejemplo, para evaluar la integral
$$\int xe^{2x}
dx$$
por partes, es posible tomar $u=x$ y $dv=e^{2x}$.
\\
\textbf{Fracciones parciales:} Este método nos permite evaluar integrales del tipo
$$\int \frac{P(x)}{Q(x)}dx$$
donde $P(x)$ y $Q(x)$ son polinomios. Este método cuenta con muchas variantes, pero los pasos generales son los mismos:
\begin{itemize}
\item \textbf{Paso 0: } Si el grado de $P$ es mayor al grado de $Q$, entonces es necesario efectuar una división de polinomios. En caso contrario, se procede al paso 1.
\item \textbf{Paso 1: } Factorizar $Q(x)$, ya sea usando inspección, completación de cuadrados, o división sintética.
\item \textbf{Paso 2: } Usar la factorización obtenida en el paso 1 para descomponer la fracción a integrar en suma de fracciones más sencillas de integrar, usualmente se tratará de fracciones cuyo denominador es un polinomio de grado 1 o 2. Recuerde que es necesario despejar los numeradores de dichas fracciones, pues aparecen como incógnitas al efectuar la descomposición.
\item \textbf{Paso 3: } Integrar cada fracción por aparte, usando las demás técnicas conocidas.
\end{itemize}
Por ejemplo, para resolver
$$\int \frac{1}{x^2 -16}$$
podemos aplicar la descomposición
$$\frac{1}{x^2 -16} = \frac{1}{(x+4)(x-4)} = \frac{A}{x+4} + \frac{B}{x-4}.$$
O para resolver 
$$\int \frac{1}{x(x^2 + 2x + 5)}$$
podemos utilizar una variante:
$$\frac{1}{x(x^2 + 2x + 5)} = \frac{A}{x} + \frac{Bx+C}{x^2 + 2x + 5}$$
ya que el discriminante del factor cuadrático en el denominador es negativo.
\\
A lo largo del curso nos encontraremos con bastantes integrales de este tipo, por lo que nos será oportuno repasar todas las variantes de este método.
\\
\textbf{Sustitución trigonométrica: } Este tipo de cambio de variable será util principalmente en 3 casos:
\begin{itemize}
\item Para integrales de la forma $\int \sqrt{b^2 - x^2}$, se utiliza el cambio $x=b\sin(\theta)$.
\item Para integrales de la forma $\int \sqrt{b^2 + x^2}$, se utiliza el cambio $x=b\tan(\theta)$.
\item Para integrales de la forma $\int \sqrt{x^2 - b^2}$, se utiliza el cambio $x=b\sec(\theta)$. \\
\end{itemize}
Realizamos este repaso previo a comenzar con el curso, pues la resolución de ecuaciones diferenciales incluye extensamente la resolución de integrales, por lo que es muy importante que no tengamos ningún problema a la hora de integrar funciones, ya que este no es el objetivo del curso. Más adelante retomaremos más métodos de integración, mas considero que estos presentados en esta lección son una buena base para iniciar el curso.

\section{Conceptos Básicos De Ecuaciones Diferenciales}
En esta sección definiremos el concepto de ecuación diferencial, y daremos también algunas definiciones que nos ayudarán a identificar los distintos tipos de ecuaciones diferenciales. La capacidad de identificar correctamente el tipo de ecuación a que enfrentamos es el primer paso en la resolución de la misma. Primero debemos responder la pregunta: $$\textbf{¿Qué es una ecuación diferencial?}$$
Al igual que las ecuaciones clásicas que estudiamos en el colegio, en las ecuaciones diferenciales estaremos intentando despejar o averiguar el valor de una incógnita (o varias). La principal diferencia es que en las ecuaciones clásicas, el valor a despejar, o \textbf{solución}, es un número, mientras que en las ecuaciones diferenciales, se trata de una función. Un ejemplo:
\begin{itemize}
\item \textbf{Ecuación clásica: } $x^2 + 2x + 1 = 0$ tiene como solución $x=-1$, un \textbf{número real}.
\item \textbf{Ecuación diferencial: } Se nos pide encontrar una función $y(x)$ que cumpla la ecuación $y' = y$. Una solución es $y(x) = e^x$, una \textbf{función}.

\end{itemize}
\newpage
Más específiamente,
\\
\textbf{Definición: } Una \textbf{ecuación diferencial} es una ecuación en donde pueden aparecer:
\begin{itemize}
\item Variables independientes, ($x$,$t$, ...)
\item Variables dependientes, las cuales serán las incógnitas a despejar. Usualmente se denotan por $y$, pero debemos recordar siempre que depende de $x$, por lo que en realidad se trata de $y(x)$.
\item Derivada (o derivadas) de la variable dependiente: $y', y'', y'''$, etc.
\end{itemize}
\textbf{Ejemplos:}
\begin{itemize}
\item $y' = e^x$
\item $y' + y'' = \cos(x)$
\item $x^2y'' + xy + 1=0$
\item $ (y')^2 + \cfrac{1}{2 \sen(x)} = \sqrt{xy}$
\item $\cfrac{dy}{dx} + \cfrac{d^2y}{dx^2} = y \cos(x)$.
\end{itemize}
Como mencionamos anteriormente, es convención que $y$ sea función de $x$, aunque podríamos tener ecuaciones donde la variable independiente sea $t$, y la dependiente sea $x$, u otros casos, por ejemplo
\begin{itemize}
\item $x' = t$

\item $\cfrac{dx}{dt} + \cfrac{d^2x}{dt^2} = x \cos(t)$.
\item $z'(v) = z(v) + v^2$
\end{itemize}
son todas ecuaciones diferenciales. Poco a poco iremos estudiando métodos para resolverlas.
\subsection{Clasificación: } El estudio de las ecuaciones diferenciales es muy amplio, y hay muchas maneras de clasificarlas y estudiarlas. Comenzamos con la primera definición:
\\
\textbf{Definición: } Una ecuación diferencial \textbf{ordinaria} (EDO, o ODE en inglés), es aquella donde la solución es una función de \textbf{una variable.} Por ejemplo:
$$y'x = 1$$
Es una ODE con solución $y(x)= \ln(x)$.
\pagebreak
\\
 \textbf{Definición: } Una ecuación diferencial \textbf{parcial} (EDP, o PDE en inglés), es aquella donde la solución es una función de \textbf{varias variables.}.En este caso aparecen también las derivadas parciales de la función a despejar. Por ejemplo:
 $$\frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} = 0$$
 tiene como solución la función de dos variables $f(x,y)=x-y$.
\\
Durante este curso, nos enfocaremos mayoritariamente en el estudio de las EDO's. En las últimas dos semanas daremos algunos métodos para resolver las EDP's más básicas. Por lo tanto, podemos olvidarnos momentáneamente de las ecuaciones en derivadas parciales y trabajar solamente con las EDO's.
\\
Una definición más formal de una ecuación diferencial ordinaria es la siguiente.
\\
\textbf{Definición: }Una EDO es una ecuación de la forma
$$F(x,y,y', \dots, y^{(n)})=0$$
Donde $F:\mathbb{R}^{n+1} \to \mathbb{R}$ es una función.
\\
La definición anterior simplemente resume más concisamente el concepto que tenemos ecuación diferencial: una expresión donde tenemos: variables ($x$), funciones de dichas variables ($y$), y sus respectivas derivadas ($y',y'', \dots$).
\\
A continuación, daremos dos definiciones que nos ayudarán a identificar los distintos tipos de EDO's. En cierto modo, nos servirán para clasificar las ecuaciones por su dificultad.
\\
\textbf{Definición: } El \textbf{orden} de una EDO, es el orden de la mayor derivada que aparece en dicha ecuación.
\\
\textbf{Definición: } El \textbf{grado} de una EDO, es el exponente al cual está elevada la derivada de mayor orden.
\\
No debemos confundir estas definiciones! El orden se trata de cuántas veces hemos derivado la función incógnita, mientras que el grado simplemente es el exponente al cual está elevada la derivada mayor.
\\
\textbf{Ejemplos: }
\begin{itemize}
\item $xy' = yx^2$ tiene orden 1 y grado 1.
\item $(1+y')^3 = x$ tiene orden 1 y grado 3.
\item $(y'')^3 + (y')^7 = 1+ \ln(x)$ tiene orden 2 y grado 3.
\item $y^{(9)} + y^{(8)}+ \dots + y'+y = 0$ tiene orden 9 y grado 1\\
\end{itemize}
NOTA: Cuando nuestra ecuación tiene radicales, es necesario eliminarlos para saber su grado, por ejemplo
$$\sqrt{\frac{dy}{dx}} = y+x$$
Se debe reescribir como 
$$\frac{dy}{dx} = (y+x)^2.$$
En donde deducimos que se trata de una ODE de orden 1 y grado 1.
\\
Algunas ODE se presentan en \textbf{forma diferencial}:
$$M(x,y)dx + N(x,y)dy = 0$$
la cual nos puede resultar poco familiar. Esto es simplemente una reescritura de una ODE común y corriente. Veamos un ejemplo, la ecuación
$$(y-x)dx + 4xdy=0$$
puede transformarse en 
$$\frac{dy}{dx} = \frac{x-y}{4x}$$
por un simple despeje. Notemos nada más que para efectuar este despeje, fue necesario pasar la cantidad $dx$ a dividir. La justificación formal de este hecho no nos preocupará en este curso.
\\
A continuación definiremos el concepto de ecuación lineal, las cuales serán extensamente estudiadas, pues están entre las más sencillas de resolver.
\\
\textbf{Definición: } Una ecuación diferencial ordinaria \textbf{lineal}, es una EDO de la forma
$$a_n(x)y^{(n)} + a_{n-1}(x)y^{(n-1)}+ \dots + a_1(x)y' + a_0(x)y = g(x)$$
donde $g(x) , a_1(x),a_2(x), \dots , a_n(x)$ son funciones que \textbf{solamente dependen de $x$} (pueden incluso ser funciones constantes). Otra manera de identificar si una ecuación diferencial es lineal es la siguiente
\begin{enumerate}
\item La incógnita $y$ y todas sus derivadas aparecen con exponente $1$. Es decir, todas las EDO linealws tienen grado 1.
\item La incógnita $y$ y todas sus derivadas aparecen multiplicadas \textbf{únicamente} por funciones de la variable $x$ (o constantes).
\end{enumerate}
En una EDO lineal, las funciones $a_i(x)$ se llaman \textbf{coeficientes}.
\pagebreak
\\
Ejemplos:
\begin{itemize}
\item $\cos(x) y^{(3)} + e^x y'' - \frac{y'}{x} + y = \tan(x)$ es una EDO lineal de orden 3
\item $y^{(5)} = y$ es une EDO lineal de orden 5. Note que todos los coeficientes son constantes, muchos de los cuales son 0.


\end{itemize}
Notemos que las EDOs lineales tienen un ligero parecido con los polinomios, pues en general, un polinomio tiene la forma
$$p(t) = a_nt^n + a_{n-1}t^{n-1} + \dots + a_1t +a_0$$
Solo que en este caso, los coeficientes son números reales, no funciones, y la variable $t$ representa un número, no una función como en el caso de las EDOs.
\\
\textbf{Tipos de ecuaciones lineales: } Hay dos tipos de EDOs lineales, los cuales son muy fáciles de identificar, mas los métodos de resolución de cada uno son distintos. 
Sea $$a_n(x)y^{(n)} + a_{n-1}(x)y^{(n-1)}+ \dots + a_1(x)y' + a_0(x)y = g(x)$$ una EDO lineal. Si $g(x)=0$, decimos que se trata de una ecuación \textbf{homogénea}, en caso contrario (si $g(x) \neq 0$), sería \textbf{no homogénea}.
\\
\textbf{Ejemplos: }
\begin{itemize}
\item La ecuación $x^4y^{(4)} + y'' + xy = 0$ es lineal, homogénea, de orden 4.
\item La ecuación $y'' + \sin(x) y = x$ es lineal no homogénea, de orden 2.
\end{itemize}
\textbf{Ejercicio: Para cada una de las siguientes EDOs, determine el grado, el orden, y si es lineal, especifique si se trata de una homogénea o no.}

\begin{itemize}
\item $v'(t) + \dfrac{v(t)}{5} = \dfrac{t}{5}$
\vspace{10pt}
\item $\dfrac{dT}{dt} = 9(200-T)$
\vspace{10pt}
\item $\dfrac{dy}{dx} = \dfrac{-x \pm \sqrt{x^2+y^2}}{y}$
\item $y'' - (1-y^2)y' + y = 0$
\item $yy'y''y'''=x$
\item $y^{(50)} = 1$
\end{itemize}
\newpage
\section{Soluciones de una EDO.}
\textbf{Definición: }Sea 
 \begin{equation}\label{eqn:1}
    F\left(x,y,y',\dots,y^{(n)}\right)=0
  \end{equation}
una ecuación diferencial ordinaria. Una \textbf{solución} de \eqref{eqn:1} es una función $f(x)$ que cumple que 
$$F\left(x,f(x),f'(x),\dots,f^{(n)}(x)\right)=0.$$
Esta definición nos puede parecer un poco redundante, pero veámosla más de cerca. Volvamos al ejemplo de ecuaciones clásicas. Si tenemos por ejemplo, que resolver la ecuación
$$t^4 = 81$$
Estamos buscando un número real, el cual al ser sustituido en el lugar de $t$, hace que la igualdad sea verdadera. Es fácil ver que $3$ es solución, puesto que 
$$3^4 = 81.$$
En el caso de EDOs la situación es parecida, veamos un ejemplo. Tenemos la ecuación 
 \begin{equation}\label{eqn:2}
   y'=x \sqrt{y}
  \end{equation}
Se propone como solución $y=\dfrac{x^4}{16}$. Para verificar que nuestra candidata funciona, debemos sustituirla en la ecuación. Note que a diferencia del ejemplo anterior, necesitamos derivar $y$ para poder sustituir, del contrario tendremos un error.
\\
Notemos que 
$$y'=\frac{x^3}{4}$$
Por lo que al sustituir en \eqref{eqn:2} debería cumplirse que 
$$\frac{x^3}{4} \stackrel{?}{=} x \sqrt{\frac{x^4}{16}}$$
lo cual se vuelve evidente después de eliminar la raíz del lado derecho. Es claro entonces que la función $y(x) = \frac{x^4}{16}$ es solución de la ecuación \eqref{eqn:2}.
Veamos otro ejemplo:
 \begin{equation}\label{eqn:3}
   y''-2y'+y=0.
  \end{equation}
Proponemos la solución $y=xe^x$. Para verificar nuestra solución necesitamos derivar 2 veces. Veamos entonces que
\begin{align*}
y'&=e^x(1+x) \\
y''&= e^x(2+x)
\end{align*}
Al sustituir en \eqref{eqn:3}, debemos verificar si 
\begin{alignat*}{2}
&&(2+x)e^x - 2(1+x)e^x + xe^x  &\stackrel{?}{=} 0 \\
\iff&&  2e^x+xe^x-2e^x-2xe^x + xe^x &\stackrel{?}{=}0\\
\iff&& 0 &\stackrel{?}{=} 0 
\end{alignat*}
Lo cual se cumple. Entonces la función $y(x)=xe^x$ es una solución de  \eqref{eqn:3}. Note también que es muy sencillo verificar que la función $y(x) = 0$ también es una solución.
\\
En matemática no sólo es importante encontrar soluciones, es usual preguntarnos ¿Hay más soluciones? ¿Cómo podemos encontrar todas las soluciones a mi problema? El estudio de ecuaciones diferenciales no es excepción: una ecuación diferencial puede tener:
\begin{itemize}
\item Una única solución, como por ejemplo la ecuación $(y')^2 + y^2 = 0$ tiene como solución única $y=0$.
\item Infinitas soluciones, como por ejemplo la ecuación $y'=y$ tiene como soluciones \linebreak $y=e^x, 2e^x, 3e^x, -e^x$ y en general $Ce^x$ donde $C$ es cualquier número real.
\item Cero soluciones, como por ejemplo, la ecuación $(y')^2 = -x^2-1$ no posee soluciones que sean funciones reales.
\end{itemize}
\textbf{Ejercicio: Para cada una de las ecuaciones siguientes, verifique si la función propuesta es solución o no}

\begin{enumerate}
\item  $y(x) = x^2 + C$, para la ecuación $y'=x$
\vspace{8pt}
\item $y(x)=x^2 + Cx$, para la ecuación $x \displaystyle  \left (\frac{dy}{dx} \right) = x^2 + y$.
\vspace{8pt}
\item $y=A\sen(5x) + B\cos(5x)$, para la ecuación $y'' + 25y = 0$
\vspace{8pt}
\item $y(t)=8t^5 + 3t^2 + 5$, para la ecuación $\displaystyle \frac{d^2y}{dt^2} - 6 = 160t^3$.
\end{enumerate}
También podemos hacernos la pregunta inversa, es decir, dada una función $y(x)$, ¿Es posible encontrar alguna EDO para la cual $y(x)$ sea una solución?

\textbf{Ejemplo: }Encuentre una ecuación diferencial cuya solución sea $y= \sen(x)$.
\\
\textbf{Solución: } Como debemos buscar una ecuación diferencial, la idea es calcular las derivadas de nuestra función, y buscar si podemos encontrar alguna relación entre ellas y la función. Observe que $y'= \cos(x)$ y $y''(x)= -\sin(x)$. De esta información vemos que la segunda derivada de $y$ es precisamente $-y$. Es decir, $y$ es solución a la ecuación
$$y''=-y.$$
\\
\textbf{Ejemplo: }Encuentre una ecuación diferencial cuya solución sea $y= e^{2x}$.
\\
\textbf{Solución: } Observe que $y'= 2e^{2x}$ . Vemos de inmediado que una ecuación posible sería 
$$y'=2y.$$
\\
NOTA: este proceso se puede hacer de muchas formas distintas, y pueden haber muchas repuestas correctas, por ejemplo, la ecuación $y'''- 8y = 0$ también tiene como solución $y=e^{2x}$.
\\
\textbf{Ejercicio: Para cada una de las siguientes funciones, encuentre una ecuación diferencial para la cual sean solución.}
\begin{enumerate}
\item $y=C_1e^x + C_2e^{-x}$
\item $y=\tan(4x+c)$
\item $y=(x-C_1)^2 + y^2 + C_2^2 $
\end{enumerate}
\subsection{Tipos de soluciones: }Como hemos mencionado antes, una EDO puede tener cero, una o infinitas soluciones. Vamos a clasificarlas de la siguiente forma:
\begin{itemize}
\item \textbf{Solución general: } Describe simultáneamente una familia de soluciones que solo difieren entre ellas por un parámetro. En otras palabras, la solución general nos da la forma de cada posible solución. Por ejemplo
\begin{itemize}
\item La sencilla ecuación $y'=1$ tiene como solución general $y=x+C$, donde $C \in \mathbb{R}$. Es decir, que cualquier valor que tome $C$, nos genera una solución distinta.
\item La solución general de la ecuación $x''(t) + 16x(t)=0$ es la función \linebreak $x(t) = A \cos(4t) + B \sen(4t)$. En este caso tenemos 2 parámetros, $A$ y $B$.
\end{itemize}
\textbf{Por lo general, el número de parámetros que aparecen en la solución general corresponden con el orden de la ecuación diferencial.}
\item \textbf{Solución particular: } Simplemente se trata de un caso particular de la solución general, en donde le damos valor concreto a los parámetros de la solución (incluso podemos darles el valor $0$). Por ejemplo
\begin{itemize}
\item Una solución particular de $y'=1$ es $y=x+20$.
\item Las funciones $ \cos(4t)$, $5\sen(4t)$ y $ 2\cos(4t)+ 9\sen(4t)$ son todas soluciones particulares de la ecuación $x''(t) + 16x(t)=0$ .
\end{itemize}  \pagebreak
\item \textbf{Solución singular: }Son soluciones que no se pueden obtener a partir de la solución general. Es decir, sin importar qué valor le demos a los parámetros, no podemos producir dicha solución.  Por ejemplo: la EDO $(y')^2= 4y$ tiene como solución general \linebreak $y = (x+C)^2$. Todas las soluciones que vamos a obtener al escoger valores de $C$ serán parábolas. Sin embargo, el estudiante puede corroborar que la función $y = 0$ es también solución de la ecuación, la cual no obedece la forma que dicta la solución general. Se trata de una solución singular.
\textit{No todas las ecuaciones diferenciales tienen soluciones singulares.}
\end{itemize}
Cuando una solución (ya sea general, particular, o singular) se puede expresar \textbf{únicamente en términos de la variable dependiente}, decimos que se trata de una solución \textbf{explícita}. Caso contrario, cuando no podemos despejar el criterio de nuestra solución, decimos que se trata de una solución \textbf{implícita.}
\\
\textbf{Ejemplos: }
\begin{itemize}
\item Una solución particular explícita de la ecuación $xy' + y = 0$ sería $y(x) = 1/x$. Note que podemos expresar el criterio de $y$ explícitamente en función de $x$.
\item Considere la ecuación $\dfrac{dy}{dx} = -\dfrac{x}{y}$. Veamos que una solución en forma implícita viene dada por $x^2 + y^2 = 25$ (expresión en la cual no es posible despejar $y$, puesto que tendríamos dos posibilidades de despeje $y = \pm \sqrt{25-x^2}$). Para verificar que nuestra curva es en efecto una solución, debemos recurrir a la \textbf{derivación implícita}. Observe que
\begin{alignat*}{2}
&& x^2 + y^2 &= 25 \\
\Rightarrow&& 2x + 2yy' &= 0\\
\Rightarrow&& y' = -\frac{2x}{2y} &= -\frac{x}{y}
\end{alignat*}
\end{itemize}
Otra manera de definir una solución a una EDO es por trozos. Por ejemplo, considere la ecuación 
$$xy'-4y = 0$$
cuya solución general es $y=cx^4$. Podemos entonces definir la solución
$$y(x) = \begin{cases} x^4 \text{    \quad si $x>0$} \\ -x^4 \text{ \ si $x \leq 0$}
\end{cases}$$
al escoger $c=1$ en el eje positivo y $c=-1$ en el eje negativo.
\begin{figure}[h]
 \center
        \includegraphics[scale=0.50]{Recorte1.png}
\end{figure}

\section{Problemas de valor inicial}
Suponga que se desea resolver la ecuación
$$y' = y.$$
La solución general de esta ecuación es $y(x)=Ce^x$. Aquí estamos en realidad hablando de infinitas soluciones, una para cada valor de $C$. Ahora, podemos plantearnos la siguiente pregunta: ¿Cuál de todas esas soluciones cumple que $y(0) = 5$? Si sabemos que la solución debe tener la forma $Ce^x$, solamente necesitamos verificar si $Ce^0 = 5$. Por lo tanto, obtenemos que cuando $C=5$, la solución particular $y=5e^x$ resuelve nuestro problema.
\\
Este tipo de problemas se conocen como \textbf{problemas de valor inicial} (o problemas de Cauchy). Los problemas de valor inicial son frecuentemente aplicados en el modelaje de fenómenos de la vida real, pues tienen una solución específica, no una familia de infinitas soluciones. Aquí es donde retomamos lo que se mencionó en la sección 2: una ecuación diferencial puede tener muchas soluciones, pero una vez que especificamos su valor inicial, obtenemos una solución concreta, en vez de una familia infinita. Se presenta la definición formal de esta situación.
\\
\textbf{Definición: } Un problema de valores iniciales es sistema del tipo
\begin{align*}
\begin{cases}
F(x,y,y',\dots,y^{(n)})&=0 \\
y(x_0)&=y_0 \\
y'(x_1)&=y_1 \\
y''(x_2)&=y_2 \\
&\vdots \\
y^{(n-1)}(x_{n-1})&=y_{n-1}
\end{cases}
\end{align*}
donde $x_0,x_1,\dots,x_{n-1},y_0,y_1,\dots,y_{n-1}$ son números reales. Cuando todas las $x_i's$ son iguales, le llamamos un \textbf{problema de Cauchy}.
\\
En su forma general, un problema de valores iniciales, además de incluir una ecuación diferencial, incluye información acerca de todas las derivadas de la función. Esta información nos ayudará a darle valores concretos a cada parámetro en la solución general. Vamos a explicar esto con varios ejemplos:
\\
\textbf{Ejemplo: }Considere el problema

\begin{align*}
\begin{cases}
y' + y &= x \\
y(0)&=1\\
\end{cases}
\end{align*}
La solución general de la ecuación es $y(x) = Ce^{-x} +x - 1$. Ahora, para asegurarnos que $y(0)=1$ debemos escoger un valor apropiado para el parámetro $C$. Necesitamos que 
\begin{alignat*}{2}
&&Ce^0 + 0 -1 &= 1 \\
\Rightarrow && C-1&=1 \\
\Rightarrow && C&=2
\end{alignat*}
Por lo tanto, la solución de nuestro problema de valor inicial es $y(x) = 2e^{-x} +x- 1$.
\\
\textbf{Ejemplo: }Considere el problema

\begin{align*}
\begin{cases}
y'' + 2y' + y &= 0 \\
y(0)&=1 \\
y'(0) &= 0\\
\end{cases}
\end{align*}
La solución general de la ecuación es $y(x) = C_1e^{-x} +C_2xe^{-x}$, tiene 2 parámetros pues se trata de una ecuación de orden 2. Ahora, para asegurarnos que $y(0)=1$ y $y'(0)=0$ debemos despejar ambos parámetros. Primero, como $y(0)=1$, eso implica que
\begin{alignat*}{2}
&&C_1e^0 + C_2 0 e^0 &= 1 \\
\Rightarrow&& C_1 &=1
\end{alignat*}
Ahora, calculamos $y'(x) = -e^{-x} + C_2e^{-x}(1-x)$ (donde ya usamos que $C_1=1$). Ahora, como $y'(0)=0$, eso implica que
\begin{alignat*}{2}
&&-e^0 + C_2e^0(1-0) &= 0 \\
\Rightarrow&& -1+C_2 &=0 \\
\Rightarrow&& C_2 &=1 \\
\end{alignat*}
Entonces finalmente, la solución a nuestro problema es 
$y(x)=e^{-x} + xe^{-x}.$
Note que este último problema es de Cauchy, pues tanto $y$ como $y'$ aparecen evaluadas en $x=0$ en las condiciones iniciales.
\\
\textbf{Ejemplo: }Considere el problema

\begin{align*}
\begin{cases}
y''  + 9y &= 0 \\
y\left(\frac{\pi}{12}\right)&=0 \\
y'\left(\frac{\pi}{9}\right)&=1\\
\end{cases}
\end{align*}
La solución general es $y= A \sen(3x) + B \cos(3x)$, una vez más tenemos 2 parámetros. Calculemos de una vez $y'(x) = 3A\cos(3x) - 3B \sen(3x)$. Note que este problema es de valor inicial, pero no de Cauchy, pues las condiciones iniciales están evaluadas en puntos distintos ($\pi/12$ y $\pi/9$). Primero, como $y\left(\frac{\pi}{12}\right)=0$, obtenemos que
$$A\sen\left(\frac{3\pi}{12}\right) + B\cos\left(\frac{3\pi}{12}\right) = A \frac{\sqrt{2}}{2}+B \frac{\sqrt{2}}{2}=0$$
mientras que con la otra condición $y'\left(\frac{\pi}{9}\right)=1$ obtenemos que
$$3A\cos\left(\frac{3\pi}{9}\right) - 3B\sen\left(\frac{3\pi}{9}\right) = A \frac{3}{2}-B \frac{3\sqrt{3}}{2}=1$$
Para despejar $A$ y $B$, debemos entonces resolver un sistema de ecuaciones:
$$\begin{cases}
A \frac{\sqrt{2}}{2}+B \frac{\sqrt{2}}{2}=0 \\
A \frac{3}{2}-B \frac{3\sqrt{3}}{2}=1
\end{cases}$$
el cual no debería representar ningunda dificultad para el estudiante. La solución es
$$A= \frac{2}{3+3\sqrt{3}} \quad ; \quad B= -\frac{2}{3+3\sqrt{3}}$$
por lo que la solución al problema es
$$y(x) = \frac{2}{3+3\sqrt{3}}( \sen(3x) - \cos(3x)).$$
\\
\textbf{Ejercicio: Se presentan varios problemas de valor inicial, son sus respectivas soluciones generales. Encuentre el valor de los parámetros en cada caso, para resolver el problema.}
\begin{enumerate}
\item $\begin{cases}y'-2y = 3x  \\ y(0)=1
\end{cases}$, con solución general $y=Ce^{2x} - \dfrac{3x}{2} + \dfrac{3}{4}$.
\item $\begin{cases}y'' - 6y' + 5y = 0  \\ y(0)=1 \\ y'(0)=0
\end{cases}$, con solución general $y=C_1e^x + C_2e^{5x}$.

\item $\begin{cases}y'' +25y = 0  \\ y\left(\frac{\pi}{15}\right)=1 \\ y'\left(\frac{\pi}{20}\right)=0
\end{cases}$, con solución general $y= A\sin(5x) + B\cos(5x)$.

\item $\begin{cases}y'''=8  \\ y(0)=1 \\ y'(1)=0 \\ y''(0)=0
\end{cases}$, con solución general $y=\dfrac{4x^3}{3} + Ax^2 + Bx + C$.\\
\end{enumerate}

Concluimos esta sección con un importante teorema, el cual nos asegura cuándo un problema de valor inicial tiene solución única.
\\
\textbf{Teorema de existencia y unicidad: } Sea
$$\begin{cases}
y'=F(x,y) \\
y(x_0)=y_0
\end{cases}$$
un problema de Cauchy. Si la función $F$ y todas sus derivadas parciales son continuas, entonces existe una única solución para dicho problema.
\\
Este teorema es muy sencillo de aplicar:
\\
\textbf{Ejemplo: }Para el problema
$$\begin{cases}
y'= y+x \sen(y) \\
y(x_0)=y_0
\end{cases}$$
Se tiene que $F(x,y)=y+x\sen(y)$, la cual es claramente una función continua. Veamos además que
$$\frac{\partial F}{\partial x} = \sen(y)$$
y además 
$$\frac{\partial F}{\partial y} = 1+x\cos(y).$$
Ambas derivadas parciales de $F$ son continuas, por lo que, aunque no sepamos resolver el sistema, podemos asegurar gracias al teorema que hay una única solución.
\section{Campos direccionales e isoclinas}
Nuestra última sección antes de iniciar de lleno con métodos de resolución corresponde con una interpretación más geométrica de las ecuaciones diferenciales. Considere por ejemplo la ecuación diferencial
$$f'(x)=f(x)$$
 Geométricamente, la ecuación anterior nos dice que para todo punto $x$, la pendiente de la recta tangente a la curva de $f(x)$ es precisamente $f(x)$. Es decir, no es necesario resolver la ecuación para tener una idea de cómo es su gráfica. Desafortunadamente, como no tenemos condiciones iniciales, no vamos a obtener una sola curva, sino que muchas. Al graficar sobre una parte del plano obtenemos lo siguiente:
 
 \begin{figure}[h]
 \center
        \includegraphics[scale=0.60]{Recorte2.png}
\end{figure}
Visualmente, estas curvas coinciden con la solución general de la ecuación: $f(x) = Ce^x$, una familia de funciones exponenciales. Si bien al principio del problema no teníamos la solución, al trazar muchos segmentos tangentes, podemos darnos una idea de cómo es la curva solución, esta es la idea principal detrás del concepto de campos direccionales.\pagebreak \\
\textbf{Definición: }Sea 
$$
y'=F(x,y) \\
$$
una ecuación diferencial. Un \textbf{campo direccional} (o campo de pendientes)  es una familia de rectas tangentes, cada una pasando por cada punto $(a,b)$ del dominio de $F(x,y)$, o sea, son \textbf{todas las posibles rectas tangentes de todas las soluciones} particulares. Una \textbf{isoclina} es una curva de la forma $F(x,y)=C$, donde $C$ es una constante.
\\
Geométricamente, para obtener una isoclina de una ecuación, tomamos primero una constante $C$ cualquiera, y en el campo direccional, buscamos todos los puntos sobre los cuales la pendiente es precisamente $C$. La colección de estos puntos es una isoclina de la ecuación. Evidentemente, hay infinitas isoclinas (una para cada $C$).
\\
\textbf{Ejemplo: } Considere la ecuación diferencial
$$y' = -\frac{x}{y}$$
Para calcular su campo direccional, simplemente tomamos muchos puntos del plano $(x_0 , y_0)$ y calculamos la pendiente que tendría la curva tangente a la solución que pasa por dicho punto $(x_0,y_0)$ mediante la fórmula $-x_0 / y_0 $. Entre más puntos calculemos, tendremos mejor resolución del campo. Se adjunta una tabla con algunos valores:

\begin{table}[h]
\begin{tabular}{|c|c|c|}
\hline
\textbf{$x_0$} & \textbf{$y_0$} & \textbf{pendiente $= -\frac{x_0}{y_0}$} \\ \hline
1              & 1              & -1                                      \\ \hline
-1             & 1              & 1                                       \\ \hline
1              & -1             & 1                                       \\ \hline
-1             & -1             & -1                                      \\ \hline
0              & 1              & 0 (horizontal)                          \\ \hline
1              & 0              & $\infty$ (vertical)                     \\ \hline
\end{tabular}
\end{table}

Con la ayuda de la computadora, graficamos el campo direccional de dicha ecuación (imagen en la siguiente página). Además, resaltamos los puntos calculados en la tabla, donde vemos (aproximadamente) que las pendientes coinciden con lo calculado.

 \begin{figure}[h]
 \center
        \includegraphics[scale=0.60]{Recorte3.png}
        
        Campo direccional para $yy'=-x$ 
\end{figure}

Vemos además que, sin haber resuelto la ecuación, las gráficas de las soluciones parecen ser círculos! En efecto, como se vio en un ejemplo anterior, la solución general de esta ecuación viene dada de manera implícita por la ecuación
$$x^2 + y^2 = K.$$
Al cambiar el valor de K, se obtienen soluciones distintas (círculos distintos), justo como se ve en la imagen. 
\\
Ahora, recordemos que las isoclinas de una ecuación vienen dadas por la familia $F(x,y)=C$. Para este caso específico, la familia de isoclinas es 
$$-\frac{x}{y}=C.$$
 O sea que la familia de isoclinas son todas las rectas que pasan por el origen. 
\\
De manera geométrica, volviendo a la imagen, podríamos preguntarnos ¿En el campo direccional, cuáles puntos tienen pendiente \textbf{horizontal} (o sea, pendiente $C=0$)? Gracias a la imagen, es fácil observar que solo aquellos puntos que están en el eje $y$ cumplen esto. Equivalentemente, dada nuestra familia de isoclinas, buscamos aquellos puntos cuya pendiente es $C=0$, o sea que cumplan la ecuación
$$-\frac{x}{y}= 0.$$
Por lo que $x=0$ (el eje $y$) son todos los puntos que estamos buscando. De igual manera, si ahora $C=1$, la isoclina de puntos con pendiente $1$ es precisamente la recta $y=-x$. En la siguiente imagen se grafica la familia de isoclinas de la ecuación diferencial, junto con su campo de direcciones.\\
 \begin{figure}[h]
 \center
        \includegraphics[scale=0.55]{Recorte4.png}
        
        Isoclinas y  campo direccional para $yy'=-x$ 
\end{figure}
 \textbf{Nota: } Las isoclinas NO son soluciones de la ecuación diferencial.
\pagebreak
\\
\textbf{Ejemplo: } La ecuación
$$y' = e^{-x^2}$$
no se puede resolver en términos de funciones elementales (aunque sí tiene solución, a saber \linebreak $y(x) = \int_0^x e^{-t^2}dt$). Sin embargo, usando el campo direccional, podemos darnos una idea visual de cómo se ve su solución general.

\begin{table}[h]
\begin{tabular}{|c|c|c|}
\hline
\textbf{$x_0$} & \textbf{$y_0$} & \textbf{pendiente $= e^{-x_0^2}$} \\ \hline
-1              & 0              & $e^{-1} \approx 0.368$ \\ \hline
0             & 0              & 1                                      \\ \hline
1              &  0            & $e^{-1} \approx 0.368$                                       \\ \hline
0             & 1             & 1                                      \\ \hline
0             & -1             & 1                                      \\ \hline
\end{tabular}
\end{table} 


Además, la familia de isoclinas viene dada por $e^{-x^2}=C$, de la cual despejando se obtiene que 
$$x=\sqrt{-\ln{C}}.$$
Es decir que todas las isoclinas son rectas verticales. En la imagen podemos ver una ilustración de la situación: \pagebreak \\

 \begin{figure}
 \center
        \includegraphics[scale=0.55]{Recorte5.png}
        
        Isoclinas y  campo direccional para $y'=e^{-x^2}$ 
\end{figure}
En esta imagen es muy fácil ver que sobre las isoclinas, todos los pequeños segmentos de recta que pasan tienen la \textbf{misma inclinación}. De ahí su nombre.
\\
\textbf{Definición: } Una \textbf{curva integral} (o curva solución) simplemente es la gráfica de una solución particular de una ecuación diferencial.
\\
\textbf{Ejemplo: } Consideremos la ecuación diferencial 
$$yy' = \cos(x)$$
cuya solución viene dada implícitamente por $y^2 = 2(C+\sen(x)).$ En la siguiente imagen mostramos el campo diferencial, junto con aquellas curvas integrales que se obtienen al escoger $C=0,1,2$ de la solución general (verde, roja y amarilla, respectivamente).

 \begin{figure}[h]
 \center
        \includegraphics[scale=0.50]{Recorte6.png}
        
        Isoclinas y  campo direccional para $yy'=\cos(x)$ 
\end{figure}

Note que en este ejemplo, si bien los segmentos del campo diferencial no coinciden perfectamente con cada solución, nos dan una buena idea aproximada de cómo se ven.
\\
En resumen, podemos decir que el \textbf{campo direccional} es una idea de cómo se ven todas las soluciones de una dada ecuación diferencial (se visualiza como un conjunto de segmentos de recta, que dan una idea de cada una de las soluciones). Las \textbf{isoclinas} son curvas cuyos puntos tienen asignada la misma pendiente. Finalmente, las \textbf{curvas integrales}, son las gráficas de las soluciones particulares a la ecuación.
\justify
Ahora que tenemos todos los conceptos básicos de EDOs, podemos presentar los distintos métodos de resolución de ecuaciones diferenciales. Es decir, vamos a responder la pregunta:

\center{\textbf{Dada una ecuación diferencial, ¿Cómo podemos hallar su solución general?}}

\section{Método de separación de variables}



\justify
El primer método se conoce como separación de variables, y nos va a permitir resolver cualquier ecuación de la forma
$$f(x)dx = g(y)dy.$$
Es decir que, si por medio de manipulaciones algebraicas (tratando los diferenciales $dx$ y $dy$ como variables), logramos que de un lado de la ecuación solo aparezca $x$ y del otro lado solo aparezca $y$, este método funcionará. Una vez se logre alcanzar esta forma, simplemente se integra a ambos lados:
$$\int f(x)dx  = \int g(y)dy.$$
\textbf{Ejemplo: } Para resolver la ecuación
$$\frac{dy}{dx} = \frac{x^2}{y(1+x^3)}$$
Podemos despejar fácilmente para obtener
$$ydy = \frac{x^2}{1+x^3}dx.$$
Por lo que solo tenemos que integrar a ambos lados para obtener
$$\int y dy = \int \frac{x^2}{1+x^3}dx$$
\pagebreak
\\
Esta integral se puede resolver mediante el cambio de variable $u=(1+x^3)$. Finalmente, la solución general se obtiene de manera implícita:
$$\frac{y^2}{2} = \frac{\ln(1+x^3)}{3} + C$$
Donde $C \in \mathbb{R}$ es un parámetro.
\\
\textbf{NOTA: }En sentido estricto, se deberían obtener $2$ constantes de integración, una a cada lado de la igualdad, obteniendo la solución general
$$\frac{y^2}{2} = \frac{\ln(1+x^3)}{3} + C_1 - C_2$$
Sin embargo, como tanto $C_1$ y $C_2$ son números reales cualesquiera, la cantidad $C_1- C_2$ también será un número real cualquiera, por lo que la resumimos simplemente como un nuevo parámetro $C$. Abusaremos mucho de este hecho a lo largo de la resolución de EDOs y problemas de valor inicial.
\\
\textbf{Ejemplo: }También podemos resolver problemas de valor inicial:
$$xdx + ye^{-x}dy = 0 \quad , \quad y(0)=1.$$
Primero debemos encontrar la solución general, para poder despejar el parámetro. Separando las variables obtenemos
$$ydy = -xe^xdx$$
e integrando en ambos lados se obtiene la solución (implícita)
$$\frac{y^2}{2} = e^x (1-x) + C$$
o equivalentemente
$$y^2 = 2e^x(1-x) + C $$
donde volvemos a hacer el abuso ``$2C = C$''. Ahora solo nos falta resolver usando la condición inicial. Como $y(0)=1$, necesitamos que 
$$1= 2e^0 (1-0)+C$$
de lo cual se deduce que $C=-1$. La solución del problema es entonces
$$y^2 = 2e^x(1-x) -1$$

\pagebreak 
\textbf{Ejercicio: }Encuentre la solución general de las siguientes EDOs
\begin{itemize}
\item $e^x y' = 2x$
\vspace{10pt}
\item $dy + 2xydx = 0$
\vspace{10pt}
\item $\dfrac{dQ}{dt}=300(Q-70)$
\vspace{10pt}
\item$\dfrac{1+x^2 }{\sqrt{1-y^2}}dy=\dfrac{dx}{\arcsen(y)}$

\vspace{10pt}
\item $y'+y\tan(x) = 0$

\vspace{10pt}
\item $\sec^2xdy + \csc ydx = 0$

\end{itemize}



\textbf{Resumen: }Este método se reduce simplemente a ``separar"  las variables en cada lado de la ecuación, con sus respectivos $dx$ y $dy$, y luego integrar a ambos lados. La mayor dificultad que se puede presentar es una integral complicada al final, por eso debemos dominar los métodos de integración.

\section{Cambios de Variable}
Al igual que cuando estudiamos métodos de integración, en la resolución de ecuaciones diferenciales, un buen cambio de variable puede hacer que un problema que pareciera imposible se vuelva más sencillo. Los cambios de variable se deben hacer siempre respetando la regla de la cadena. Veamos un ejemplo
\\
\textbf{Ejemplo: }La ecuación $$\frac{dy}{dx}=\frac{1}{x+y}$$
no es separable. Considere ahora el cambio de variables $z=x+y$. Derivando (justo como se haría en el cambio de variable de una integral)
$$dz=dx+dy \Rightarrow \frac{dy}{dx} = \frac{dz}{dx}-1$$
lo cual quiere decir, que en este caso en particular, podemos reescribir la ecuación únicamente en términos de $x$ y $z(x)$:
$$\frac{dz}{dx}-1 = \frac{1}{z}$$
la cual sí es separable. Al separar sus variables se obtiene que
$$\frac{z}{1+z}dz = dx.$$
Integrando a ambos lados obtenemos la solución implícta pero en términos de $z(x)$.
$$z- \ln(1+z) = x + C$$
por lo que solo falta deshacer el cambio de variable
$$x+y - \ln(1+x+y) = x+C.$$
La solución general viene dada de forma implícita:
$$y-\ln(1+x+y) = C.$$
\\
\textbf{Ejemplo: } A veces es necesario realizar más de un cambio de variable. Considere la ecuación
$$xy'=y\cos(xy)$$
la cual reescribimos como 
$$xdy = y \cos(xy)dx.$$
Comencemos primero tomando $x=e^t$ (esto cambiará la variable independiente, ahora será $t$). Tenemos entonces que $dx = e^t dt$ por lo que al sustituir en la ecuación obtenemos que
$$e^tdy = y\cos(ye^t)e^tdt $$
la cual se simplifica a 
$$dy = y\cos(ye^t)dt.$$
Esta ecuación aún no es separable, por lo que ahora consideramos el cambio de variable $u = ye^t$. Derivando (usando la regla del producto) se tiene que 
\begin{alignat*}{2}
 &&du &= e^t dy + ye^tdt \\
 && &= e^tdy + udt \\
 \Rightarrow&& dy &= (du-udt)e^{-t}.
\end{alignat*}
Por lo que nuestra ecuación puede expresarse en términos de $u(t)$ y $t$
$$(du-udt)e^{-t} = ue^{-t}\cos(u)dt$$
la cual sí es separable. No nos interesa por ahora el resto de la resolución, pues la integral que resulta al final no se puede expresar elementalmente. \pagebreak
\\
Cuando hacemos cambios de variable siempre debemos mantenernos atentos a si nuestras variables son dependientes o independientes. Recodemos que como trabajamos con ecuaciones \textbf{ordinarias}, solo podemos tener en todo momento \textbf{una} variable independiente, y \textbf{una} independiente (y sus derivadas).
\\
\textbf{NOTA: } El cambio de variable del ejemplo anterior de hecho funciona para cualquier ecuación de la forma $$xy'=yf(xy)$$
\subsection{Sustitución lineal: }Este cambio de variables lo utilizamos para resolver ecuaciones de la forma
$$y'=f(ax+by+c)$$
El cambio de variable a usar es $z=ax+by+c$, del cual se deduce que $dz=adx+bdy$. 
\\
\textbf{Ejemplo: }
$$y' = \tan(x+y+3).$$
Tomemos $z=x+y+3$, lo cual implica que $dz=dx+dy$. Entonces, recordando que nuestra ecuación se puede ver como $dy =\tan(x+y+3)dx$, al sustituir obtenemos
\begin{alignat*}{2}
&&(dz-dx)=\tan(z)&dx \\
\Rightarrow&& dz = (1+\tan(z))&dx
\end{alignat*}
Por lo tanto, nuestro último obstáculo para resolver esta ecuación, es resolver la integral
$$\int \frac{dz}{1+\tan(z)}.$$
Recomiendo el cambio de variable 
$u=\tan(z)$, seguido de una descomposición en fracciones parciales. La solución general de la ecuación es
$$    \ln(\tan(x+y+3) +1) + y + \ln(\cos (x+y+3)) = x + C$$
\newpage
 \subsection{Ecuaciones que contienen funciones homogéneas.}
 \justify
 Antes de proceder con este método, vamos a definir el concepto de \textbf{función homogénea}. Esto NO se debe confundir con el concepto de EDO lineal homogénea, pues son completamente distintos.
 \\
 \textbf{Definición: }Sea $f:\mathbb{R}^2 \to \mathbb{R}$ una función de $2$ variables. Diremos que $f(x,y)$ es \textbf{homogénea de grado $k$} si para todo $t \in \mathbb{R}$ se cumple que 
 $$f(tx,ty)=t^k f(x,y).$$
 \textbf{Ejemplos: }
 \begin{itemize}
 \item La función $f(x,y) = x^2 + y^2$ es homogénea de grado $2$, puesto que si $t \in \mathbb{R}$, se tiene que
 $$f(tx,ty)=(tx)^2 + (ty)^2 = t^2x^2 + t^2y^2 = t^2(x^2+y^2) = t^2f(x,y)$$
 \item La función $f(x,y) = \dfrac{x^3 + y^3}{x^3 - y^3}$ es homogénea de grado 0, puesto que si $t \in \mathbb{R} \setminus \{0\}$, se tiene que
 $$f(tx,ty)=\frac{(tx)^3 + (ty)^3}{(tx)^3 - (ty)^3} = \frac{t^3 (x^3 + y^3)}{t^3(x^3 - y^3)} = \frac{x^3 + y^3}{x^3 - y^3} = t^0f(x,y)$$
 \item La función $f(x,y) = x^4y^4$ es homogénea de grado $8$, puesto que si $t \in \mathbb{R}$, se tiene que
 $$f(tx,ty)=(tx)^4(ty)^4 = t^8 (xy)^4 = t^8 f(x,y)$$

 \item La función $f(x,y)= \cos(x+y)$ no es homogénea, pues no hay ningún número $k$ tal que
 $$\cos(t(x+y)) \neq t^k \cos(x+y)$$
  \end{itemize}
  \textbf{Ejercicio: }Verifique si la función
   $g(x,y)= \dfrac{1}{\sqrt{x+y}}$ es homogénea. Encuentre su grado.
\\
En esta subsección veremos el método de resolución para ecuaciones que tengan la forma
 \begin{equation}\label{eqn:4}
    y'=f(x,y)
  \end{equation}
donde $f$ es una función homogénea \textbf{de grado 0}. O equivalentemente, ecuaciones de la forma
$$M(x,y)dx + N(x,y)dy = 0$$
donde $M(x,y)$ y $N(x,y)$ son funciones homogéneas \textbf{del mismo grado}.
\\
La sustitución que usaremos para resolver \eqref{eqn:4}, cuando $f(x,y)$ es homogénea de grado 0 será
$$u= \frac{y}{x}$$
o equivalentemente $y=ux$, por lo que
$$dy = udx + xdu.$$
Esto convierte a nuestra ecuación en
$$udx+xdu = f(x,ux)dx$$
que por homogeneidad se vuelve
$$udx+xdu = f(1,u)dx$$
una ecuación separable.
\\
\textbf{Ejemplo: }Resuelva la ecuación
$$y' = \frac{x^2 + 3y^2}{2xy}.$$
Observe que el lado derecho de la ecuación es una función homogénea de grado 0. Por lo tanto tomando $y=ux$ y $dy = udx + xdu$ obtenemos
\begin{alignat*}{2}
&& xdu + udx &= \frac{x^2 + 3(ux)^2 }{2x (ux)}dx \\
&& &=\frac{1+3u^2}{2u}dx
\end{alignat*}
la cual, después de separar variables, se convierte en 
\begin{alignat*}{2}
&& xdu &=  \left(  \frac{1+3u^2}{2u} - u\right)dx \\
\Rightarrow && xdu &= \left( \frac{1+u^2}{2u} \right)dx \\
\Rightarrow&& \frac{2u}{1+u^2} &= \frac{dx}{x}
\end{alignat*}
Al integrar a ambos lados, obtenemos que
$$\ln(1+u^2) = \ln(x) + C.$$
Al deshacer el cambio de variable, obtenemos la solución general
$$\ln\left(1+\frac{y^2}{x^2}\right) = \ln(x) +C$$
la cual se puede simplificar aplicando la función exponencial a ambos lados (y usando el abuso ``$e^C=C$")
$$1+\frac{y^2}{x^2} = Cx \quad , C>0$$ \pagebreak \\
\textbf{Ejemplo: }Considere la ecuación diferencial
$$xdy -(\sqrt{y^2-x^2}+y)dx = 0.$$
Estamos ante una ecuación de la forma
$M(x,y)dx+N(x,y)dy=0$. Es fácil verificar que tanto $M(x,y)$ como $N(x,y)$ son funciones homogéneas del mismo grado (1). Aplicando el cambio de variable $xu=y$, obtenemos
$$x(udx+xdu) - (\sqrt{x^2u^2-x^2}+ux)dx=0$$
lo cual, al dividir todo por $x$ se vuelve
$$udx + xdu - (u+\sqrt{u^2-1})dx= 0$$
la cual es una ecuación separable. Después de reducir términos semejantes y separar las variables, se obtiene
$$\frac{du}{\sqrt{u^2-1}}= \frac{dx}{x}.$$
Al integrar a ambos lados, obtenemos la solución
$$\ln(\sqrt{u^2-1}+u) = \ln(x) + C.$$
Finalmente, al deshacer el cambio de variable y exponenciar a ambos lados, obtenemos la solución general.
$$\sqrt{\frac{y^2}{x^2}-1} + \frac{y}{x} = Cx \quad , C>0.$$
Como ejercicio, se recomienda completar los detalles en este ejemplo, incluyendo la integral.
\\
\textbf{Ejercicio: }Resuelva los siguientes problemas de valor inicial.

\begin{itemize}
\item $y'= \dfrac{y(2xy + 1)}{x(xy-1)}$, con la condición $y(1)=1$. Utilice el cambio $z=xy$.
\vspace{10pt}

\item $y'=\sen(-x+y-2\pi)$, con la condición $y(0)=0$


\vspace{10pt}
\item $(x+y)dx + xdy = 0$ , con la condición $y(1)=0$.
\vspace{10pt}
\item $y' = \dfrac{y-x}{y+x}$ , con la condición $y(1)=1$.
\vspace{10pt}
\item $\left(y + x\cot\dfrac{y}{x} \right) -xdy = 0$, con la condición $y(1)=-\pi$.
\vspace{10pt}
\item $\dfrac{x+y+1}{x-y-1}$, con la condición $y(1)=1$.
\end{itemize}
\pagebreak
\section{Ecuaciones Diferenciales Exactas}
\noindent Una EDO de primer orden en la forma
$$M(x,y)dx + N(x,y)dy = 0$$
se dice ser \textbf{exacta} si
$$\frac{\partial M(x,y)}{\partial y}=\frac{\partial N(x,y)}{\partial x}$$
\textbf{Ejemplo: }la ecuación $$(2xy-9x^2)dx + (2y+x^2 + 1)dy = 0$$
es exacta. Pues tomando $M(x,y)=2xy-9x^2$ y $N(x,y)=2y+x^2 + 1$, podemos notar que
$$\frac{\partial M}{\partial y} = 2x  = \frac{\partial N}{\partial x}.$$
\textbf{Nota: }Recuerde que para calcular la derivada parcial con respecto a una variable, hacemos como si las demás variables fueran constantes.\\
\textbf{Ejemplo: } La ecuación
$$\cos(x+y)dx + ydy = 0$$
no es exacta, pues si $M(x,y)=\cos(x+y)$ y $N(x,y)=y$, vemos que
$$\frac{\partial M}{\partial y} = -\sen(x+y) \neq 1 = \frac{\partial N}{\partial x}.$$
Para resolver una ecuación diferencial exacta, tenemos que encontrar una \textbf{función potencial}, esto es, una función $F(x,y)$ que cumpla
$$\frac{\partial F(x,y)}{\partial x } = M(x,y)\quad , \quad \frac{\partial F(x,y)}{\partial y} = N(x,y).$$
Una vez encontrada dicha función, la solución general viene dada simplemente por 
$$F(x,y)=C$$
donde $C$ es el parámetro.\\
\textbf{Ejemplo: }Resolvamos paso a paso la ecuación $$(2xy^2+4)dx - 2(3-x^2y)dy = 0.$$
Si deseamos utilizar este método, debemos verificar primero que se trata de una ecuación exacta. Tomemos por lo tanto $M(x,y)=(2xy^2+4)$ y $N(x,y)=-2(3-x^2y)$. Tenemos entonces que
$$\frac{\partial M}{\partial y} = 4xy$$
mientras que 
$$\frac{\partial N}{\partial x} = -2(-2xy)=4xy.$$
Por lo que nuestras derivadas coinciden. Lo que resta es encontrar nuestra función potencial. Estamos buscando alguna función $F(x,y)$ que cumpla
$$\begin{cases}
\frac{\partial F(x,y)}{\partial x}=M(x,y)=2xy^2+4 \\
\frac{\partial F(x,y)}{\partial y}=N(x,y)=-2(3-x^2y)
\end{cases}$$
Para encontrarla, debemos integrar dos veces, una con respecto a $x$ y otra con respecto a $y$.
\begin{alignat*}{2}
&& \dfrac{\partial F(x,y)}{\partial x}&=2xy^2+4 \\
\Rightarrow&& \int  \dfrac{\partial F(x,y)}{\partial x}dx&=\int (2xy^2+4) dx \\
\Rightarrow&& F(x,y) &= x^2y^2 + 4x + 
C(y)
\end{alignat*}
En la integral de la derecha, como se trabaja respecto a $x$, hacemos cuenta de que $y$ es un número, por lo cual sale de la integral. Además, note que en vez de constante de integración, añadimos una función que solo depende de $y$. Esto pues, al derivar toda la expresión de nuevo con respecto a $x$, se tiene que $\frac{\partial C(y)}{\partial x}=0$, por lo que $C(y)$ en realidad se comporta de manera análoga a la constante de integración. De igual forma, integrando la segunda igualdad,
\begin{alignat*}{2}
&& \dfrac{\partial F(x,y)}{\partial y}&=-2(3-x^2y) \\
\Rightarrow&& \int  \dfrac{\partial F(x,y)}{\partial y}dy&=\int -2(3-x^2y) dy \\
\Rightarrow&& F(x,y) &= -6y + x^2y^2 + K(x)
\end{alignat*}
donde una vez más, $K(x)$ es la ``constante de integración'' que en realidad depende de $x$ (pues esta vez integramos con respecto a $y$). Tenemos por lo tanto suficiente información acerca de $F(x,y)$:
\begin{align*}
F(x,y)&=x^2y^2 + 4x + C(y) \\
F(x,y)&= x^2y^2 + K(x) - 6y
\end{align*}
A partir de aquí, podemos ver por medio de un tanteo, que $K(x) =4x$ y que $C(y) =-6y$. Es decir, si bien cada una de las integrales no nos muestra quien es $F$, al unir la información, llegamos a la función, por lo que $F(x,y)=x^2y^2 +4x - 6y$. Finalmente, la solución general de la ecuación es $F(x,y)=C$, o sea
$$x^2y^2 +4x - 6y=C$$
\textbf{Ejemplo: }Resuelva el siguiente problema de valor inicial
$$ (3y^3 e^{3xy}-1)dx + (2ye^{3xy}+3xy^2e^{3xy})dy = 0 \ ; \ y(0)=1$$
Tenemos entonces que $M(x,y)=3y^3 e^{3xy}-1$ y que $N(x,y) =2ye^{3xy}+3xy^2e^{3xy}$. Derivando, obtenemos
$$\frac{\partial M}{\partial y}  = 9y^2e^{3xy} + 9xy^3e^{3xy}= \frac{\partial N}{\partial x}$$
por lo que nuestra ecuación es exacta. Tenemos ahora que encontrar $F(x,y)$ tal que 
$$\begin{cases}
\dfrac{\partial F(x,y)}{\partial x}=3y^3 e^{3xy}-1 \\
\ \\
\dfrac{\partial F(x,y)}{\partial y}=2ye^{3xy}+3xy^2e^{3xy}
\end{cases}$$
para lo cual integramos con respecto a $x$:
\begin{alignat*}{2}
&& F(x,y) &= \int (3y^3e^{3xy} -1) dx \\
\Rightarrow&& &= y^2e^{3xy} - x + C(y).
\end{alignat*}
Ahora podemos integrar con respecto a $y$, pero en vez de eso, usaremos un atajo. Sabemos \footnote{Recordemos la abreviación
$F_z = \dfrac{\partial F}{\partial z}$} que $F_y = N(x,y)$. Es decir, que si derivamos la expresión que tenemos para $F$ con respecto a $y$, deberíamos obtener $N(x,y)$, en otras palabras
\begin{alignat*}{2}
&&\frac{\partial}{\partial y} \left( y^2e^{3xy} - x + C(y) \right) &= 2ye^{3xy}+3xy^2e^{3xy} \\
\Rightarrow&& 2ye^{3xy} + 3xy^2e^{3xy} +  C'(y) &= 2ye^{3xy}+3xy^2e^{3xy} \\
\Rightarrow&& C'(y) = 0
\end{alignat*}
Esto nos dice que $C(y)$ es en realidad una constante, digamos $C(y)=k$. Tenemos entonces nuestra función potencial, sin haber hecho la segunda integral con respecto a $y$. 
$$F(x,y) = y^2e^{3xy}-x +k.$$
\pagebreak
\\
La solución general al problema es
$$y^2 e^{3xy} - x  = C.$$
donde una vez más usamos el abuso ``$C-k=C$''. Solamente falta resolver la condición inicial: como $y(0)=1$, tenemos que
$$1e^0 - 0 = C \Rightarrow C=1$$
por lo que la solución al problema es finalmente  $$y^2 e^{3xy} - x  = 1.$$

\subsection{Solución por factores integrantes.} 
No todas las ecuaciones de la forma
$$M(x,y)dx + N(x,y)dy = 0$$
son exactas. Sin embargo, a veces es posible multiplicar toda la ecuación por alguna función $\mu(x,y) \neq 0$ de forma que la nueva ecuación
$$\mu(x,y)M(x,y)dx + \mu(x,y)N(x,y)dy=0$$
sea exacta. Cuando esto es posible, decimos que la función $\mu(x,y)$ es un \textbf{factor integrante} de la ecuación diferencial. \\
\textbf{Ejemplo: } La ecuación
$$\left(1+  \frac{y^2}{x} \right) - 2ydy = 0$$
no es exacta, pues si $M(x,y)=(1+  \frac{y^2}{x})$ y $N(x,y)=-2y$, vemos fácilmente que $M_y = \frac{2y}{x} \neq 0 = N_x$. Sin embargo, si multiplicamos por $\mu(x) = \frac{1}{x}$ (el factor integrante puede ser incluso una función de una variable), obtenemos la ecuación
$$\left(\frac{1}{x}+  \frac{y^2}{x^2} \right) - \frac{2y}{x}dy = 0$$
en la cual, si tomamos ahora $P = \frac{1}{x}+  \frac{y^2}{x^2}$ y $Q = -\frac{2y}{x}$, vemos que
$$P_y = \frac{2y}{x^2} = Q_x,$$
lo cual implica que nuestra nueva ecuación sí es exacta. Tenemos entonces que la función potencial es $$F(x,y)=\int P dx = \ln(x) - \frac{y^2}{x}+C(y)$$
y como $F_y=Q$, derivando esta última expresión respecto a y, obtenemos
$$-\frac{2y}{x}+C'(y) = -\frac{2y}{x} \Rightarrow C'(y)=0$$
o sea, que $C(y)=C$ (es constante). Después de simplificar las constantes adicionales, la solución general de la ecuación es
$$\ln(x) - \frac{y^2}{x} = C.$$
En general, encontrar un factor integrante es difícil, pues no hay muchas fórmulas que nos ayuden a encontrarnos. Tenemos sin embargo un recurso que funciona para cierto tipo de ecuaciones diferenciales.\\
Suponga que deseamos resolver
$$M(x,y)dx+N(x,y)dy = 0$$
usando algún factor integrante $\mu(x,y)$. Entonces, se tiene que
\begin{itemize}
\item Si la función $\varphi = \dfrac{My-Nx}{N}$ solo es función de $x$, entonces un factor integrante para la ecuación diferencial es $\mu(x) = e^{\int \varphi(x)}$.
\vspace{10pt}
\item Si la función $\psi = \dfrac{Nx-My}{M}$ solo es función de $y$, entonces un factor integrante para la ecuación diferencial es $\mu(y) = e^{\int \psi(y)}$.\\
\end{itemize}
\textbf{Ejemplo: }Encuentre la solución general de la ecuación
$$(y \ln(y) + ye^x)dx + (x+y \cos y)dy = 0.$$
Esta ecuación no es exacta. Intentemos calcular un factor integrante tomando \linebreak $M=(y\ln(y) + ye^x)$ y $N=(x+y \cos y)$. Tenemos entonces que
$$M_y = \ln(y) +e^x + 1 , \quad Nx=1.$$
Podemos observar entonces que la función
$$\psi = \frac{N_x-M_y}{M}= \frac{\ln(y) - e^x}{y(\ln(y) + e^x)}=\frac{-1}{y}$$
solo depende de $y$. Por lo tanto, nuestro factor integrante es
$$\mu(y) = e^{-\int \frac{1}{y} dy}= e^{-\ln y}=\frac{1}{y}.$$
Al multiplicar la ecuación original por $\mu$, se obtiene la ecuación exacta
$$(\ln(y) + e^x)dx + \left(\frac{x}{y} + \cos(y) \right)dy = 0$$
la cual ya podemos resolver con nuestras herramientas. La solución general de la ecuación es 
$$e^x + x \ln(y) + \sen(x) = C.$$
\subsection{Ecuaciones lineales de primer orden}
Recordemos que una EDO lineal de primer orden tiene la forma
$$a(x)y' + b(x)y = c(x)$$
donde $a(x) \neq 0$. Podemos incluso dividir toda la ecuación por $a(x)$ para llegar a una de la forma
 \begin{equation}\label{eqn:5}
   y'+p(x)y= q(x).
  \end{equation}
En esta sección daremos una \textbf{fórmula general} para resolver cualquier ecuación de ese tipo. Note primero que podemos reescribir la ecuación \eqref{eqn:5} como
$$(p(x)y - q(x))dx + dy = 0.$$
Tomando ahora $M=p(x)y - q(x)$ y $N=1$, podemos ver que 
$$\frac{M_y-N_x}{N} = \frac{p(x)}{1}=p(x)$$
solo depende de x. Podemos tomar el factor integrante $\mu(x) = e^{\int p(x)dx}$. Así de \eqref{eqn:5} obtenemos la ecuación
$$y' e^{\int p(x)dx} + p(x)ye^{\int p(x)dx} = q(x)e^{\int p(x)dx}$$
cuyo lado izquierdo es simplemente la derivada de $\mu y$:
$$(ye^{\int p(x)dx})' = q(x)e^{\int p(x)dx}.$$
Esta ecuación se resuelve simplemente integrando a ambos lados con respecto a $x$ (también se puede hacer separando variables), para obtener que
\begin{alignat*}{2}
&&\int(\mu(x)y(x))'dx &= \int q(x) \mu(x)dx \\
\Rightarrow&&\mu(x)y &= \int q(x)\mu(x)dx + C
\end{alignat*}
Por lo que, hemos demostrado que la solución general de la ecuación \eqref{eqn:5} es
$$y = \frac{1}{\mu(x)}\left(\int q(x)\mu(x)dx + C\right)$$
donde $C$ es un parámetro y $\mu(x)= e^{\int p(x)dx}$.\\
\textbf{Ejemplo: } Para resolver la ecuación $y' +y\tan(x) = x^2 \cos(x)$, simplemente tomamos $p(x) = \tan(x)$, $q(x) =x^2 \cos(x)$. Calculamos 
$$\mu(x) = e^{\int p(x)dx} = e^{-\ln(\cos(x))}=\sec(x).$$
Entonces nuestra solución general viene dada por
$$y = \frac{1}{\sec(x)}\left(\int x^2 \cos(x) \sec(x)dx +C \right) = \cos(x)\left( \frac{x^3}{3}+C\right).$$
La fórmula general para ecuaciones lineales es una herramienta muy útil, pues nos ahorra todo el trabajo de encontrar factores integrantes. Para finalizar la sección, veremos el método de resolución de dos tipos de ecuaciones más, en las cuales un cambio de variable nos lleva a una ecuación lineal.
\subsection{Ecuación de Bernoulli} Son aquellas EDOs de la forma
$$y' +p(x)y = q(x)y^n, \quad \text{con $n \in \mathbb{R}$ }$$
las cuales se pueden reescribir como
$$y'y^{-n} + p(x)y^{1-n} = q(x).$$
Para resolver estas ecuaciones, utilizamos el cambio de variable $u = y^{1-n}$, por lo que \linebreak $du = (1-n)y^{-n}dy$. Después de sustituir en la ecuación reescrita, se obtiene
$$\frac{u'}{1-n}+up(x) = q(x)$$
que es una ecuación diferencial lineal, solo restaría aplicar la fórmula general.\\
\textbf{Ejemplo: } Resuelva el siguiente problema de valores iniciales
$$y'-5y = e^{-2x}y^{-2} \ ; \ y(0)=1$$
Estamos en presencia de una ecuación de Bernoulli. Tomando entonces $u=y^3$, vemos que $du = 3y^2dy$, por lo que, sustituyendo obtenemos
$$\frac{u'}{3}-5u = e^{-2x} \Rightarrow u' - 15u = 3e^{-2x}.$$
Esta ecuación tiene como factor integrante $\mu(x) = e^{-15x}$, por lo que gracias a la fórmula general, se tiene que
$$u=e^{15x}\left(\int{3e^{-15x}e^{-2x}dx + C}\right) = 3e^{15x}\left(\int e^{-17x}dx + 
C\right) = 3e^{15x}\left(-\frac{e^{-17x}}{17}+ C \right).$$
Deshaciendo nuestro cambio de variable, se tiene que la solución general es
$$y^3 = -\frac{3}{17}\left( e^{-2x} +Ce^{15x} \right).$$
Finalmente, como $y(0) = 1$, tenemos que 
$$1 = -\frac{3}{17}(1+C).$$
Por lo que $C=-\frac{21}{3}.$\pagebreak
\subsection{Ecuación de Riccati} Son aquellas ecuaciones que tienen la forma
$$y' +a(x)y+ b(x)y^2 = c(x).$$
Aunque no veremos el método de resolución general, veremos una forma de deducir una solución a partir de otra. Si se conoce una solución $y_1$, entonces podemos aplicar el cambio $z=y-y_1$, en donde $z'=y'-y_1'$ para obtener
\begin{alignat*}{2}
&&y_1' + z' +a(x)(y_1+z) + b(x)(y_1+z)^2 &= c(x) \\
\Rightarrow&& y_1' + z' + a(x)y_1 + a(x)z + b(x)y_1^2 + 2b(x)y_1z + b(x)z^2 &= c(x) \\
\Rightarrow && (y_1' + a(x)y_1 + b(x)y_1^2) + z' + a(x)z+2b(x)y_1z + b(x)z^2 &= c(x)
\end{alignat*}
Ahora, como sabemos que $y_1$ es solución, esto significa que 
$$y_1' + a(x)y_1 + b(x)y_1^2 = c(x)$$
por lo que sustituyendo esto en la ecuación anterior obtenemos
\begin{alignat*}{2}
&&c(x) + z' + a(x)z + 2b(x)y_1z + b(x)z^2 &= c(x) \\
\Rightarrow && z' +a(x)z+2b(x)y_1z + b(x)z^2 &= 0 \\
\Rightarrow && z' + (a(x)+2b(x)y_1)z + b(x)z^2 &= 0
\end{alignat*}
Esta última ecuación es de Bernoulli, y se puede resolver con el método de la subsección anterior.
\textbf{Ejemplo: }Resuelva la ecuación
$$y'+y^2\sen(x) = 2\tan(x)\sec(x)$$
si se sabe que $y_1=\sec x$ es una solución de la ecuación.\\
Note primero que en esta ecuación, $a(x)=0$, $b(x)=\sen(x)$, y que $c(x) = 2\tan(x)\sec(x)$. Tomando el cambio $z=y-\sec(x)$, podemos ahorrarnos todo el proceso hecho arriba para llegar a que nuestra ecuación se convierte en
$$z' + 2\sen(x)\sec(x)z + \sen(x)z^2 = 0$$
la cual es una ecuación de Bernoulli, que se puede reescribir como
$$z'z^{-2} + 2\sen(x)\sec(x)z^{-1} = -\sen(x).$$
El cambio de variable $u=z^{-1}$ convierte esta ecuación en una lineal:
$$-u' + 2\sen(x)\sec(x)u = -\sen(x)$$
la cual se resuelve gracias al factor integrante
$$\mu(x) = e^{-2\int \sen(x)\sec(x)dx} = e^{-2\int \tan(x)dx} = e^{2\ln(\cos(x))} = \cos^2(x).$$
La solución viene dada gracias a la fórmula general
$$u = -\sec^2(x) \left( \int \sen(x)\cos^2(x) dx + C\right) = \frac{-\cos(x)}{3}-C\sec^2(x).$$
Finalmente, al deshacer los cambios de variable $u=z^{-1}$, y $z=y-\sec(x)$, llegamos a la solución general
$$\frac{1}{\sec(x)- y} = \frac{\cos(x)}{3} + C\sec^2(x).$$
\textbf{Ejercicio: } Resuelva las siguientes EDOs exactas. En caso de no ser exactas, utilice un factor integrante.
\begin{itemize}
\item $2(y-1)e^xdx+2(e^x-2y)dy = 0$. 
\vspace{10pt}
\item $x \arctan(y)dx + \dfrac{x^2}{2(1+y^2)}dy = 0$.
\vspace{10pt}
\item $(3x^2+y\cos(x))dx + (\sen(x)-4y^3)dy=0$.
\vspace{10pt}
\item $\dfrac{2y}{x}y' = \dfrac{x+y^2}{x^2}$
\vspace{10pt}
\item $(1+y^2)dx + xydy = 0$.
\vspace{10pt}
\item $\left(e^x - \dfrac{y^2}{2} \right)dx + (e^y - xy)dy=0$.
\vspace{10pt}
\item $(t^2-1)x'(t) = -t-2x(t)$.
\end{itemize}
\textbf{Ejercicio: }Resuelva las siguientes EDOs lineales, de Bernoulli y de Riccati.
\begin{itemize}
\item $y'-2xy = e^{x^2}.$
\vspace{10pt}
\item $2r'(\theta) + r \sec(\theta) = \cos(\theta)$.
\vspace{10pt}
\item $xy' + 2y + x^5y^3e^x = 0.$
\vspace{10pt}
\item $y' = y \cot(x) + y^3 \csc(x).$
\vspace{10pt}
\item $\dfrac{dy}{dx}= -2-y+y^2$, si se sabe que una solución es $y_1=2$.
\vspace{10pt}
\item $\dfrac{dy}{dx} = \dfrac{2\cos^2(x)-\sen^2(x)+y^2}{2\cos(x)}$, si se sabe que una solución es $y_1=\sen(x)$.
\end{itemize}
\newpage
\section{Ecuaciones Diferenciales Ordinarias de orden superior}
Hemos estudiado ya varios métodos de resolución para ecuaciones diferenciales de orden 1 (aquellas en donde la derivada de mayor orden es la primera). En esta sección estudiaremos principalmente la resolución de ecuaciones \textbf{lineales} de orden mayor o igual a 2. Recordemos que dichas EDOs tienen la forma
 \begin{equation}\label{eqn:6}
    a_n(x)y^{(n)}(x) + a_{n-1}(x)y^{(n-1)}(x) + \dots + a_1(x)y'(x) + a_0(x)y(x) = f(x)
  \end{equation}
  donde $a_n,a_{n+1},\dots,a_1,a_0,f$ son funciones de una variable $x$, y además $a_n(x) \neq 0$, con $n \geq 2$. Recordemos también que si $f(x)=0$, llamamos a la ecuación \eqref{eqn:6} \textbf{homogénea}. Finalmente, cuando $a_n,a_{n-1},\dots,a_1,a_0$ son funciones constantes, es decir números, decimos que la ecuación \eqref{eqn:6} tiene \textbf{coeficientes constantes.} Primero presentamos un teorema que generaliza al último de la sección 5. \\
  \textbf{Teorema de existencia y unicidad para EDOs lineales: } Considere el problema de Cauchy
  \begin{align*}
\begin{cases}
a_n(x)y^{(n)}(x) + a_{n-1}(x)y^{(n-1)}(x) + \dots + a_1(x)y'(x) + a_0(x)y(x) = f(x) \\
y(x_0)=y_0 \\
y'(x_0)=y_1 \\
y''(x_0)=y_2 \\
\vdots \\
y^{(n-1)}(x_0)=y_{n-1}
\end{cases}
\end{align*}
Cuando todas las funciones $a_n,a_{n+1},\dots,a_1,a_0,f$ son continuas en algún $A \subseteq \mathbb{R}$, entonces el problema de Cauchy posee una única solución.\\
\textbf{Ejemplo: } El problema $$\frac{y''}{x^2} - \sqrt{x}y = 0 \ , \ y(2)=1  \ , \ y'(3) = 0$$
posee una única solución, siempre que $x>0$, gracias a que los coeficientes $\dfrac{1}{x^2}$, y $-\sqrt{x}$ son continuos en esta región. La aplicación del teorema es directa en este caso.\\
\textbf{Ejemplo: }Todo problema de Cauchy cuya ecuación diferencial sea lineal con coeficientes constantes y homogénea, es decir de la forma
$$a_ny^{(n)} +a_{n-1}y^{(n-1)}+ \dots + a_1y' + a_0y = 0 \quad , \quad  a_i \in \mathbb{R} \text{ para } i=0,1,\dots,n$$tiene solución única, pues evidentemente todas las funciones constantes son continuas. \pagebreak \\
La importancia de los teoremas de existencia y unicidad para ecuaciones diferenciales es más teórica que práctica, puesto que no son realmente maneras de calcular la solución de un problema determinado, sino solamente herramientas para demostrar que una solución existe (lo cual hace que valga la pena intentar buscarla en primer lugar).
\subsection{El conjunto solución de una ecuación diferencial visto como espacio vectorial.}
Hemos visto que cuando resolvemos una ecuación diferencial de primer orden, por ejemplo $y'=y$, su solución general viene dada por una \textit{familia} de funciones, en este caso $y'=Ce^x$, donde $C$ es cualquier número real. Para ecuaciones de orden superior, vamos a tener una situación similar (entre mayor el orden, más parámetros necesitamos). Para precisar esta intuición de manera matemática, necesitamos volver a la noción de un \textbf{espacio vectorial}. A partir de ahora, vamos a permitirnos usar números complejos ($\mathbb{C}$) cuando sea conveniente. El uso de números complejos nos permitirá resolver aún más ecuaciones diferenciales.\\
% \textbf{Definición: }Un \textbf{espacio vectorial} es un conjunto de vectores $V$, junto con algún conjunto de escalares (usualmente $\mathbb{R}$ o $\mathbb{C}$), el cual cumple que:
% \begin{itemize}
% \item Podemos sumar vectores. Es decir, si $v,w \in V$ son vectores, entonces $v+w \in V$ es también un vector
% \item Podemos escalar vectores. Es decir, si $v \in V$, y $\lambda \in \mathbb{R}$ (o incluso $\mathbb{C}$), entonces $\lambda v \in V$ es un vector.
% \item Tenemos un vector $\mathbf{0}$ de forma que para todo $v \in V$ se cumple que $v+\mathbf{0} = v.$\\
% Podemos demostrar a partir de aquí que es posible restar vectores, pues si $v,w \in V$, sabemos que como $-1$ es un escalar, $v,-w \in V$, y por lo tanto la suma de ellos estará en V, $v+(-w) = v-w \in V$.
% \end{itemize}
% Las operaciones de suma y producto escalar se comportan de manera natural (conmutativas y asociativas). \\
% A partir de ahora, nuestro conjunto de escalares será el conjunto de los números complejos, $\mathbb{C}$, pues contiene a $\mathbb{R}$ y nos ayudará a encontrar aún más soluciones a ecuaciones. \\
\textbf{Definición: } Si $f_1(x),\dots,f_n(x):\mathbb{R} \to \mathbb{R}$ son funciones, entonces aquellas funciones de la forma
$$c_1f_1(x) + c_2f_2(x) + \dots + c_nf_n(x)$$
para $c_i \in \mathbb{C}$, se llaman \textbf{combinaciones lineales} de $f_1,\dots,f_n$. Note que las combinaciones lineales de una sola función $g(x)$, son todas de la forma $\lambda g(x)$, con $\lambda \in \mathbb{C}$, es decir, son todas \textbf{múltiplos} de $g(x)$. \\
\textbf{Ejemplo:} La función $f(x)=x^2 + 3x + 1$ es una combinación lineal de las funciones $x^2 ,x, 1$.\\
\textbf{Ejemplo: }La función $e^{iz} = \cos(z) + i \sen(z)$ es una combinación lineal de $\sen(z)$ y $\cos(z)$. \\
\textbf{Ejemplo: } La función $\cos(x)$ no se puede escribir como un múltiplo de $\sen(x)$. Pues de ser el caso, entonces tendríamos que habría algún número $\lambda \in \mathbb{C}$ que cumple que para todo $x$, 
$$\cos(x) = \lambda \sen(x)$$
lo cual implica que $\cot(x) = \lambda$ para todo $x$, lo cual es falso, pues la función cotangente no es constante. \\
El siguiente teorema se conoce como \textit{principio de superposición} para ecuaciones homogéneas, y nos dice que el conjunto de solución de una EDO lineal homogénea es en efecto un espacio vectorial.\\
\textbf{Teorema: } Si $y_1,y_2,\dots,y_k$ son soluciones de una EDO lineal homogénea, entonces cualquier combinación lineal de ellas es también una solución.\\
Esto nos dice básicamente que sumar soluciones de una EDO lineal homogénea produce nuevas soluciones de la misma ecuación. \pagebreak \\
\textbf{Ejemplo: } Las funciones $y_1=x^2$ y $y_2 = x^2 \ln x$ son soluciones de la ecuación lineal homogénea $x^3y''' - 2xy' + 4y = 0$. Por el principio de superposición, tenemos que las funciones \linebreak $y_3= -x^2 + 5x^2 \ln(x)$ , $y_4 = \frac{2}{7}x^2 - \sqrt{3}x^2 \ln (x)$ son también soluciones  a la misma ecuación. Más generalmente, para cualesquiera $C_1,C_2 \in \mathbb{C}$, la función
$$y=C_1x^2 + C_2x^2 \ln(x)$$
es solución a la ecuación diferencial.\\
Vemos entonces que cuando se trata de una EDO lineal homogénea, sin importar el grado, su \textit{familia} de soluciones es en realidad un espacio vectorial. Recordemos que para describir un espacio vectorial, basta con describir una base del mismo. Buscaremos entonces una base del espacio solución.\\
\textbf{Definición: } Un conjunto de funciones $\{f_1(x),\dots,f_n(x) \}$ se dice ser \textbf{linealmente independiente} si no existen constantes $c_1 , c_2 , \dots , c_n \in \mathbb{C}$ \textbf{no todas nulas}, que hagan que
$$c_1f_1(x) + c_2f_2(x) + \dots + c_nf_n(x)=0$$
para todo $x \in \mathbb{R}$. \\
\textbf{Ejemplo: }El conjunto $\{ x,x^2\}$ es linealmente independiente. Para esto, supondremos que hay escalares $c_1 , c_2$ que hagan que para todo $x$, $c_1x +  c_2x^2=0$, pero probaremos que serán necesariamente $0$, lo cual confirma que $x,x^2$ son l.i. Si $c_1x + c_2x^2 = 0$ para todo $x$, significa que para todo $x$, $x(c_1 + c_2x) = 0$ y que, para todo $x \neq 0$, $c_1+c_2x=0$. Si fuese que $c_2 \neq 0$ se tendría que para todo $x$, $x=-\frac{c_1}{c_2}$, lo cual no tiene sentido pues dice que todo $x$ es la misma constante, por lo que necesariamente $c_2 = 0$, y como, para todo $x \neq 0$, $$c_1 + c_2x =0 \Rightarrow c_1+ 0x_2 = c_1 = 0,$$ concluimos que ambos $c_1,c_2$ deben ser 0, lo que confirma que $x,x^2$ son l.i.\\
\textbf{Ejemplo: }las funciones $\sen^2(x) , \cos^2(x) , 1$ son linealmente dependientes (l.d), pues
$$\sen^2(x) + \cos^2(x) - 1 = 0.$$
Verificar si un conjunto de funciones es l.i. puede llegar a ser complicado, especialmente si tenemos muchas funciones. Para ello, tomamos prestado un recurso de álgebra lineal, el determinante.\\
\textbf{Definición: } El \textbf{Wronskiano} de las funciones $f_1(x),\dots,f_n(x)$ se define mediante la fórmula
$$W(f_1(x),\dots,f_n(x))(x) = \det \begin{pmatrix}
f_1(x) & f_2(x) & \dots & f_n(x) \\
f'_1(x) & f'_2(x) & \dots & f'_n(x) \\
\vdots & \vdots & \ddots & \vdots\\
f_1^{(n-1)}(x) & f_2^{(n-1)}(x) & \dots & f_n^{(n-1)}(x)
 \end{pmatrix}$$
 Note que el Wronskiano de las funciones $f_1(x),\dots,f_n(x)$ es también una función de $x$.\\
 El siguiente teorema es una adaptación uno estudiado en álgebra lineal.\\
 \textbf{Teorema: } Si $f_1,\dots,f_n$ son funciones \textbf{l.d.}, entonces, para todo $x \in \mathbb{R}$, $$W(f_1(x),f_2(x),\dots,f_n(x))(x)=0.$$ Es decir, el Wronskiano de las funciones es la constante $0$.\\
 También podemos ver el mismo teorema escrito de otra forma:\\
 \textbf{Teorema: } Si $f_1,\dots,f_n$ son funciones, y existe algún $x$ tal que $$W(f_1(x),\dots,f_n(x))(x)\neq0,$$ entonces las funciones son \textbf{l.i}. Es decir, cuando el Wronskiano no es la constante 0, las funciones serán l.i.\\
 \textbf{Ejemplo: }Demostremos de nuevo que las funciones $x,x^2$ son l.i. Note que
 $$W(x,x^2)(x) = \det \begin{pmatrix*}
 x & x^2 \\
 1 & 2x
 \end{pmatrix*} = (x)(2x)-(1)(x^2)=x^2.$$
 Como el Wronskiano no es la constante 0, concluímos gracias al teorema que $x$ y $x^2$ son l.i. La prueba es más fácil que la anterior.\\
 \textbf{Ejemplo: }Las funciones $x,e^x,xe^x$ son l.i. Pues
 \begin{alignat*}{2}
 &&W(x,e^x,xe^x)(x) &= \det \begin{pmatrix}
 x & e^x & xe^x \\
 1 & e^x & (x+1)e^x \\
 0 & e^x & (x+2)e^x
 \end{pmatrix} \\
 && &= x \det \begin{pmatrix}
 e^x & (x+1)e^x  \\
 e^x & (x+2)e^x  \\
 \end{pmatrix}  - \det \begin{pmatrix}
  e^x & xe^x \\
 e^x & (x+2)e^x
 \end{pmatrix} \\
 && &= x\left[(x+2)e^{2x} - (x+1)e^{2x} \right] -   \left[ (x+2)e^{2x}- xe^{2x} \right]\\
 && &=xe^{2x} - 2e^{2x} \\
 && &=(x-2)e^{2x}.
 \end{alignat*}
 Como el Wronskiano no es la constante $0$, de inmediato concluimos que la ecuación
 $$Ax + Be^x + Cxe^x=0 \quad , \text{ para todo } x$$
 con variables $A,B,C$, no tiene más solución que $A=B=C=0$ (o  sea estas funciones son linealmente independientes). \pagebreak \\
 \textbf{Nota: }En general, cuando el Wronskiano de un conjunto de funciones sí es la constante 0, no podemos concluir que las funciones son l.d. Sin embargo, si nuestro conjunto de funciones es parte de la solución de una ecuación lineal homogénea, sí podemos establecer la equivalencia ``$W = 0$ \textit{sii} son l.d.''  \\
  \textbf{Ejercicio: }Para cada conjunto de funciones, determine si son l.i. o l.d.
 \begin{itemize}
 \item $1,x^2,x^4$.
 \item $\sec^2(x), \tan^2(x) , 1$ .
 \item $\sen(z), \cos(z) , e^{iz}$.
 \item $\sen(x)e^x , \cos(x)e^x$.
 \item $e^{mx},e^{nx}$ cuando $m \neq n$.
 \end{itemize}
 \textbf{Definición: } Un \textbf{conjunto fundamental de soluciones} de una EDO lineal homogénea es cualquier conjunto l.i. $y_1, \dots ,y_n$ de soluciones de la ecuación. \\
 El siguiente teorema generaliza la noción inuitiva de que ``una ecuación diferencial de orden $n$ tiene una solución general con $n$ parámetros''\\
 \textbf{Teorema: }La familia de soluciones de una EDO lineal homogénea de orden $n$, es decir, de la forma
  \begin{equation}\label{eqn:7}
 a_n(x)y^{(n)} + a_{n-1}(x)y^{(n-1)} + \dots + a_1(x)y' + a_0(x)y =0
  \end{equation}
 es un espacio vectorial de dimensión $n$. En otras palabras, existen $n$ funciones linealmente independientes $y_1,\dots,y_n$ que cumplen que, para cualquier otra solución $y$, existen (únicos) escalares $c_1,c_2, \dots , c_n \in \mathbb{C}$ tales que para todo $x$,
 $$y(x) = c_1y_1(x)+ \dots + c_ny_n(x).$$
 Dicho de una tercera forma, el conjunto solución una EDO lineal homogénea de orden $n$, tiene un \textit{base} con $n$ elementos.
 \\El teorema anterior simplemente nos dice que si estamos intentando resolver una EDO lineal homogénea de orden $n$, y ya tenemos $n$ soluciones que son l.i., entonces ya tenemos la solución general.\\
 \textbf{Ejemplo: }Las funciones $y_1(x) = e^x$ y $y_2 = xe^x$ son l.i. y además son soluciones de la ecuación lineal homogénea de coeficientes constantes (verifíquelo)
 $$y''-2y'+y = 0.$$ \pagebreak \\
 El teorema anterior nos dice entonces que como el orden es $2$ y tenemos $2$ soluciones l.i, cualquier otra solución es combinación lineal de $e^x$ y $xe^x$, en otras palabras, todas las soluciones de esta EDO tienen la forma
 $$y(x) = C_1e^x + C_2xe^x.$$
 O sea que ésta es la solución general de la ecuación.\\
 \textbf{Ejemplo: } Queremos encontrar la solución general de
 $$y'''-6y''+11y'-6y=0.$$ No es difícil verificar que $y_1 = e^x$, $y_2 = e^{2x}$ y $y_3= e^{3x}$ son soluciones de la ecuación. Además, son l.i, puesto que
 $$W(e^x, e^{2x},e^{3x})(x) = \det \begin{pmatrix*}
 e^x & e^{2x} & e^{3x} \\
  e^x & 2e^{2x} & 3e^{3x} \\
   e^x & 4e^{2x} & 9e^{3x} \\
 \end{pmatrix*}  = 2e^{6x} \neq 0$$
 por lo que de inmediato podemos deducir que la solución general a la ecuación viene dada por
 $$y(x) = C_1e^x + C_2e^{2x} + C_3 e^{3x}.$$
 A continuación daremos otra manera de calcular el Wronskiano de un conjunto de funciones cuando conocemos una EDO lineal homogénea que las tenga como solución, y seguidamente presentamos una fórmula muy útil para el caso de las EDO lineales homogéneas de orden 2.\\
 \textbf{Identidad de Abel: } Sean $y_1,\dots,y_n$ soluciones l.i. de una ecuación de la forma $$a_n(x)y^{(n)} + a_{n-1}(x)y^{(n-1)} + \dots + a_1(x)y' + a_0(x)y =0,$$ entonces
 $$W(y_1(x),\dots,y_n(x))(x)= C \exp\left(-\int_0^x \frac{a_{n-1}(t)}{a_n(t)}dt\right)$$
 donde $C \in \mathbb{R}$. Esta identidad\footnote{Recuerde que $\exp(u)=e^u$.} no nos permite calcular $C$ explícitamente.\pagebreak\\
 \textbf{Ejemplo: }La ecuación diferencial $y''' =y'$ tiene soluciones l.i. $y_1 = e^x$ , $y_2= e^{-x}$, $y_3 = 1$. En este caso, como $a_3=1$, $a_2=a_0=0$ y $a_1=-1$, por la identidad de Abel se cumple
 $$W(e^x,e^{-x},1)(x) = C\exp\left({\int_0^x \frac{a_2}{a_3}dt}\right) = C\exp\left({\int_0^x 0
 dt}\right) = Ce^0 = C,$$
 es decir que, el Wronskiano de estas funciones es una constante. Vemos que en efecto, si calculamos también el determinante:
 $$\det \begin{pmatrix}
 e^x & e^{-x} & 1 \\
  e^x & -e^{-x} & 0 \\
   e^x & e^{-x} & 0 \\
 \end{pmatrix} = 2$$
 En el caso especial de las ecuaciones de orden 2, podemos usar la siguiente fórmula, que nos permite fabricar una solución a partir de otra, y que ambas sean l.i: \\
 \textbf{Corolario (Fórmula de Abel): }Si $y_1(x) \neq 0$ es una solución de una EDO de la forma
 $$y'' + b(x)y' + c(x)y = 0$$ entonces podemos encontrar otra solución $y_2(x)$, que sea linealmente independiente a $y_1$, mediante la fórmula
 $$y_2(x) = y_1(x)\int \frac{\exp\left(-\int b(x)dx \right)}{y_1^2(x)}dx.
$$
\textbf{Ejemplo: }Es fácil verificar que la ecuación $y''+y'+\frac{1}{4}y =0$ posee la solución $y_1(x) = e^{-x/2}$. Si queremos calcular la solución general, debemos encontrar otra solución que sea l.i. con $y_1$, podemos usar la fórmula de Abel 
\begin{alignat*}{2}
&& y_2(x) &= y_1(x)\int \frac{\exp\left(-\int b(x)dx \right)}{y_1^2(x)}dx \\
&& &= e^{-\frac{x}{2}}\int \frac{\exp\left(-\int dx \right)}{e^{-x}}dx \\
&& &= e^{-\frac{x}{2}}\int \frac{e^{-x}}{e^{-x}}dx \\
&& &= xe^{-\frac{x}{2}}
\end{alignat*}
Podemos omitir en estos pasos todas las constantes de integración, puesto solo necesitamos encontrar una solución más, no infinitas. Por lo tanto, tenemos dos soluciones l.i, $y_1=e^{-x/2}$, y $y_2 = xe^{-x/2}$, esto nos dice que la solución general de esta ecuación es
$$y(x) = C_1 e^{-\frac{x}{2}} +  C_2 xe^{-\frac{x}{2}}.$$ \pagebreak \\
\textbf{Ejercicio: } Verifique que 
$y_1(x)=\ln(x)$ es solución de la ecuación $$x^2 \ln^2(x)y'' - 2x \ln(x) y' + (\ln(x) +2)y = 0.$$
Utilice la fórmula de Abel para encontrar otra solución $y_2$ linealmente independiente de $y_1$. Dé la solución general de la ecuación.\\
\textbf{Ejercicio: }Repita el ejercicio anterior para la solución $y_1(x) = \cos(1/x)$, y la ecuación $$x^5 y'' + 2x^4y'+xy =0.$$
Seguidamente, encuentre la solución del problema que se obtiene al agregar las condiciones iniciales $y\left(\frac{1}{\pi}\right)=1$ y $y'\left(\frac{1}{2\pi}\right) = 2$. \\
Hemos definido bastantes conceptos, los cuales serán necesarios para la resolución de ecuaciones de orden superior. Notará que a lo largo de la sección no hemos resuelto ninguna ecuación. Todos los ejemplos son del tipo ``Si ya tenemos las soluciones l.i, cómo encontrar las demás''. A partir de ahora, nos dedicaremos a encontrar las \textit{soluciones fundamentales} (las l.i.), pues es a partir de ellas que se encuentra la solución general.
\subsection{Ecuaciones diferenciales homogéneas con coeficientes constantes.}
En esta subsección vamos a resolver ecuaciones de la forma  
 \begin{equation}\label{eqn:8}
    a_n y^{(n)} + a_{n-1}y^{(n-1)} + \dots + a_1y' + a_0y = 0
  \end{equation}
  donde los $a_i$ son todos números reales. Para resolver esta ecuación, vamos a construir una nueva ecuación, llamada la \textbf{ecuación característica}, la cual no es una EDO, sino una ecuación polinomial clásica. Ésta se consigue cambiando en \eqref{eqn:8} las $y^{(k)}$ por un $m^k$ para todo $k \in \{0,1,\dots,n \}$. Es decir, la ecuación característica es
 \begin{equation}\label{eqn:9}
    a_n m^n + a_{n-1}m^{n-1} + \dots + a_1m + a_0 = 0.
  \end{equation}
  Las raíces de esta ecuación son $n$ números complejos (puesto que todo polinomio de grado $n$ tiene exactamente $n$ raíces en $\mathbb{C}$). Supongamos que $\alpha_1,\dots,\alpha_n$ son las raíces de \eqref{eqn:9}. Entonces es posible demostrar que las funciones $y_i(x) = e^{\alpha_ix}$ son soluciones de la ecuación \eqref{eqn:8}. De ellas podemos entonces construir directamente la solución general de la ecuación \eqref{eqn:8}.\\
  \textbf{Caso 1:} Si todos los $\alpha_1,\dots,\alpha_n$ son reales y distintos, entonces la solución general es
  $$y(x) = C_1e^{\alpha_1 x} +  C_2e^{\alpha_2 x} + \dots +  C_{n-1}e^{\alpha_{n-1} x} +  C_ne^{\alpha_n x}.$$
  Esto pues en caso de ser todas las raíces distintas, todas las $y_i = e^{\alpha_ix}$ son l.i, y como son exactamente $n$, son una base del espacio solución.\pagebreak\\
  \textbf{Caso 2: }Si entre los $\alpha_1,\dots,\alpha_n$ hay algunos repetidos (sean reales o complejos), entonces debemos contar sus \textbf{multiplicidades} (es decir, cuántas veces aparece cada uno repetido). Entonces por ejemplo, si la raíz $\alpha_1$ tiene una multiplicidad de $k$, a esta raíz se le asocia la solución
  $$y_{\alpha_1}(x) = C_0e^{\alpha_1x} +C_1xe^{\alpha_1x} +C_2x^2e^{\alpha_1x} + \dots C_{k_1}x^{k-1}e^{\alpha_1x}.$$
  Es decir, para obtener la solución asociada a una raíz repetida $k$ veces, sumamos a partir de $e^{\alpha_1 x}$, agregándole $xe^{\alpha_1 x}$, y así sucesivamente hasta llegar a la potencia $k-1$ en $x$.
  Repitiendo esto para cada solución \textbf{distinta} de la ecuación característica, se tiene que la solución general es
  $$y(x) = y_{\alpha_1}(x) + \dots + y_{\alpha_n}(x)$$
\textbf{Caso 3: }Cuando alguna de las raíces sea un número complejo (no real), de la forma $\alpha+\beta i$, sabemos que $\alpha - \beta i$ (su conjugado complejo) también es raíz de \eqref{eqn:9}. Esto nos dice que las funciones $e^{\alpha + \beta i}$ y $e^{\alpha - \beta i}$  son ambas soluciones de \eqref{eqn:8}. Aplicando el principio de superposición y algunas identidades de números complejos, podemos resumir la solución asociada a ambas raíces $\alpha+\beta i$ y $\alpha-\beta i$ , como una función de argumento real, dada por
$$y_{\alpha + \beta i} = e^{\alpha x}(c_1 \cos(\beta x) + c_2 \sen(\beta x)) \quad \text{con } c_1,c_2 \in \mathbb{C}.$$
No hay ningún problema con escribir las soluciones como funciones complejas, pero podemos ahorrarnos esto y expresar la solución con números reales. Para encontrar la solución general en este caso se procede como en los casos 1 o 2.\\
Este método parece tener muchas variantes y casos, pero por medio de ejemplos veremos que es un método sencillo y directo de aplicar. Simplemente debemos seguir los pasos con atención. \\
\textbf{Ejemplo: } La ecuación $$y'' - 3y' - 10y = 0$$
es una EDO lineal homogéna de coeficientes constantes. Entonces podemos aplicar este método. Su ecuación característica es
$$m^2 - 3m -10 = 0.$$
Por medio de inspección o fórmula general, podemos ver que las raíces de esta ecuación son $m_1 = -2$ y $m_2 = 5$. Como son soluciones reales distintas, podemos aplicar el caso 1 del método y decir simplemente que la solución general es
$$y(x) = C_1 e^{-2x} + C_2 e^{5x}.$$\pagebreak \\
\textbf{Ejemplo: } La ecuación
$$y'' +10y' +25y=0$$
tiene ecuación característica
$$m^2 + 10m + 25 = 0.$$
la cual se factoriza como 
$$(m+5)^2 = 0.$$
Esto nos dice que la raíz $m_1 = -5$ tiene \textbf{multiplicidad 2}, por lo que debemos aplicar el caso 2 del método. La solución asociada a $m_1 = -5$ es
$y_{m_1}= C_1 e^{-5x} + C_2 x e^{-5x}$,
y como no hay más raíces, la solución general viene dada por 
$$y(x) = y_{m_1} =  C_1 e^{-5x} + C_2 x e^{-5x}.$$
\textbf{Ejemplo: }La ecuación $$y'' + y' + y = 0$$ tiene la ecuación característica
$$m^2 + m + 1 = 0.$$
Las raíces de este polinomio se deben buscar usando la fórmula general, y son complejas no reales, pues $\Delta = -3$. Tenemos entonces las soluciones
$$m_1 = -\frac{1}{2} + \frac{\sqrt{3}}{2}i \ , \  m_2 = -\frac{1}{2} - \frac{\sqrt{3}}{2}i$$
por lo que la solución general es simplemente
$$y= C_1e^{(-\frac{1}{2} + \frac{\sqrt{3}}{2}i)x} + C_2e^{(-\frac{1}{2} - \frac{\sqrt{3}}{2}i)x}.$$
No hay ningún problema en especificar la solución así, pero es preferible usar funciones de argumento real, y dejar los números complejos solo como escalares y parámetros. Aplicando el caso 3, como $m_1= -\frac{1}{2} + \frac{\sqrt{3}}{2}i$, tomando $\alpha= -\frac{1}{2} $ y $\beta = \frac{\sqrt{3}}{2}$, obtenemos que la solución asociada a $m_1$ (o a $m_2$) se puede reescribir de la forma
$$y_{m_1}= e^{-\frac{x}{2}}\left(A\cos\left(\frac{\sqrt{3}}{2}x \right) + B\sen \left(\frac{\sqrt{3}}{2}x\right)\right)$$
donde $A,B \in \mathbb{C}$. Como no hay más raíces del polinomio, la solución general es la solución asociada a $m_1$.
$$y(x) = e^{-\frac{x}{2}}\left(A\cos\left(\frac{\sqrt{3}}{2}x \right) + B\sen \left(\frac{\sqrt{3}}{2}x\right)\right).$$ \pagebreak \\
\textbf{Ejemplo: } Considere la ecuación de orden 4
$$y^{(4)}-5y'' + 4y = 0.$$
Su ecuación característica viene dada por 
$$m^4 - 5m^2 + 4 = 0.$$
Al utilizar división sintética o inspección, podemos ver que esta ecuación se factoriza como
$$(m+1)(m-1)(m+2)(m-2)=0,$$
por lo que tenemos 4 soluciones: $m_1=1$, $m_2=-1$, $m_3=2$ y $m_4=-2$. Como solo tenemos soluciones reales, podemos escribir la solución general de una vez
$$y(x) = C_1e^{x}+C_2e^{-x}+C_3e^{2x}+C_4e^{-2x}.$$
\textbf{Ejemplo: }En este ejemplo combinaremos todos los casos. Considere la ecuación de orden 6 $$y^{(6)}+ 2y^{(4)} + y'' = 0.$$ Su ecuación característica, $m^6 + 2m^4 + m^2=0$, puede factorizarse como
$m^2 (m^2+1)^2=0.$
Sus raíces son: $m_1 = 0$, $m_2 = i$ y $m_3 = -i$, todas con multiplicidad 2. Entonces debemos encontrar las soluciones asociadas a cada $m_i$, y luego sumarlas para obtener la solución general. Para $m_1 = 0$, tenemos
$$y_{m_1}= C_1 e^{0x} + C_2xe^{0x} = C_1 + C_2x.$$
Ahora, para las soluciones complejas aplicamos el caso 3, y como $i$ y $-i$ son conjugados, solo necesitamos encontrar $y_{m_2}$. Como $i=0+1i$, se tiene que $\alpha = 0$ y que $\beta = 1$, por lo que
\begin{align*}y_{m_2} &= e^0(C_3 \cos(x) + C_4 \sen(x)) + xe^0(C_5 \cos(x) + C_6 \sen(x))\\
&= C_3 \cos(x) + C_4 \sen(x) + C_5 x\cos(x) + C_6 x\sen(x), \end{align*}
donde recordamos que como son soluciones múltiples, se debe sumar una copia de la solución multiplicada por $x$ (con nuevos parámetros). Entonces para obtener la solución general, sumamos las familias de soluciones asociadas a cada raíz,
$$y(x)=y_{m_1}+ y_{m_2} = C_1 + C_2x +C_3 \cos(x) + C_4 \sen(x) + C_5 x\cos(x) + C_6 x\sen(x).$$
Como nos dice el teorema, necesitamos 6 parámetros para describir la solución completamente, pues es un espacio vectorial de dimensión 6. \pagebreak \\
\textbf{Ejercicio: }Encuentre la solución general de cada una de las siguientes EDOs.
\begin{itemize}
\item $y''+4y'-y=0$.
\vspace{10pt}
\item $y''' -3y''+3y'-3y = 0$
\item $y''+5y=4y'$.
\vspace{10pt}
\item $16 \dfrac{d^4y}{dx^4}+24\dfrac{d^2y}{dx^2} + 9y=0$.
\vspace{10pt}
\item $u^{(5)} + 5u^{(4)}-2u^{(3)}-10u''+u'+5u=0$.
\end{itemize}
\textbf{Ejercicio: }Resuelva los siguientes problemas de valor inicial.
\begin{itemize}
\item $8x''(t) - 2x'(t) -15x(t) = 0$ con las condiciones $y(0)=y'(0)=1$ .
\vspace{10pt}
\item $y^{(6)}-2y^{(5)}-2y^{(4)}+2y^{(3)}+y''+4y'+4y=0$, con la condición \newline $y(0) = y'(0)=\dots = y^{(5)}(0)=0$.
\end{itemize}
\subsection{Operadores diferenciales: }Vamos a introducir una nueva manera de denotar la derivada de una función. Definimos el \textit{operador diferencial }$D$ como la función
$$D(f(x))=f'(x).$$
Así, tenemos que $D(x^3)=3x^2$, y $D(\sen(x))=\cos(x)$ por ejemplo. Denotamos $Df$ en vez de $D(f(x))$ por comodidad. Note que las derivadas de orden superior también se pueden expresar con este operador
$$D^2y = D(D(y))=D(y')=y'' \ , \ \text{y en general } \ D^ny=y^{(n)}.$$
Además podemos formar expresiones polinomiales usando este operador, así tenemos por ejemplo que
\begin{itemize}
\item $(D^2+1)(y) = D^2y + y =y'' + y$.
\item $(D^3 - D)(\sen(x))=(\sen(x))''' - (\sen(x))' = -\cos(x) - \cos(x) = -2\cos(x)$
\item $(D^4 + 8D + 4)(x^3)=  D^4(x^3) + 8D(x^3) + 4(x^3) = 0 + 24x^2 + 4x^3 = 4(x^3 + 6x^2). $
\item $(D-1)(e^x)=D(e^x) - e^x =0.$
\end{itemize}
Cualquier EDO lineal se puede reescribir usando el operador diferencial $D$. Por ejemplo, la ecuación
$$y''+5y'+6y=5x$$
pasa a ser
$$(D^2+5D+6)y=5x.$$
Para resolver ecuaciones no homogéneas, vamos a definir los anuladores diferenciales.\\
\textbf{Definición: }Un \textit{anulador diferencial} (o aniquilador diferencial) de una función $f$ es un polinomio en $D$, llamado $H(D)$, que cumpla que
$$H(D)f=0.$$
Por ejemplo, $D-1$ es un anulador de $e^x$, $D^2+1$ es un anulador de $\sen(x)$.\\
A continuación una lista con los anuladores que vamos a necesitar más a menudo. \\
\textbf{Lista de Anuladores: }

\begin{table}[h]
\begin{tabular}{|c|c|}
\hline
\textbf{Función $f$}                                                                    & \multicolumn{1}{c|}{\textbf{Anulador Diferencial}} \\ \hline
$a_nx^n + \dots + a_1x + a_0$                                                           & $D^{n+1}$                                          \\ \hline
$Ae^{\alpha x}$                                                                         & $D-\alpha$                                         \\ \hline
$Ax^ne^{\alpha x}$                                                                      & ($D-\alpha)^{n+1}$                                     \\ \hline
$A \cos(\omega x) + B \sen(\omega x)$                                                   & $D^2 + \omega^2$                                   \\ \hline
$A \cosh(\omega x) + B\senh(\omega x)$                          & $D^2-\omega^2$                                     \\ \hline
$P_n(x)\cos(\omega x) + Q_m(x) \sen(\omega x)$ & $(D^2 + \omega^2)^{N+1} \, \ N=\max{n,m}$   \\ \hline
$e^{\alpha x}(P_n(x)\cos(\omega x) + Q_m(x) \sen(\omega x))$ & $((D-\alpha)^2 + w^2)^{N+1} \ , \ N=\max{n,m}$
\\ \hline
\end{tabular}
\end{table}
En las últimas dos filas, $P_n$ y $Q_m$ son dos polinomios de grado $n$ y $m$, respectivamente.
Además, podemos notar que si $y_1,y_2$ son funciones con anuladores $H_1=H_1(D)$ y $H_2= H_2(D)$ respectivamente, entonces el operador $H_1H_2$ es anulador de $y_1+y_2$. Es decir, que para anular una suma de dos funciones, buscamos el anulador de cada función y luego solo los multiplicamos.\\
\textbf{Ejemplo: }El anulador de 
$$y=3e^{-2x} - 5xe^x - 2x^3e^x$$
se encuentra sacando el anulador de cada uno de sus sumandos: Para $3e^{-2x}$, se puede tomar $D+2$, para $-5xe^x$, se puede escoger $(D-1)^2$, y para $-2x^3e^x$, tomamos $(D-1)^4$, basándonos en la tabla. Además, observe que $(D-1)^4$ también es anulador de $-5xe^x$, por lo que no necesitamos multiplicar por $(D-1)^2$. Combinando, obtenemos que
$$(D-1)^4(D+2)y = 0.$$
Los anuladores no son únicos, pero en general buscamos anuladores de grado pequeño, además, podemos multiplicar los anuladores en cualquier orden.\\
\textbf{Ejemplo: } Encuentre el anulador de la siguiente función: 
$$y = e^{-x}(3-x+\sen(x)) - \sen(\sqrt{5}x)$$
la cual se puede reescribir como
$$y = 3e^{-x} - xe^{-x}+e^{-x}\sen(x) - \sen(\sqrt{5}x).$$
Los anuladores correspondientes a cada sumando son $D+1$, $(D+1)^2$ , $D^2 +2D +2$ y $D^2 + 5$. Combinando estos anuladores y omitiendo a $D+1$ porque no es necesario, se tiene que
$$(D+1)^2(D^2+2D+2)(D^2+5)y = 0.$$
\textbf{Ejercicio: }Encuentre el anulador diferencial de cada una de las siguientes funciones:
\begin{itemize}
\item $xe^{-x}(2-3x) + xe^{4x}$.
\item $5x\sen(\sqrt{2}x) - 3\cos(\sqrt{2}x)$.
\item $x^2 e^{-x}\cos(x) - (-8x^3 + 9x^5)\sen(3x) + (x^{2020} + 2020x + 2020)$.
\end{itemize}
Utilizaremos la ayuda de los anuladores diferenciales para resolver ecuaciones lineales no homogéneas.
\subsection{EDOs lineales no homogéneas}
Vamos a considerar ecuaciones de la forma
 \begin{equation}\label{eqn:10}
   a_ny^{(n)} + \dots + a_1y' + a_0 = f(x)
  \end{equation}
Donde $a_i \in \mathbb{R}$ y $f(x) \neq 0$. Esta ecuación puede verse como 
$$(a_nD^n + \dots + a_1D + a_0)y = f(x)$$
Para resolver esta ecuación debemos encontrar un anulador diferencial $H$ de $f(x)$. Una vez encontrado, multuplicamos toda la ecuación por $H$, para obtener
$$H(a_nD^n + \dots + a_1D + a_0)y = Hf(x)=0.$$
la cual es una ecuación lineal homogénea. Una vez hecho esto, debemos comparar la solución general $y_h$ de esta ecuación homogénea con la \textbf{solución complementaria} $y_c$ de 
$$(a_nD^n + \dots + a_1D + a_0)y = 0$$
es decir, de la ecuación original sin el término $f$. Esta comparación nos permitirá encontrar una solución particular $y_p$ de la ecuación \eqref{eqn:10}. La solución general viene dada finalmente por
$$y = y_c + y_p.$$
Todo esto es más claro por medio de ejemplos:\pagebreak \\
\textbf{Ejemplo: }Encuentre la solución general de la ecuación 
$$y'' - 2y + y = x.$$
Lo primero que debemos hacer es resolver la ecuación como si fuera homogénea, para encontrar $y_c$. Esta ecuación ya la sabemos resolver, por lo que
$$y_c = C_1e^x + C_2xe^x.$$
Ahora, reescribimos la ecuación en términos del operador $D$, para obtener
$$(D^2 - 2D + 1)y = (D-1)^2y =  x,$$
como el anulador de $x$ es $D^2$, se lo aplicamos a la ecuación en ambos lados.
$$D^2(D-1)^2 y = 0.$$
Esta ecuación también la sabemos resolver (simplemente resolvemos la ecuación característica $m^2 (m-1)^2 = 0$. Esto nos dice que
$$y_h = C_3 + C_4x + C_5e^x + C_6xe^x.$$
Para conseguir $y_p$ debemos eliminar los términos \textit{similares} a los de $y_c$, en la solución $y_h$, es decir, los términos que son iguales salvo parámetros. En este caso, los términos similares son $e^x$ y $xe^x$, por lo que, eliminándolos, buscamos una solución particular de la forma
$$y_p = C_3 + C_4x.$$
Como buscamos una solución \textit{particular,} debemos hallar los valores de $C_3$ y $C_4$, para esto simplemente derivamos nuestra candidata, y la sustituimos en la ecuación original.
\begin{alignat*}{2}
&&(C_3 + C_4x)'' - 2(C_3+C_4x)' + (C_3 + C_4x) &= x \\
\Rightarrow&& -2C_4 + C_3 + C_4x &= x\\
\end{alignat*}
Al comparar coeficientes a cada lado, se deduce que $C_4=1$, y por lo tanto $C_3=2$. Esto implica que $y_p = 2+x$. Finalmente, la solución general de la ecuación es
$$y = y_c + y_p = C_1e^x + C_2xe^x + 2 + x.$$ \pagebreak \\
\textbf{Ejemplo: }Encuentre la solución del problema de Cauchy
$$y''-y' = e^x \cos(x) \ , \ y'(0)=y(0)=0.$$
Primero reescribimos la ecuación,
$$D(D-1)y = e^x \cos(x).$$
Primero resolvemos $D(D-1)y=0$, para hallar
$$y_c = C_1 + C_2e^x.$$
Ahora, como el anulador de $e^x \cos(x)$ es $(D^2 - 2D+2)$, lo aplicamos a ambos lados para obtener
$$(D^2 - 2D + 2)D(D-1)y = 0.$$
Resolver esta ecuación homogénea con coeficientes constantes nos produce
$$y_h = C_3 + C_4e^x + C_3e^x \sen(x) + C_4e^x \cos(x),$$
por lo que, al eliminar términos similares, buscamos una solución particular de la forma
$$y_p = Ae^x \sen(x) + Be^x \cos(x).$$
Derivando, obtenemos que
\begin{align*}
y_p' &= (A-B)e^x \sen(x) + (A+B)e^x \cos(x) \\
y_p'' &= -2Be^x \sen(x) + 2Ae^x \cos(x).
\end{align*}
Luego, sustituyendo, tenemos que
\begin{alignat*}{2}
&&y''_p - y'_p &= e^x \cos(x) \\
\Rightarrow&&  (-2B-A+B)e^x\sen(x) + (2A-A-B)e^x \cos(x) &= e^x \cos(x)\\
\Rightarrow&& (-A-B)e^x \sen(x) + (A-B)e^x\cos(x) &= e^x\cos(x)
\end{alignat*}
Comparando términos, vemos que 
$$\begin{cases}
A+B=0\\
A-B=1
\end{cases},$$
por lo que $A=\frac{1}{2}$ y $B=-\frac{1}{2}$. Concluimos que 
$$y_p = \frac{e^x}{2}(\sen(x)-  \cos(x))$$
y que la solución general a la ecuación es
$$y=y_c+y_p = C_1+C_2e^x + \frac{e^x}{2}(\sen(x)-  \cos(x)). $$
Sin embargo, aún nos falta resolver para las condiciones iniciales. Dejaremos como ejercicio verificar que $C_1=\frac{1}{2}$, y que $C_2=0$, por lo que la solución del problema es
$$2y = 1+e^x (\sen(x)-\cos(x)).$$
\textbf{Ejercicios: }Encuentre la solución general de las siguientes ecuaciones diferenciales.
\begin{itemize}
\item $y'' + 3y' + 2y = 4x^2$.
\vspace{10pt}
\item $y'' - 5y' + 6y = e^{-3x} + \sen(2x)$.
\vspace{10pt}
\item $y'''+y'' = e^x \sen(x)$
\end{itemize}

 Este método de resolución tiene el inconveniente de que puede llegar a ser extremadamente largo para ecuaciones con muchas raíces repetidas. Presentamos un método que funciona para resolver el mismo tipo de ecuación, es decir, lineal no homogénea con coeficientes constantes.
 \subsection{Método de coeficientes indeterminados.} 
Una vez más, estamos interesados en resolver ecuaciones de la forma \eqref{eqn:10}. Vamos a utilizar la misma técnica de encontrar la solución complementaria $y_c$, y a partir de ella una solución particular $y_p$, de donde se sigue que la solución general es $y=y_c + y_p$. Sin embargo, para encontrar $y_p$, usaremos un nuevo método, el cual consiste en una especie de \textit{conjetura} que hacemos a partir de la forma que tenga $f(x)$.\\
\textbf{Nota: }Este método funciona únicamente cuando el término $f(x)$ de la ecuación \eqref{eqn:10} es un polinomio, un seno o un coseno, una exponencial, o cualquier suma y/o producto de estos.\\
\textbf{Ejemplo: } Encuentre la solución general de
$$y''+4y-2y = 2x^2 - 3x + 6$$
mediante coeficientes indeterminados.\\
Comenzamos al igual que con el método de anuladores, resolviendo la ecuación sin término $f(x)$,
$$y''+4y'-2y = 0,$$
cuya solución es
$$y_c = C_1 e^{-(2+\sqrt{6})x}+ C_2 e^{(-2+\sqrt{6})x}.$$
Ahora, como la función $f(x)$ es un polinomio de grado 2, el método consiste en \textbf{asumir} que la solución particular debe ser también un polinomio de grado 2:
$$y_p = Ax^2 + Bx+ C,$$
del cual solo debemos despejar $A,B,C$. Derivando nuestra candidata, obtenemos
\begin{alignat*}{2}
&& y_p''+4y_p' - 2y_p &= 2x^2 - 3x + 6\\  \Rightarrow && (Ax^2 + Bx+ C)'' + 4(Ax^2 + Bx+ C)' - 2(Ax^2 + Bx+ C) &= 2x^2 - 3x + 6 \\
\Rightarrow && 2A+8Ax+4B - 2Ax^2 - 2Bx - 2C &=2x^2 - 3x + 6
 \end{alignat*}
 Comparando los coeficientes de cada polinomio, debemos resolver el sistema
 $$\begin{cases}
 -2A=2 \\
 8A-2B=-3\\
 2A+4B-2C=6\\
 \end{cases}.$$
 La solución es $A=-1$, $B=-\frac{5}{2}$, $C=-9$. Esto nos dice que
 $$y_p = -x^2 - \frac{5}{2}x - 9$$
 por lo que finalmente la solución general es
 $$y=y_c+y_p = C_1 e^{-(2+\sqrt{6})x}+ C_2 e^{(-2+\sqrt{6})x}+-x^2 - \frac{5}{2}x - 9. $$
 Es decir, cuando $f(x)$ es un \textit{polinomio}, nuestra hipótesis para $y_p$ será un polinomio del mismo grado.\\
 \textbf{Ejemplo: }Encuentre la solución general de
 $$y''+8y'+y = 2 \sen(3x).$$
 Ya sabemos verificar que
 $$y_c = e^{-(4+\sqrt{15})x}+ C_2 e^{(-4+\sqrt{15})x}.$$
 Ahora, como $f(x)$ es un seno, es buena práctica asumir un $y_p$ de la forma
 $$y_p = A\sen(3x) + B\cos(3x),$$
 puesto que si solo colocamos un seno, podríamos toparnos con un sistema de ecuaciones  del tipo $A\cos(x) = \sen(x)$, en donde $A$ es imposible de despejar (esto pues  $\sen(x)$ y $\cos(x)$ se intercambian al derivarse). Tenemos entonces que
 \begin{align*}
 y_p' &= 3A\cos(3x) -3B\cos(3x) \\
 y_p'' &= -9A\sen(3x) -9B\cos(3x).
 \end{align*}
 Por lo que
 $$y_p''+8y_p'+y_p= - 8(A+3B)\sen(3x) + 8(3A-B)\cos(3x)$$
 por lo que al resolver el pequeño sistema
 $$
 \begin{cases}
 -8(A+3B)=2 \\
 8(3A-B)=0
\end{cases}$$
obtenemos $A=-\frac{1}{40}$, $B=-\frac{3}{40}$ por lo que la solución general viene dada por
$$y= y_c+y_p = y_c = e^{-(4+\sqrt{15})x}+ C_2 e^{(-4+\sqrt{15})x} - \frac{1}{40} \left(\sen(3x) + 3\cos(3x) \right).$$
En resumen, cuando $f(x)$ es un seno o un coseno, es mejor asumir que $y_p$ es de la forma $A\sen(u) + B\cos(u)$, donde $u$ es el mismo argumento que aparece en $f$ (en este caso tomamos $3x$). Veamos un tercer ejemplo\\
\textbf{Ejemplo: }Resuelva por coeficientes indeterminados
$$2y'' + 5y' - 3y  = x^2 e^{2x}.$$
Primero, resolvemos la ecuación homogénea,
$$y_c= C_1 e^x + C_2 e^{-3x}.$$
Ahora, observemos el término $f(x)$. En este caso, podemos ver que se trata de un \textbf{polinomio de grado 2} multiplicado por $e^{2x}$. El lector podrá intentar resolver la ecuación tomando $y_p = Ax^2e^{2x}$, lo cual resultará infructífero, pues la forma más general de un polinomio de grado 2 no es $Ax^2$ sino $Ax^2 + Bx + C$. Es por esto que debemos tomar
\begin{align*}
y_p &= (Ax^2 + Bx+ C)e^{2x} \\
y'_p &= (2Ax + B)e^{2x} + 2(Ax^2 + Bx+ C)e^{2x} \\
y''_p &= 2Ae^{2x} + 2(2Ax + B)e^{2x}+ 2(2Ax + B)e^{2x} +4(Ax^2 + Bx+ C)e^{2x} 
\end{align*}
por lo que
$$2y_p'' + 5y_p' -3y_p = (4A + 13B + 15C)e^{2x} + (26A+15B)xe^{2x}+ 15Ax^2e^{2x}$$
Al comparar con el término $x^2 e^{2x}$, tenemos el sistema
$$
\begin{cases}
4A + 13B + 15C = 0\\
26A+15B=0\\
15A=1
\end{cases}.$$
Resolver este sistema nos da los coeficientes $A=1/15$, $B=-26/225$, $C = 278 / 3375$. La solución general de la ecuación es
$$y=y_c+ y_p = C_1 e^x + C_2 e^{-3x}+\frac{1}{15}x^2e^{2x} -\frac{26}{225}xe^{2x}  + \frac{278}{3375}e^{2x}.$$
En resumen, si nuestro $f(x)$ está multiplicada por alguna potencia de $x$, es mejor asumir que $y_p$ está multiplicado por todo un polinomio indeterminado del mismo grado que la potencia. Veamos un último ejemplo, el cual es importante.\\
\textbf{Ejemplo: }Encontrar la solución general de la ecuación
$$y''-5y' + 4y = 8e^x.$$
Podemos observa que la solución complementaria es dada por
$$y_c= C_1e^x + C_2e^{4x}.$$
Ahora, si intentamos tomar 
$$y_p = Ae^x,$$
obtenemos 0 al sustituir en la ecuación. Esto sucede pues nuestra candidata a nuestra solución particular ya está contenida entre los términos de la solución complementaria. Es decir, se trata en el fondo de un \textit{solución repetida}. Entonces en estos casos podemos modificar nuestra candidata:
$$y_p=Axe^x$$
Al derivar y sustituir obtenemos
$$y_p'' - 5y'_p + 4y_p = -3Ae^x$$
Lo cual nos dice de inmediato que $A=-8/3$. Por lo que la solución general es
$$y= C_1e^x + C_2e^{4x}- \frac{8}{3}xe^x.$$
En resumen, si nuestra candidata a $y_p$ aparece como un término en $y_c$ , debemos multiplicarla por $x$.\pagebreak \\
\textbf{Ejercicio: }Complete la siguiente tabla.
\begin{table}[h]
\begin{tabular}{|c|c|}
\hline
\textbf{$f(x)$}             & \textbf{Forma de $y_p$} \\ \hline
$1$ (o cualquier constante) & A                       \\ \hline
$5x+5$                      & A$x$+B                    \\ \hline
$3x^2-2$                    &                         \\ \hline
$x^4 - 2x$                  &                         \\ \hline
$\sen(4x)$                  &                         \\ \hline
$\cos(x)+1$                 &                         \\ \hline
$e^{5x}$                    &                         \\ \hline
$9xe^{5x}$                  &                         \\ \hline
$x^2 \sen(3x)$              &                         \\ \hline
$e^{3x}\sen(4x)$            &                         \\ \hline
$5x^2 + x \sen(4x)$         &                         \\ \hline
$xe^x\sin(x)$               &                         \\ \hline
\end{tabular}
\end{table}
\textbf{Ejercicio: } Resuelva las siguientes EDOs de orden superior, por medio del método de coeficientes indeterminados
\begin{itemize}
\item $y''+3y'+2y = -xe^{-2x} + x^2 - 7$.
\vspace{8pt}
\item $y'''+2y''-5y'-6y = \dfrac{e^{-x}}{3}$.
\vspace{8pt}
\item $y'''-4y' = \cos^2(3x) $
\vspace{8pt}
\item $y'''+y'' = e^x \cos(x)$
\end{itemize}

\textbf{Ejercicios: }Resuelva los siguientes problemas de valor inicial
\begin{itemize}
\item $(D^2 - 2D + 5)y =  e^x \cos(2x)$, con las condiciones $y(0) = y'(0) = 1$.
\vspace{10pt}
\item $(D^4-D^2 - 12)y = \sen(\sqrt{3}x)$, con las condiciones $y(0)=0$, $y'(0)=y''(0)=y'''(0)=1$.
\end{itemize}
\newpage
\subsection{Método de variación de parámetros.}
En esta subsección estamos interesados en resolver ecuaciones de orden 2, de la forma
 \begin{equation}\label{eqn:11}
   y'' + p(x)y' + q(x)y = f(x)
  \end{equation}
En donde $f(x) \neq 0$ y tampoco es de la forma apropiada para aplicar anuladores o coeficientes indeterminados. La inspiración de este método proviene de la solución de la homogénea. Supongamos por un momento que la ecuación sí es homogénea, es decir que $f(x)=0$. Entonces existen dos funciones, $y_1(x)$ y $y_2(x)$, que son l.i.  y que hacen que la solución de la homogénea sea
$$y_c=C_1y_1(x) + C_2y_2(x)$$
donde $C_1,C_2$ son escalares. La idea de este método es no considerar $C_1,C_2$ como números sino como \textbf{funciones} de $x$. Esto nos ayudará a encontrar la solución particular que tendrá la forma
$$y_p = C_1(x)y_1(x) + C_2(x)y_2(x).$$
Al derivar $y_p$ dos veces, sustituir, y después de algunas manipulaciones algebraicas, llegamos a que, para encontrar $C_1(x)$ y $C_2(x)$ es necesario resolver el sistema
$$\begin{cases}
y_1C_1' + y_2C_2' = 0\\
y_1'C_1' + y_2'C_2'  = f(x)
\end{cases}.$$
Despejando, se obtiene que 
$$C_1' = \frac{-C_2'y_2}{y_1}$$
y sustituyendo esto en la otra ecuación del sistema tenemos
$$\left(\frac{-C_2'y_2}{y_1}\right)y_1' + y_2'C_2'  = f(x).$$
Despejando $C_2$ e integrando (recordemos que $C_2 = C_2(x)$), obtenemos que
$$C_2(x) = \int \frac{y_1(x)f(x)}{y_2(x)'y_1(x) - y_1(x)'y_2(x)}dx,$$
y por último, note que el denominador de la fracción es precisamente el Wronskiano de $y_1,y_2$, por lo que
$$C_2(x) = \int \frac{y_1(x)f(x)}{W(y_1,y_2)(x)}dx.$$
Aplicando el mismo procedimiento, pero despejando $C_1$, se obtiene que
$$C_1(x) = \int \frac{-y_2(x)f(x)}{W(y_1,y_2)(x)}dx.$$
En resumen, tenemos el siguiente teorema. \\
\textbf{Teorema: }Considere la ecuación diferencial \eqref{eqn:11}, con sistema fundamental de soluciones $\{y_1,y_2\}$. La solución general de la ecuación es dada por
$$y(x)=Ay_1(x) + By_2(x) + C_1(x)y_1(x) + C_2(x)y_2(x)$$
en donde $A,B \in \mathbb{C}$, y
$$C_1(x) = \int \frac{-y_2(x)f(x)}{W(y_1,y_2)(x)}dx \quad , \quad C_2(x) = \int \frac{y_1(x)f(x)}{W(y_1,y_2)(x)}dx.$$
El método de variación de parámetros es muy poderoso, siempre y cuando podamos encontrar el sistema de soluciones fundamentales (las 2 soluciones l.i. que generan el espacio solución)\\
\textbf{Ejemplo: }Considere la ecuación 
$$y'' - 2y' + y = e^x \ln(x).$$
Comenzamos igual que siempre, como se trata de coeficientes constantes, es fácil calcular la solución complementaria
$$y_c = Ae^x + Bxe^x$$
de donde solamente nos interesa tomar el sistema fundamental:
$$y_1 = e^x  \ ; \ y_2 = xe^x.$$
Podemos calcular el Wronskiano de una vez
$$W(e^x,xe^x)(x) = \det \begin{pmatrix*}
e^x & xe^x \\
e^x & (x+1)e^x\\
\end{pmatrix*} = e^{2x}.$$
Ahora, podemos aplicar la variación de parámetros, usando las fórmulas para $C_1$ y $C_2$.
\begin{align*}
C_1 &=  \int \frac{-y_2(x)f(x)}{W(y_1,y_2)(x)}dx = \int \frac{-xe^x e^x \ln(x)}{e^{2x}}dx = \int -x\ln( x )dx = \frac{x^2(1-2\ln(x))}{4} \\
\vspace{8pt}
C_2 &=\int \frac{y_1(x)f(x)}{W(y_1,y_2)(x)}dx = \int \frac{e^x e^x \ln(x) }{e^{2x}} = \int \ln(x)dx ) =  x \ln(x) - x
\end{align*}
Ambas integrales se calculan usando integración por partes. Además, omitimos las constantes de integración pues en caso de agregarlas, redundarían con los parámetros finales $A$ y $B$. Gracias al teorema, encontramos rápidamente la solución general a la ecuación
$$y=y_c + y_p = Ae^x + Bxe^x + \left(\frac{x^2(1-2\ln(x))}{4} \right)e^x + (x\ln(x) - x)xe^x$$
la cual, después de agrupar un poco, queda como 
$$y= Ae^x + Bxe^x - \frac{3}{4}x^2e^x + \frac{1}{2}x^2 \ln(x)e^x.$$
Notemos que esta última ecuación solo puede ser resuelta con este método, pues no es posible encontrar un anulador para la función $e^x \ln(x)$, ni tampoco es posible plantear una candidata de $y_p$ con coeficientes indeterminados, pues tendríamos que adivinar que la solución tiene la forma $Ax^2 e^x + Bx^2 \ln(x) e^x$, lo cual simplemente no es viable en general. Este método no tiene variantes, pero presentamos otro ejemplo.\\
\textbf{Ejemplo: } Calcule la solución general de la ecuación
$$4y'' + 36y = \csc (3x).$$
Si intentamos aplicar el método de variación de una vez, incurriremos en un error, pues siempre debemos escribir la ecuación con un coeficiente principal de 1:
$$y'' + 9y = \frac{\csc(3x)}{4}.$$
La solución complementaria se calcular igual que siempre (en este caso tenemos raíces complejas).
$$y_c = A\sen(3x) + B\cos(3x)$$
de donde deducimos que $y_1 = \sen(3x)$ y que $y_2 = \cos(3x)$. Su Wronskiano es
$$W(\sen(3x), \cos(3x)) = \det \begin{pmatrix*}
\sen(3x) & \cos(3x) \\
-3\cos(3x) & 3\sen(3x)
\end{pmatrix*} = -3.$$
Aplicando el teorema, se obtiene que
\begin{align*}
C_1 &=  \int \frac{-\cos(3x)\csc(3x)}{-12}  =  \frac{1}{36} \ln(\sen(3x))\\
C_2 &=\int \frac{\sen(3x)\csc(3x)}{-12}dx = -\frac{x}{12}
\end{align*}
Por lo que la solución general es
$$y = A\sen(3x) + B\cos(3x) + \frac{\ln(\sen(3x))\sen(3x)}{36}- \frac{x\cos(3x)}{12}.$$
\textbf{Nota: }No importa en qué orden se escojan $y_1$ y $y_2$ pero sí es importante no confundirlas una vez hayan sido escogidas. Esto ocasionaría errores de signos pues se cumple la identidad $$W(y_1,y_2)=-W(y_2,y_1).$$ \pagebreak\\
\textbf{Ejercicio: }Resuelva las siguientes ecuaciones diferenciales y problemas de valor inicial, utilizando el método de variación de parámetros.
\begin{itemize}
\item $y''-2y' + y = \dfrac{e^x}{1+x^2}$.
\vspace{10pt}
\item $y'' - y = \frac{1}{x}$. \textit{Nota: }si aparecen integrales no elementales, puede dejarlas en forma integral.
\vspace{10pt}
\item $x''(t) + 3x'(t) + 2x(t) = \sen(e^-t).$
\item $y'' + y = \cot(x)$, bajo la condición $y(\pi/4)= y'(\pi/4)=0$.
\vspace{10pt}
\item $x^2y'' - xy' + y = \dfrac{x}{1+\ln^2(x)}$ con las condiciones $y(1) = y(e) =0$, sabiendo que una solución particular es $y=x$. \textit{Sugerencia: } Esta ecuación no tiene coeficientes constantes, para encontrar la otra solución l.i. puede utilizar la fórmula de Abel.
\end{itemize}
\subsection{Ecuación de Cauchy-Euler}
Para concluir con el tema de EDOs de orden superior, estudiaremos el método de solución para las ecuaciones de \textit{Cauchy-Euler}, las cuales tienen la forma

 \begin{equation}\label{eqn:120}
  a_nx^ny^{(n)} + a_{n-1}x^{n-1}y^{(n-1)} + \dots + a_1xy' + a_0y=0.
  \end{equation}
En donde $a_0,a_1,\dots,a_n$ son constantes. Es decir, estas ecuaciones tienen coeficientes variables, pero estos coeficientes tienen un patrón, pues el coeficiente que acompaña la $k$-ésima derivada de $y$ es simplmente $x^k$.\\
Para resolver este tipo de ecuación, debemos aplicar el cambio de variable $x=e^u$, de donde $\frac{dx}{du}=x$, la cual convierte a la ecuación en una de coeficientes constantes, que debe ser resuelta por alguno de los otros métodos que hemos estudiado.\\
\textbf{Ejemplo: }Considere la ecuación de segundo orden
$$x^2y'' +bxy' + cy = 0.$$
Tomando el cambio de variable $x=e^u$ (o equivalentemente $ u= \ln(x)$), debemos calcular ahora las dos primeras derivadas de $y$ con respecto a $u$. Debemos usar la regla de la cadena,
$$\frac{dy}{du} = \frac{dy}{dx}\frac{dx}{du}=x\frac{dy}{dx} = xy',$$
y derivando de nuevo con respecto a $u$ (hay que aplicar la regla del producto, y la regla de la cadena de nuevo),\pagebreak
$$\frac{d^2y}{du^2}=\frac{dx}{du}\frac{dy}{dx} + x \frac{d^2y}{dx^2}\frac{dx}{du} = xy' + x^2y''.$$
Utilizando estas dos igualdades, podemos despejar $y''$ y $y'$, para obtener
\begin{align*}
y' &= \frac{1}{x} \frac{dy}{du} \\
y'' &= \frac{1}{x^2} \left(\frac{d^2y}{du^2} -  \frac{dy}{du} \right)
\end{align*}
Después de sustituir y simplificar, esto convierte a nuestra ecuación en
$$\frac{d^2y}{du^2} + (b-1) \frac{dy}{du}+ cy=0$$
la cual es una EDO lineal de coeficientes constantes. Note que este cambio de variable y las manipulaciones a los diferenciales serán siempre los mismos, sin importar qué ecuación se tenga (siempre y cuando sea de orden 2).\\
\textbf{Ejemplo: } Consideremos la ecuación $$x^2y'' - xy' + y=0,$$
en donde vemos que $b=-1$ , $c=1$. Al aplicar el cambio de variable (el cual no tenemos que hacer todas las veces), la ecuación se convierte en
$$\frac{d^2y}{du^2} -2 \frac{dy}{du}+ y=0,$$
cuyas solución general viene dada por
$$y= C_1e^u - C_2ue^u,$$
y finalmente, revertiendo el cambio de variable, llegamos a 
$$y = C_1x - C_2 x \ln(x).$$
\textbf{Ejemplo: } Resolver
$$4x^2y'' + 17y = \ln(x)+1.$$
Tomando $x=e^u$, $b=0$, y $c=17/4$, la ecuación resultante después del cambio de variable es
$$\frac{d^2y}{du^2} - \frac{dy}{du} + \frac{17}{4}y = u+1$$
la cual se trata de una inhomogénea con coeficientes constantes. Su solución complementaria es
$$y_c = e^{\frac{u}{2}}(C_1\cos(2u) + C_2\sen(2u)).$$
Aplicando coeficientes indeterminados, podemos suponer que nuestra solución particular es de la forma $y_p=Au+B$, por lo que derivando y sustituyendo, obtenemos que
$$-A+\frac{17}{4}(Au+B)=u+1$$
de donde se deduce que $A=4/17$ y que $B=84/289$, por lo que la solución a la ecuación es 
$$y=y_c+y_p = e^{\frac{u}{2}}(C_1\cos(2u) + C_2\sen(2u)) + \frac{4}{17}u + \frac{84}{289}$$
y finalmente, deshaciendo el cambio de variable
$$y= \sqrt{x}(C_1\cos(\ln(x^2))+C_2\sen(\ln(x^2)))+ \frac{4}{17}\ln(x) + \frac{84}{289}.$$
\textbf{Ejercicio: }Resuelva las siguientes EDOs.
\begin{itemize}
\item $x^2y'' - 3xy' + 3y = 2x^4e^x$.
\vspace{10pt}
\item $3x^2y'' - xy' + 2y = 0$.
\vspace{10pt}
\item $x^3y'' - 4x^2y' + 6xy = \ln(x^{x^4})$.
\vspace{10pt}
\item $x^3y''' +5x^2y'' + 7xy' + 8y = 0$.
\vspace{10pt}
\end{itemize}
\newpage
\section{Ecuaciones Diferenciales y series de potencias}
En esta sección vamos a introducir un nuevo método de resolución de ecuaciones diferenciales. Para aplicar este método, debemos retomar el concepto de \textbf{serie de potencia}, el cual nos va a permitir encontrar soluciones de manera \textit{analítica.} Recordemos que una serie de potencias centrada en un número $a$ es una suma infinita de la forma
\begin{equation}\label{eqn:12}
\sum_{n=0} ^ \infty c_n(x-a)^n = c_0 + c_1(x-a) + c_2 (x-a)^2 + \dots
\end{equation}
donde $a,c_n \in \mathbb{R}$ (o incluso $\mathbb{C}$). Por ejemplo, la serie de potencias
$$\sum_{n=0}^\infty2^{n}x^n = 1+2x+4x^2 + 8x^3 + \dots$$
es una serie centrada en 0. Como observación, no es necesario que nuestras series de potencia siempre inicien en $0$, pueden iniciar desde cualquier entero positivo.\\
Las series de potencia nos ayudan a aproximar funciones, de hecho, decimos que una serie de potencias \textbf{converge a una función $f(x)$} si en algún intervalo $I \subseteq \mathbb{R}$ se cumple que 
$$f(x) = \lim_{K \to \infty} \sum_{n=0} ^ K c_n(x-a)^n , \quad \text{para todo $x \in I$}$$
o en otras palabras, si las sumas parciales de la suma se van a acercando cada vez más a un valor $f(x)$. Damos aquí rápidamente un repaso de los conceptos clave acerca de la convergencia de las series de potencia. Asumamos que nuestra serie está definida únicamente en los números reales.
\textbf{Definición: } Considere la serie de potencias \eqref{eqn:12}.
\begin{itemize}
\item \textbf{Intervalo de convergencia: }Es el intervalo de números reales $x$ donde la serie converge.
\item \textbf{Radio de convergencia: }El intervalo de convergencia $I$ se puede expresar de la forma $I = [a-R,a+R]$, donde $R \geq 0$. A este número $R$ le denominamos radio de convergencia \linebreak (si $R = \infty$, decimos que $I=\mathbb{R}$). \textbf{Nota: }el intervalo de convergencia puede ser cerrado, abierto, o incluso semiabierto en cualquier extremo. Una fórmula útil para calcular $R$ es
$$R = \lim_{n \to \infty}\left|\frac{c_{n+1}}{c_n}\right|.$$
\item \textbf{Convergencia absoluta: } Decimos que la serie \eqref{eqn:11} converge absolutamente si 
$$\sum_{n=0} ^ \infty |c_n(x-a)^n|$$
converge. Toda serie de potencias converge absolutamente dentro de su intervalo de convergencia, y diverge fuera de él.
\end{itemize}
\pagebreak
Un caso especial de las series de potencias son las series de Taylor (y Maclaurin).\\
\textbf{Definición: } Dada una función $f:\mathbb{R} \to \mathbb{R}$ infinitamente diferenciable, definimos su serie de Taylor centrada en $a$ como la suma
$$S(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n.$$
Cuando $a=0$, la llamamos serie de Maclaurin. \\
\textbf{Nota: }Es importante notar que no siempre ocurre que $S(x) = f(x)$. Sin embargo, cuando sí es el caso (es decir, cuando la serie de Taylor de $f$ sí aproxima a $f$) decimos que $f$ es una función \textbf{analítica en el punto $x$.} La gran mayoría de las funciones infinitamente diferenciables que conocemos ($e^x, \sen(x) , \ln(x)$, polinomios) son analíticas. Un ejemplo de una función no analítica es el siguiente
$$f(x) = \begin{cases}
\exp(-\frac{1}{x}) \ , \ \text{cuando } x > 0 \\
0 , \ \text{cuando } x \leq 0  \end{cases} $$
$f(x)$ no es analítica en el punto $x=0$, pues, como $f^{(n)}(0)=0$ para cualquier $n$ (puede calcular esto como ejercicio) la serie de Taylor centrada en $0$ es la suma 
$$S(x) = 0+0+0+0+\dots$$
la cual no aproxima a $f(x)$ cuando $x$ es estrictamente positivo.

\begin{figure}[h]
 \center
        \includegraphics[scale=0.80]{Recorte7.png}
        
        Gráfica de $f(x)$, una función no analítica.
\end{figure}
Vamos a conectar estos conceptos de cálculo diferencial con nuestro interés en ecuaciones diferenciales con la siguiente definición. \\
\textbf{Definición: }Considere la ecuación diferencial lineal de segundo orden
\begin{equation}\label{eqn:13}
y''+ P(x)y' + Q(x)y = 0
\end{equation}
Decimos que un punto $x_0$ es un \textbf{punto ordinario} de la ecuación \eqref{eqn:13} si ambas funciones $P$ y $Q$ son analíticas en $x_0$. Aquellos puntos que no sean ordinarios, se llaman \textbf{puntos singulares}.\pagebreak \\
\textbf{Ejemplo: } Considere la ecuación 
$$x^2y'' - 2y' + xy = 0$$
(note que ningún método de los que tenemos puede resolver esta ecuación). El punto $x=1$ es un punto ordinario de la ecuación, puesto que las funciones 
$$P(x) = -\frac{2}{x^2} \ , \ Q(x) = \frac{1}{x}$$
son ambas analíticas en $1$. Sin embargo, el punto $x=0$ es singular, puesto que $P'(0)$ y $Q'(0)$ ni siquiera se pueden definir (para que una función sea analítica, tiene que ser por lo menos infinitamente diferenciable).
\subsection{Solución en una vecindad de un punto ordinario. }
Tenemos entonces el primer teorema que nos ayuda a resolver ecuaciones por medio de series. \\
\textbf{Teorema: } Si $x_0$ es un punto ordinario de una ecuación en la forma \eqref{eqn:13}, podemos encontrar dos soluciones linealmente independientes $y_1,y_2$ en forma de series de potencias centradas en $x_0$. Estas series convergen para todo $x$ que esté entre $x_0$ y el punto singular más cercano. En otras palabras, $y_1(x)$ y $y_2(x)$ se pueden definir siempre y cuando $|x-x_0|<r$, donde $r$ es la distancia entre $x_0$ y el punto singular más cercano. \\
Este teorema nos dice que, si $a$ es un punto ordinario, podemos declarar una solución candidata de la forma
$$y(x)= \sum_{n=0}^{\infty} c_n (x-a)^n.$$
Y por lo tanto, si logramos despejar de alguna forma los coeficientes $c_n$, tendremos nuestra solución en forma de serie.\\ 
\textbf{Ejemplo: } Resuelva la ecuación $$y'' + xy= 0.$$
Note que ninguno de nuestros métodos estudiados hasta el momento funciona para resolver esta ecuación. Procederemos por series de potencias: puesto que no hay puntos singulares, podemos escoger cualquier punto (escogeremos $0$ por ser el más cómodo) como centro de nuestra serie de potencias, y ésta misma va a converger en todo $\mathbb{R}$ por el teorema anterior. Suponemos entonces que nuestra solución tiene la forma de una serie centrada en $0$
$$y = \sum_{n=0}^\infty c_nx^n = c_0 + c_1x + c_2x^2 + \dots.$$ \pagebreak
La idea de éste método es la siguiente: como estamos asumiendo que $y$ es solución, al derivarla y sustituirla en la ecuación diferencial, tendremos suficiente información para despejar los coeficientes $c_n$. En cierta forma podemos pensar en este método como una especie de coeficientes indeterminados \textit{infinitos}. Derivando, obtenemos que 
$$y''  = 0+0+2c_2 + 6c_3 x \dots = \sum_{n=2}^\infty c_n n (n-1)x^{n-2} = \sum_{n=0}^\infty c_{n+2} (n+2)(n+1)x^n$$
donde, en el último paso, cambiamos el índice para volver a iniciar en $n=0$. Como sabemos que $y'' + xy = 0$, tenemos que
\begin{alignat*}{2}
&& y'' + xy =  \sum_{n=0}^\infty c_{n+2} (n+2)(n+1)x^n+ x\sum_{n=0}^\infty c_nx^n &= 0 \\
\Rightarrow&& \sum_{n=0}^\infty c_{n+2} (n+2)(n+1)x^n  +  \sum_{n=0}^\infty c_nx^{n+1} &= 0 \\
\Rightarrow&& \sum_{n=0}^\infty c_{n+2} (n+2)(n+1)x^n  + \sum_{n=1}^\infty c_{n-1}x^{n} &= 0 \\
\Rightarrow&&  2c_2 + \sum_{n=1}^\infty c_{n+2} (n+2)(n+1)x^n + \sum_{n=1}^\infty c_{n-1}x^{n} &= 0. 
\end{alignat*}
En el primer paso, simplemente multiplicamos por $x$ la segunda suma. En el segundo paso, modificamos el índice de la segunda suma para que inicie en $n=1$. Finalmente, en el tercer paso, sacamos el primer término de la primera suma para que comience también en $n=1$. La razón por la que manipulamos las series de esta forma es para poder \textit{sumarlas de manera conveniente}, es decir, queremos que ambas series inicien en el mismo $n$, y tengan la misma potencia de $x$ en su término $n$-ésimo. Así, obtenemos la fórmula más manejable
$$2c_2 + \sum_{n=1}^\infty [c_{n+2}(n+2)(n+1) + c_{n-1}]x^n = 0.$$
A partir de aquí, debemos comparar coeficientes a cada lado de la igualdad (justo como se haría si tuviéramos coeficientes indeterminados), para encontrar los valores de $c_n$. Como el lado de la derecha es $0$, obtenemos que todos los coeficientes de todas las potencias de $x$ deben ser $0$. Es decir
$$\begin{cases}
c_2 = 0 \\
c_{n+2}(n+2)(n+1) + c_{n-1} = 0 , \text{ para todo } n \geq 1.
\end{cases}$$
A partir de aquí, para despejar las demás $c_n$'s, debemos utilizar una \textbf{relación de recurrencia}: Note que $c_{n+2}$ puede encontrase a partir de $c_{n-1}$, de la forma
$$c_{n+2} = \frac{-c_{n-1}}{(n+2)(n+1)}$$
De manera intuitiva, esto nos dice que las $c_n$'s están determinadas \textit{de tres en tres}, puesto que a partir de $c_0$, esta recurrencia nos permite calcular $c_3$ , $c_6$ , $c_9$, ...etc, de manera sucesiva. De igual forma, si tenemos $c_1$, ésta nos permite calcular $c_4$ , $c_7$ , $c_{10}$ ...etc,  de manera sucesiva, y de manera análoga, si tenemos $c_2$, podemos calcular $c_5$ , $c_8$ , $c_{11}$, ...etc. Más formalmente, obtenemos que, iniciando a partir de $c_0$, se tiene que 
\begin{align*}
c_3 &= \frac{-c_0}{3 \cdot 2} \\
c_6&= \frac{-c_3}{6 \cdot 5} =  \frac{c_0}{2 \cdot 3  \cdot 5  \cdot 6 }  \\
c_9 &= \frac{-c_6}{9 \cdot 8} =  \frac{-c_0}{2 \cdot 3  \cdot 5  \cdot 6\cdot 8\cdot 9 } \\
\vdots \\
c_{3n} &= \frac{4 \cdot 7 \cdot 10\cdots (3n-2) }{(3n)!} (-1)^n c_0
\end{align*}
Partiendo ahora de $c_1$, obtenemos
\begin{align*}
c_4 &= \frac{-c_1}{4 \cdot 3} \\
c_7&= \frac{-c_4}{7 \cdot 6} =  \frac{c_1}{3 \cdot 4  \cdot 6  \cdot 7 }  \\
c_{10} &= \frac{-c_7}{10 \cdot 9} =  \frac{-c_1}{3 \cdot 4  \cdot 6  \cdot 7\cdot 9\cdot 10 } \\
\vdots \\
c_{3n+1} &= \frac{2 \cdot 5 \cdot 8\cdots (3n-1) }{(3n+1)!} (-1)^n c_1
\end{align*}
Podríamos también formar los coeficientes a partir de $c_2$, pero como ya sabemos que $c_2=0$, obtenemos de inmediato que $c_{3n+2} = 0$ para todo $n$, es decir $c_2 = c_5 = c_8 = \dots = 0$. Hemos entonces encontrado todos los coeficientes de la serie (los cuales son infinitos), salvo $c_0$ y $c_1$. Tenemos entonces nuestra serie
$$y = c_0 + c_1x +0x^2 - \frac{c_0}{3 \cdot 2}x^3 -  \frac{c_1}{4 \cdot 3}x^4 + 0x^5 +  \frac{c_0}{2 \cdot 3  \cdot 5  \cdot 6 }x^6 +  \frac{c_1}{3 \cdot 4  \cdot 6  \cdot 7 } x^7 + \dots$$
en la cual podemos agrupar términos multiplicados por $c_0$ y $c_1$ respectivamente, para obtener 
$$y = c_0 \underbrace{\left(1-\frac{x^3}{3 \cdot 2}  + \frac{x^6}{2 \cdot 3  \cdot 5  \cdot 6 } - \dots \right)}_{y_0}  + c_1 \underbrace{\left(x - \frac{x^4}{4 \cdot 3} +  \frac{x^7}{3 \cdot 4  \cdot 6  \cdot 7 } - \dots \right)}_{y_1},$$ 
para obtener finalmente nuestra solución general 
$$y= c_0y_0(x) + c_1y_1(x).$$ 
Los valores de $c_0$, $c_1$ no se determinan, puesto que cualquier valor que les demos, ¡Producirán soluciones a la ecuación! Es por esta razón que la solución queda con $2$ parámetros, lo cual coincide perfectamente con lo que hemos aprendido, pues la ecuación es lineal de orden 2. Es buena práctica expresar finalmente a $y_0 ,y_1$ usando la notación sigma. La solución general a la ecuación $y'' + xy =0$ es entonces
$$y = c_0y_0(x) + c_1y_1(x)$$
donde
\begin{align*}
y_0(x) &=  \sum_{n=0} ^\infty \frac{4 \cdot 7 \cdot 10\cdots (3n-2) }{(3n)!} (-1)^n  x^{3n} \\
y_1(x) &= \sum_{n=0}^\infty \frac{2 \cdot 5 \cdot 8\cdots (3n-1) }{(3n+1)!} (-1)^n  x^{3n+1}
\end{align*}
En general es difícil pasar de la expresión en serie a una expresión elemental (trigonométrica, exponencial, logaritmo, etc). De hecho, la mayoría de soluciones analíticas no tienen expresión elemental. En la siguiente gráfica podemos ver las soluciones independientes a la ecuación.

\begin{figure}[h]
 \center
        \includegraphics[scale=0.5]{Recorte8.png}
        
        Soluciones fundamentales de la ecuación $y'' + xy = 0$. Ambas soluciones están definidas en todo $\mathbb{R}$.
\end{figure}
\textbf{Ejemplo: }Encuentre la solución del problema de valor inicial
$$(x^2-1)y'' + 4xy' + 2y = 0 \ , \ \text{con } y(0)=y'(0)=1$$
Vamos de nuevo a aplicar un desarrollo en series de potencias. Note que los puntos singulares de esta ecuación son $1$ y $-1$, por lo que, si tomamos una serie de potencias centrada en cero, nuestra solución convergerá para todo $x$ en el intervalo $]-1,1[$. Sea entonces 
$$y= \sum_{n=0}^\infty c_n x^n $$
nuestra candidata a solución, debemos despejar los $c_n$'s. Derivando, y luego de acomodar los índices podemos ver que
$$y' = \sum_{n=0}^\infty (n+1)c_{n+1}x^{n} \ \text{y que} \ y'' = \sum_{n=0}^\infty c_{n+2}(n+2)(n+1)x^n $$
Al sustituir en la ecuación, se obtiene que 
\begin{alignat*}{2}
&& (x^2-1)\sum_{n=0}^\infty c_{n+2}(n+2)(n+1)x^n + 4x\sum_{n=0}^\infty c_{n+1}(n+1)x^{n} + 2\sum_{n=0}^\infty c_n x^n &= 0 \\
\Rightarrow&& \sum_{n=0}^\infty c_{n+2}(n+2)(n+1)x^{n+2} - \sum_{n=0}^\infty c_{n+2}(n+2)(n+1)x^{n} + \sum_{n=0}^\infty 4c_{n+1} (n+1)x^{n+1} + \sum_{n=0}^\infty 2c_nx^n &=0,
\end{alignat*}
luego de reindexar para obtener potencias iguales, obtenemos
\begin{alignat*}{2}
&& \sum_{n=2}^\infty c_nn(n-1)x^n -   \sum_{n=0}^\infty c_{n+2}(n+2)(n+1)x^{n} +  \sum_{n=1}^\infty  4c_n n x^n + \sum_{n=0}^\infty 2c_n x^n = 0.
\end{alignat*}
A partir de aquí, podemos ver que para poder sumar estas series, debemos extraer de las sumatorias, los siguientes sumandos: los primeros 2 en la segunda suma, el primero en la tercera suma, y los primeros 2 en la cuarta suma. Haciendo esto, obtenemos
$$-2c_2 - 6c_3x + 4c_1x +2c_0 + 2c_1x + \sum_{n=2}^\infty [c_nn(n-1) - c_{n+2}(n+2)(n+1) + 4c_nn + 2c_n]x^n = 0$$
lo cual se puede reescribir mejor como
$$2(c_0 - c_2)  + (6c_1 - 6c_3)x + \sum_{n=2}^\infty[(n^2+3n+2)c_n - (n^2+3n+2)c_{n+2}]x^n = 0.$$
Al comparar coeficientes, obtenemos el sistema de recurrencias
$$\begin{cases}
c_0 - c_2 = 0 \\
6c_1-6c_3 = 0 \\
(n^2 + 3n + 2)c_n - (n^2 + 3n +2)c_{n+2} = 0
\end{cases}$$
El cual es más sencillo de resolver que el del ejemplo pasado. Notemos que tenemos de inmediato que $c_0=c_2$, y que $c_1=c_3$. Además, la última ecuación nos dice que para todo $n$, $c_n = c_{n+2}$. O sea que en este caso, las soluciones vienen dadas \textit{de dos en dos}. En este caso, partiendo de $c_0$, obtenemos que
$$c_2=c_4=c_6=\dots = c_0$$
y partiendo de $c_1$, obtenemos 
$$c_3 = c_5 = c_7 = \dots =  c_1.$$
Hemos hallado entonces todos los coeficientes, salvo los parámetros $c_0$ y $c_1$. Obtenemos entonces la solución general
\begin{align*}
y &= c_0 + c_1x + c_2x^2 + c_3x^3 + c_4x^4 + \dots \\
&= c_0 + c_1x + c_0x^2 + c_1x^3 + c_0x^4 + \dots\\
&= c_0 (1+x^2 + x^4 + \dots) + c_1(x + x^3 + x^5 + \dots) \\
&= c_0 y_0(x) + c_1y_1(x)
\end{align*}
En donde 
$$y_0(x) = \sum_{n=0}^\infty x^{2n}  \ \text{y} \ y_1(x) = \sum_{n=0}^\infty x^{2n+1}.$$ 
Finalmente, como nos dan la condición inicial $y(0) = y'(0) = 1$, tenemos que, derivando término a término, $y(0)=c_0 \Rightarrow c_0=1$ y que 
$y'(0) = c_1 \Rightarrow c_1 = 1$
por lo que finalmente nuestra solución es
$$y = \sum_{n=0}^{\infty}x^n = \frac{1}{1-x}$$
la cual está definida para $x \in (-1,1)$. En la siguiente figura podemos observar la gráfica de la solución de nuestro problema de valor inicial. Podemos observar que como $-1$ y $1$ son puntos singulares, la solución analítica no se define fuera del intervalo. 

\begin{figure}[h]
 \center
        \includegraphics[scale=0.6]{Recorte9.png}
        
        Solución al problema de valor inicial
\end{figure} \pagebreak
\textbf{Ejemplo: }Resuelva la ecuación 
$$y'' + (\cos x)y = 0.$$
Una vez más, tomamos $y = \sum_{n=0}^\infty c_nx^n$. 
Centraremos alrededor de 0 por comodidad, pues no hay puntos singulares. Tenemos entonces que usar la serie de Taylor para $\cos(x)$, que es analítica.
\begin{alignat*}{2}
&& y'' + (\cos x)y &= \sum_{n=2}n(n-1)c_nx^{n-2} + \left(1-\frac{x^2}{2!} + \frac{x^4}{4!} - \dots \right)\sum_{n=0}^\infty c_nx^n = 0\\
\Rightarrow&&  &=2c_2 + 6c_3x + 12c_4x^2 + 20c_5x^3+ \dots +  \left(1-\frac{x^2}{2!} + \frac{x^4}{4!} - \dots \right) (c_0 + c_1x + c_2x^2  + \dots) = 0
\end{alignat*}
A partir de aquí debemos agrupar los coeficientes según cuál potencia de $x$ acompañen. Vamos a calcular los primeros $5$, puesto que la relación de recurrencia que se necesita para calcularlos todos es considerablemente complicada. En otras palabras, vamos a truncar el desarrollo de Taylor de $\cos(x)$ para calcular los primeros coeficientes de la serie. Retomando la ecuación, tenemos
$$y'' + (\cos x)y = (2c_2+c_0) + (6c_3 + c_1)x + (12c_4 + c_2 - \frac{1}{2}c_0)x^2 + (20c_5 + c_3 - \frac{1}{2}c_1)x^3 + \dots = 0.$$
Entonces, comparando coeficientes, obtenemos el sistema de ecuaciones
$$\begin{cases}
2c_2 + c_0 = 0 \\
6c_3 + c_1 = 0 \\
12c_4 + c_2 - \frac{1}{2}c_0 = 0 \\
20c_5 + c_3 - \frac{1}{2}c_1 = 0
\end{cases}$$
cuya solución es $c_2 = -c_0/2$ , $c_3 = -c_1/6$ , $c_4 = c_0/12$, y $c_5 = c_1/30$. Al agrupar los términos de la serie, obtenemos finalmente que la solución general (hasta donde la pudimos calcular), es
$$y= c_0y_0(x) + c_1y_1(x)$$
donde
$$y_0(x) = 1-\frac{1}{2}x^2 + \frac{1}{12}x^4 + \dots \ \text{ y } \ y_2(x)=x- \frac{1}{6}x^3 + \frac{1}{30}x^5 + \dots$$ \vspace{10pt}
\subsection{Solución en un vecindario de un punto singular regular.}
También podemos resolver ecuaciones diferenciales de la forma \eqref{eqn:13} centrando nuestra serie alrededor de un punto singular, pero debemos tener ciertas precauciones.\\
\textbf{Definición: }Sea $x_0$ un punto singular de la ecuación $y''+ P(x)y' + Q(x)y = 0$, Decimos que $x_0$ es un \textbf{punto singular regular} si las funciones
$$p(x) = (x-x_0)P(x) \ , \ q(x) = (x-x_0)^2Q(x)$$
son ambas analíticas en $x_0$. Los puntos singulares que no son regulares, los llamaremos puntos \textbf{irregulares.}\\
\textbf{Ejemplo: } Para la ecuación 
$$(x^2 -4)^2y'' + 3(x-2)y' + 5y = 0$$
es evidente que $x_0=2$ y $x_1=-2$ son ambos puntos singulares. Sin embargo, note que, estudiando primero $x_0=2$,
\begin{align*}
p(x) &= (x-2)P(x) = \frac{3(x-2)^2}{(x^2-4)^2} = \frac{3}{(x+2)^2} \\
q(x) &= (x-2)^2Q(x) = \frac{5(x-2)^2}{(x^2-4)^2}= \frac{5}{(x+2)^2}.
\end{align*}
Como ambas funciones $p(x),q(x)$ son analíticas en $x=2$, concluimos que $2$ es un punto singular regular. Veamos qué pasa con $-2$,

\begin{align*}
p(x) &= (x+2)P(x) = \frac{3(x+2)(x-2)}{(x^2-4)^2} = \frac{3}{(x+2)(x-2)}.
\end{align*}
Esta función no es analítica en $x=-2$, por lo que el punto $-2$ es singular irregular (no necesitamos revisar $q(x)$).\\
Tenemos entonces el teorema que nos ayudará a resolver la ecuaciones con puntos singulares. \\
\textbf{Teorema (Método de Frobenius): }Si $x=x_0$ es un punto singular regular de la ecuación diferencial 
$$y''+P(x)y' + Q(x)y =0,$$ entonces existe al menos una solución de la forma
$$y=\sum_{n=0}^{\infty} c_n(x-x_0)^{n+r}.$$
La serie convergerá en algún intervalo $(x_0-R,x_0+R)$, con $R>0$. Para encontrar $r$, debemos resolver la \textbf{ecuación indicial}, dada por
$$r(r-1) + p_0r + q_0 = 0$$
donde
$$p_0 = \lim_{x \to x_0} (x-x_0)p(x) \quad \text{y} \quad q_0 = \lim_{x \to x_0} (x-x_0)^2q(x).$$
Dependiendo de las dos soluciones de la ecuación indicial, las soluciones se construyen de distintas formas:
\begin{itemize}
\item \textbf{Caso 1:} Cuando $r_1-r_2 \notin \mathbb{Z}$, tenemos dos soluciones l.i de la forma
$$y_1(x) = \sum_{n=0}^\infty c_n x^{n+r_1} \quad \text{y} \quad y_2(x) = \sum_{n=0}^\infty b_n x^{n+r_2} $$
\item \textbf{Caso 2:} Si $r_1-r_2 \in \mathbb{Z}$, las soluciones son 
$$y_1(x) = \sum_{n=0}^\infty c_n x^{n+r_1} \quad \text{y} \quad y_2(x) = Ay_1(x)\ln(x) + \sum_{n=0}^\infty b_n x^{n+r_2} $$
donde $A$ es una constante a determinar (la cual podría ser incluso $0$). En el caso especial cuando $r_1=r_2$, tenemos que $A=1$.
\end{itemize}
\textbf{Ejemplo: } Resuelva la ODE siguiente
$$3xy'' + y' - y = 0.$$
Primero, reescribimos:
$$y'' + \frac{y'}{3x} - \frac{y}{3x} = 0,$$
de donde podemos observar de inmediato que $x_0 = 0$ es un punto singular regular, en efecto:
\begin{align*}
p(x) = \frac{x}{3x} &= \frac{1}{3}\\
q(x) = -\frac{x^2}{3x} &=  -\frac{x}{3}
\end{align*}
ambas funciones analíticas en $0$ (y en todo $\mathbb{R}$). Entonces procedemos a resolver la ecuación indicial. Como
$$p_0=\lim_{x \to 0} p(x) = \frac{1}{3} \quad \text{y} \quad q_0 = \lim_{x \to 0} q(x) = 0,$$
debemos resolver la ecuación
$$r(r-1) + \frac{r}{3} = 0.$$
Las raíces de esta ecuación son $r_1= 0$ y $r_2= 2/3$, por lo que debemos proceder como en el caso 1. Proponemos dos soluciones de la forma
$$y_1(x) = \sum_{n=0}^\infty c_n x^n \quad \text{y} \quad \sum_{n=0}^\infty b_n x^{n+2/3}.$$
Ahora lo que queda es despejar tanto los coeficientes $c_n$'s como los $b_n$'s. Primero, despejemos los $c_n$. Derivando $y_1$ y sustituyendo en la ecuación, obtenemos
\begin{alignat*}{2}
&&3x \sum_{n=2}^\infty n(n-1) c_n x^{n-2} + \sum_{n=1}^\infty n c_n x^{n-1} - \sum_{n=0}^\infty c_n x^n &= 0 \\
\Rightarrow&&  \sum_{n=2}^\infty 3 n(n-1)c_n x^{n-1} +  \sum_{n=1}^\infty n c_n x^{n-1} - \sum_{n=0}^\infty c_n x^n &= 0 \\
    \Rightarrow&&  \sum_{n=1}^\infty 3 n(n+1)c_{n+1} x^{n} +  \sum_{n=0}^\infty (n+1)c_{n+1} x^{n} -  \sum_{n=0}^\infty c_n x^n &= 0 \\
     \Rightarrow&&  \sum_{n=1}^\infty 3 n(n+1)c_{n+1} x^{n} + c_1 +  \sum_{n=0}^\infty (n+1)c_{n+1} x^{n} - c_0 -  \sum_{n=1}^\infty c_n x^n &= 0
     \\
    \Rightarrow&& (c_1-c_0) +   \sum_{n=1}^\infty ((n+1)(3n+1)c_{n+1} - c_n) x^n &= 0
\end{alignat*}
Tenemos la recurrencia $$c_0 = c_1 \ \text{ y } \ c_{n+1} = \frac{c_n}{(n+1)(3n+1)}$$
por lo que, escribiendo y observando el patrón (puede realizar esto como ejercicio), vemos que en general, para todo $n \geq 1$,
$$c_n = \frac{c_0}{(n!) \cdot 1 \cdot 4 \cdot 7 \cdot (3n-2)}$$
por lo que
$$y_1(x) = \left(1+ \sum_{n=1}^\infty \frac{x^n}{(n!)\cdot 1 \cdot 4 \cdot 7 \cdots (3n-2)} \right)$$
donde hemos omitido el parámetro $c_0$, ya que queremos una solución particular (el parámetro volverá con la solución general).\\
Aún nos falta encontrar los coeficientes de $y_2(x)$. Derivando y sustituyendo, obtenemos que

\begin{alignat*}{2}
&&3x \sum_{n=0}^\infty \left(n+\frac{2}{3}\right)\left(n-\frac{1}{3}\right) b_n x^{n-4/3} + \sum_{n=0}^\infty \left(n+\frac{2}{3}\right) b_n x^{n-1/3} - \sum_{n=0}^\infty b_n x^{n+2/3} &= 0 \\
\Rightarrow&&  \sum_{n=0}^\infty 3 \left(n+\frac{2}{3}\right)\left(n-\frac{1}{3}\right)b_n x^{n-1/3} + \sum_{n=0}^\infty \left(n+\frac{2}{3}\right) b_n x^{n-1/3} - \sum_{n=0}^\infty b_n x^{n+2/3} &= 0 \\
    \Rightarrow&&  \sum_{n=0}^\infty 3 \left(n+\frac{2}{3}\right)\left(n-\frac{1}{3}\right)b_n x^{n-1/3} +  \sum_{n=0}^\infty \left(n+\frac{2}{3}\right) b_n x^{n-1/3} -  \sum_{n=1}^\infty b_{n-1} x^{n-1/3} &= 0 \\
      \Rightarrow&& -\frac{2}{3}(b_0-b_0) + \sum_{n=1}^\infty 3 \left(n+\frac{2}{3}\right)\left(n-\frac{1}{3}\right)b_n x^{n-1/3} +  \sum_{n=1}^\infty \left(n+\frac{2}{3}\right) b_n x^{n-1/3} -  \sum_{n=1}^\infty b_{n-1} x^{n-1/3} &= 0
     \\
    \Rightarrow&& \sum_{n=1}^\infty (n(3n+2)b_{n} - b_{n-1}) x^{n-1/3} = 0 \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad &\quad
\end{alignat*}
Observe que al derivar esta candidata a solución, los primeros términos de la serie no se anulan, por lo que en el primer paso todas las series inician en $n=0$.
Obtenemos a partir de aquí la recurrencia
$$b_{n} = \frac{b_{n-1}}{n(3n+2)} \ \text{ para $n \geq 1$}.$$
la cual se puede dar explícitamente como
\begin{align*}
b_n &= \frac{b_0}{(n!)\cdot 5 \cdot 8 \cdot 11 \cdots (3n+2)} \text{ para $n \geq 1$}
\end{align*}
de donde obtenemos la segunda solución, donde de nuevo omitimos el parámetro libre
$$y_2(x) = x^{2/3} \left(1+ \sum_{n=1} ^\infty \frac{x^n}{(n!)\cdot 5 \cdot 8 \cdot 11 \cdots (3n+2)}  \right).$$
Nuestra solución general es finalmente dada por
$$y(x) = Ay_1(x) + By_2(x)$$
donde $A,B$ son los 2 parámetros (también pudimos poner $c_0$ y $b_0$).\\
\textbf{Ejemplo: }Considere la ecuación
$$x(x-1)y'' + 3xy' + y = 0$$
Dejamos como ejercicio verificar que $x_0 = 0$ es un punto singular regular de la ecuación ($x_1=1$ también lo es). Vamos a resolver usando series centradas en $0$, una vez más por comodida. Además, la ecuación indicial viene dada simplemente por  $r(r-1)=0$, por lo que $r_1=0$,$r_2=1$. Debemos proceder como en el caso 2. Tomamos $y_1(x) = \sum_{n=0}^\infty c_nx^n$, derivando y sustituyendo en la ecuación obtenemos que
\begin{alignat*}{2}
&& x(x-1)\sum_{n=2}^\infty c_n n(n-1) x^{n-1}  + 3x \sum_{n=1}^\infty c_nnx^{n-1} + \sum_{n=0}^\infty c_nx^n &= 0 \\
\Rightarrow&& \sum_{n=2}^\infty c_nn(n-1)x^n - \sum_{n=2}^\infty c_nn(n-1)x^{n-1} + \sum_{n=1}^\infty 3c_nnx^n + \sum_{n=0}^\infty c_nx^n &=0\\
\Rightarrow&& \sum_{n=2}^\infty c_nn(n-1)x^n - \sum_{n=1}^\infty c_{n+1}n(n+1)x^{n} + \sum_{n=1}^\infty 3c_nnx^n + \sum_{n=0}^\infty c_nx^n &=0\\
\Rightarrow&&
c_0 + (4c_1 - 2c_2)x + \sum_{n=2}^\infty c_nn(n-1)x^n - \sum_{n=2}^\infty c_{n+1}n(n+1)x^{n} + \sum_{n=2}^\infty 3c_nnx^n + \sum_{n=2}^\infty c_nx^n &=0 \\ 
\Rightarrow&&
c_0 + (4c_1 - 2c_2)x + \sum_{n=2}^{\infty}((n+1)^2 - n(n+1)c_{n+1})x^n =0. \quad \quad \quad \quad \quad   \quad &\quad
\end{alignat*}
Tenemos entonces la relación de recurrencia $c_0= 0$ , $c_{n+1} = c_n \frac{n+1}{n}$, la cual se puede resolver explícitamente como
$$c_0 = 0 \ ; \ c_n= nc_1,$$
lo cual nos permite deducir que
$$y_1(x) = \sum_{n=1}^\infty n x^n = x \sum_{n=1}^\infty nx^{n-1} = \frac{x}{(1-x)^2}$$
donde la última igualdad se obtiene derivando la serie geométrica $\sum x^n = 1/(1-x)$. Para obtener $y_2$, podemos aplicar el mismo procedimiento (derivar, sustituir y despejar) con la candidata
$$y_2(x) = Ay_1(x)\ln(x) + \sum_{n=0}^\infty b_nx^n.$$
Sin embargo, podemos usar simplemente la fórmula de Abel:
$$y_2(x) = y_1(x) \int \frac{\exp(-\int \frac{3dx}{x-1})}{y_1^2(x)}dx = \frac{x}{(1-x)^2}\int \frac{(x-1)^{-3}}{\frac{x^2}{(1-x)^4}}dx = \frac{x}{(1-x)^2}\int \frac{1-x}{x^2}dx = -\frac{1+x \ln x}{(1-x)^2}.$$
Tenemos finalmente la solución general
$$y = C_1\frac{x}{(1-x)^2} + C_2 \frac{1+x\ln(x)}{(1-x)^2}.$$  
\\
\textbf{Ejercicios: }
\begin{itemize}
\item Encuentre la solución general de $y' = 3y$ usando un desarrollo en serie de potencias centrado en $x=0$.
\vspace{10pt}
\item Encuentre las dos soluciones fundamentales de la ecuación de \textit{Airy} $y'' = xy$.
\vspace{10pt}
\item Encuentre la solución general de $(x^2+1)y'' + xy' - y = 0$.
\vspace{10pt}
\item Demuestre que la función $$J_0(t) = \sum_{m=0}^\infty \frac{(-1)^m}{(m!)^2}\left( \frac{t}{2}\right)^m$$
es solución de la ecuación $t^2x''(t) + tx'(t) + t^2x(t) =0$. Esta función se conoce como \textit{función de Bessel de orden } 0.
\vspace{10pt}
\item Demuestre utilizando series de potencias, que la solución general de $y'' + y =0$ viene dada por $y = A\cos(x) + B\sen(x)$.
\vspace{10pt}
\item Encuentre los primeros $5$ términos del desarrollo en series de potencias de cada solución fundamental de la ecuación 
$y'' + \sen(x) + e^x y = 0$.
\vspace{10pt}
\item Encuentre una solución fundamental de la ecuación $x^2 y'' - xy' + (1-x)y = 0$. Exprésela como serie de potencias alrededor del punto $x=0$.
\end{itemize}
\section{Sistemas de Ecuaciones Diferenciales} 
Es muy común en el estudio de los fenómenos del mundo real encontrarnos con múltiples cantidades que dependen principalmente del tiempo, pero también dependen unas de otras, por lo que describir dichos fenómenos se puede volver complicado en una sola ecuación. Un buen ejemplo de esto es cuando deseamos predecir el comportamiento de dos poblaciones de animales en donde una es depredadora de la otra. Evidentemente, la cantidad de individuos de cada población depende directamente del tiempo y además, entre más depredadores existan, menos presas habrán, lo cual se traduce en menos alimento para los mismos depredadores, lo cual en última instancia disminuirá su población. Análogamente, si hay pocos depredadores, la presa tendrá tiempo para reproducirse libremente, lo cual creará eventualmente un crecimiento en la población depredadora, debido a la abundancia de alimento. Este tipo de situación no aplica únicamente para depredadores y presa, un proceso análogo sucede con la oferta-demanda en economía, y en general, en cualquier fenómeno en donde dos participantes compitan.\\
En esta sección tendremos la oportunidad de estudiar los \textbf{sistemas de ecuaciones diferenciales ordinarias}, o sistemas de EDOs, los cuales, como acabamos de discutir, aparecen naturalmente en casi cualquier área de la ciencia. Recordemos que en un sistema de ecuaciones, queremos encontrar el valor de 2 o más incógnitas (en este caso funciones) que satisfagan un cierto número de ecuaciones al mismo tiempo. Por ejemplo, podemos considerar el siguiente sistema
$$\begin{cases}
x_1(t) + 2x_2(t) = x_1'(t)\\
3x_1(t) + 2x_2(t) = x_2'(t)
\end{cases}$$
Necesitamos  encontrar dos funciones del tiempo\footnote{En esta sección utilizaremos más a menudo a $x$ como variable dependiente y a $t$ como variable independiente.}, $x_1(t)$, y $x_2(t)$. Note que no podemos resolver ninguna de las dos ecuaciones por separado, pues para encontrar tanto $x_1'(t)$ como $x_2'(t)$ necesitamos saber el valor de ambas funciones $x_1,x_2$. Veremos que la solución general del sistema viene dada por
\begin{align*}
x_1(t) = -C_1e^{-t} + 2C_2e^{4t}\\
x_2(t) = C_1e^{-t} + 3C_2e^{4t}
\end{align*}
Pues, en efecto
\begin{align*}
x_1'(t) &= C_1e^{-t} + 8C_2e^{4t} = (-C_1e^{-t} + 2C_2e^{4t}) + 2(C_1e^{-t} + 3C_2e^{4t})= x_1(t) + 2x_2(t) \\
x_2(t) &= -C_1e^{-t} + 12C_2e^{4t} = 3(C_1e^{-t} + 3C_2e^{4t}) + 2(  C_1e^{-t} + 3C_2e^{4t}) = 3x_1(t) + 2x_2(t)
\end{align*}
lo cual confirma que la solución general es correcta.\\
Vamos a utilizar la notación matricial para tratar este tipo de problemas. Con notación matricial, el sistema anterior se puede escribir como
$$X' = \begin{pmatrix} 1 &2 \\ 3& 2 \end{pmatrix} X $$
donde 
$$X = \begin{pmatrix} x_1(t)  \\x_2(t)
\end{pmatrix},$$
mientras que su solución se expresa de la forma
$$X = C_1e^{-t} \begin{pmatrix*}[c] -1 \\ 1  \end{pmatrix*} + C_2e^{4t}\begin{pmatrix}2 \\ 3  \end{pmatrix}. $$
\textbf{Nota: } A lo largo de esta sección, retomaremos en gran medida conceptos de álgebra lineal. Se recomienda un repaso de operaciones matriciales, manipulación de sistemas de ecuaciones y cálculo de determinantes y autovalores de una matriz.\\
\textbf{Definición:} Un \textbf{sistema lineal de EDOs de primer orden, en forma normal} es un sistema de ecuaciones del tipo
\begin{equation}\label{eqn:14}
\begin{cases}
\dfrac{dx_1}{dt} = a_{11}(t)x_1 + a_{12}(t)x_2 + \dots + a_{1n}(t)x_n + f_1(t) \vspace{5pt} \\
\dfrac{dx_2}{dt} = a_{21}(t)x_1 + a_{22}(t)x_2 + \dots + a_{2n}(t)x_n + f_2(t) \\
\vdots \\
\dfrac{dx_n}{dt} = a_{n1}(t)x_1 + a_{n2}(t)x_2 + \dots + a_{nn}(t)x_n + f_n(t)
\end{cases},\end{equation}
cuyas incógnitas son $x_1(t) ,x_2(t) ,\dots, x_n(t)$, y donde los $a_{ij}(t)$'s y las $f_i(t)$'s son funciones de $t$. Este sistema se puede representar de forma matricial, tomando
$$X(t) = \begin{pmatrix} x_1(t)  \\ x_2(t) \\ \vdots \\ x_n(t)
\end{pmatrix} , A(t) = \begin{pmatrix}
a_{11}(t) & a_{12}(t) & \dots & a_{1n}(t) \\
a_{21}(t) & a_{22}(t) & \dots & a_{2n}(t) \\
\vdots &  &  & \vdots \\
a_{n1}(t) & a_{n2}(t) & \dots & a_{nn}(t) \\
\end{pmatrix} , \text{ y } 
F(t) = \begin{pmatrix} f_1(t)  \\ f_2(t) \\ \vdots \\ f_n(t)
\end{pmatrix},$$
lo cual simplifica el sistema \eqref{eqn:14} en
$$X' = AX + F,$$
y cuando $F = \vec{0}$, diremos que el sistema de ecuaciones es \textbf{homogéneo:}
$$X' = AX$$
Los siguientes ejemplos, definiciones y teoremas, se centran en el estudio de estos sistemas. \\
\textbf{Ejemplo: }
El sistema
$$
\begin{cases}
\dfrac{dx}{dt} = 3x + 4y \vspace{5pt} \\
\dfrac{dy}{dt} = 5x - 7y \\
\end{cases} \text{ que es } X' = \begin{pmatrix} 3 & 4 \\ 5 & -7 \end{pmatrix}X
$$
es homogéneo, mientras que el sistema
$$
\begin{cases}
\dfrac{dx}{dt} = 6x + y + z + t  \vspace{5pt}\\
\dfrac{dy}{dt} = 8x + 7y - x  + 10t \vspace{5pt} \\
\dfrac{dz}{dt} = 2x + 9y + 6t
\end{cases}  \text{ que es } X' = \begin{pmatrix} 6 & 1 & 1 \\ 8 & 7 & - 1 \\ 2 & 9 & 0 \end{pmatrix}X + \begin{pmatrix} t \\ 10t \\6t
\end{pmatrix}
$$
no lo es.\\
\textbf{Nota: }Cuando escribamos la derivada en notación vectorial $X'$, nos referimos al vector que se obtiene de derivar cada entrada de $X$.\\
\textbf{Ejercicio: } Verifique que la solución general del sistema
$$X' = \begin{pmatrix} -5 & 1 \\ 4 & -2 \end{pmatrix} X$$
es dada por 
$$X=C_1 e^{-t} \begin{pmatrix*}[c]
1 \\4 \end{pmatrix*} + C_2 e^{-6t} \begin{pmatrix} -1 \\1 \end{pmatrix}.$$
También podemos tener problemas de valor inicial en forma de sistemas de ecuaciones diferenciales, por ejemplo, considere el sistema
$$\begin{cases}
x_1' = x_1 + 2x_2 \\
x_2' = 3x_1 + 2x_2 \\
x_1(0) = 0\\
x_2(0)=-4
\end{cases}$$
Note para cada función incógnita, necesitamos un valor inicial que la describa. Además, hemos omitido la variable independiente $t$ por comodidad. Este sistema se puede reescribir en forma matricial como
\begin{align*}
\begin{cases}X' &= \begin{pmatrix}
1 & 2 \\ 3 & 2
\end{pmatrix}X \vspace{6pt} \\
X(0) &= \begin{pmatrix*}[r] 0 \\ -4 \end{pmatrix*}
\end{cases}
\end{align*}
donde recordemos que $X = \begin{pmatrix}x_1(t) \\x_2(t) \end{pmatrix}$. Sabemos que la solución general es
$$X = C_1e^{-t} \begin{pmatrix*}[c] -1 \\ 1  \end{pmatrix*} + C_2e^{4t}\begin{pmatrix}2 \\ 3  \end{pmatrix}, $$
por lo que, aplicando la condición inicial, se ve que
\begin{alignat*}{2} &&X(0) = \begin{pmatrix*}[r] 0 \\ -4 \end{pmatrix*} &= C_1e^0 \begin{pmatrix*}[c] -1 \\ 1  \end{pmatrix*} + C_2e^0 \begin{pmatrix}2 \\ 3  \end{pmatrix} \\
\Rightarrow&& \begin{pmatrix*}[r] 0 \\ -4 \end{pmatrix*} &= \begin{pmatrix} -C_1 + 2C_2 \\
C_1 + 3C_2\end{pmatrix},
\end{alignat*}
por lo que, para encontrar los valores de $C_1$ y $C_2$, debemos resolver el pequeño sistema
$$\begin{cases}
-C_1+ 2C_2 = 0\\
C_1 + 3C_2 = -4
\end{cases}.$$
Su solución es $C_1= -8/5$ y $C_2 = -4/5$, por lo que la solución del problema de valor inicial es
$$X=-\frac{8}{5}e^{-t} \begin{pmatrix*}[c] -1 \\ 1  \end{pmatrix*} + -\frac{4}{5}e^{4t}\begin{pmatrix}2 \\ 3  \end{pmatrix}.$$
\textbf{Definición: }Un problema de valor inicial para un sistema de ecuaciones diferenciales, es de la forma
$$\begin{cases}
X' = A(t) X + F(t)\\
X(t_0)=X_0
\end{cases}$$
donde
$$X(t_0)=\begin{pmatrix} x_1(t_0) \\ x_2(t_0) \\ \vdots \\ x_n(t_0) \end{pmatrix} \ \text{ y } \ X_0 =\begin{pmatrix} b_1 \\ b_2 \\ \vdots \\ b_n \end{pmatrix} $$
Es decir, justamente como el ejemplo anterior, se trata simplemente de un sistema ecuaciones diferenciales con $n$ incógnitas $x_1(t) , \dots , x_n(t)$, sujeto a una condición inicial para cada incógnita, $x_i(t_0) = b_i$.\\
Ahora que tenemos los conceptos básicos de sistemas, estudiaremos algunos métodos de solución para los mismos. Comenzamos con dos importantes teoremas. \\
\textbf{Teorema: }Si en el problema de valores iniciales
$$X' = A(t)X + F(t) \ , \ X(t_0) = X_0$$
se cumple que todas las entradas de las matrices $A(t)$ y $F(t)$ son funciones continuas, entonces existe una única solución en un intervalo que contiene a $t_0$.\\
El siguiente teorema es similiar a uno anteriormente estudiado, y nos dice que el espacio solución de un sistema \textit{homogéneo} es un espacio vectorial.\\
\textbf{Teorema: (principio de superposición)} Sean $X_1(t), X_2(t) \dots X_n(t)$ vectores solución del sistema homogéneo
$$X' = A(t)X.$$
Entonces cualquier combinación lineal
$$X = c_1X_1 + c_2X_2 + \dots + c_nX_n \quad \quad \text{ para $c_i \in \mathbb{C}$}$$
es también solución del sistema. En resumen, \textit{``Suma de soluciones sigue siendo solución"}.\\
Tenemos también el mismo concepto de independencia lineal, pero para vectores solución.\\
\textbf{Definición:} Un conjunto $\{X_1(t) ,\dots , X_n(t) \}$ de funciones vectoriales se dice \textbf{linealmente independiente} si no existen $c_1,c_2,\dots,c_n$ no todos nulos, que hagan que para todo $t$, se cumpla
$$c_1X_1(t)+ c_2X_2(t) + \dots + c_nX_n(t) = 0.$$
\textbf{Definición: }Recordemos que un \textbf{conjunto fundamental} de soluciones es un conjunto de soluciones l.i de un sistema de ecuaciones diferenciales homogéneo.
Tenemos además un criterio de independencia lineal parecido al que estudiamos anteriormente.\\
\textbf{Teorema: (Criterio del Wronskiano para sistemas)} Sean
$$X_1(t) = \begin{pmatrix} x_{11}(t) \\ x_{21}(t) \\ \vdots \\ x_{n1}(t) \end{pmatrix} , X_2(t) = \begin{pmatrix} x_{12}(t) \\ x_{22}(t) \\ \vdots \\ x_{n2}(t) \end{pmatrix} \ , \  \dots , \  X_n(t) = \begin{pmatrix} x_{1n}(t) \\ x_{2n}(t) \\ \vdots \\ x_{nn}(t) \end{pmatrix}$$
vectores solución de algún sistema homogéneo $X' = AX$. Entonces dichos vectores solución son linealmente independientes si y solo si su Wronskiano es distinto de $0$ en todo punto $t$. Es decir, si
$$W(X_1,X_2,\dots ,X_n) = \det \begin{pmatrix} 
x_{11}(t) & x_{12}(t) & \dots & x_{1n}(t) \\
x_{21}(t) & x_{22}(t) & \dots & x_{2n}(t) \\
\vdots & & \vdots & \\
x_{n1}(t) & x_{n2}(t) & \dots & x_{nn}(t) \\
\end{pmatrix} \neq 0$$
\textbf{Nota: } A esta última matriz se le conoce como \textbf{matriz fundamental} del sistema de ecuaciones (denotada $\Phi(t)$), y se obtiene simplemente concatenando los vectores que constituyen un conjunto fundamental.\\
\textbf{Ejemplo: }Observe primero que las funciones
$$X_1 = \begin{pmatrix} e^{-2t}  \\ -e^{-2t}  \end{pmatrix} \ , \ X_2 = \begin{pmatrix} 3e^{6t}  \\ 5e^{6t}  \end{pmatrix} $$
son soluciones de
$$X' = \begin{pmatrix} 1 & 3 \\ 5 & 3 
 \end{pmatrix} X.$$
 En efecto, note que
 \begin{align*}
 \begin{pmatrix} 1 & 3 \\ 5 & 3 
 \end{pmatrix} X_1 =\begin{pmatrix} 1 & 3 \\ 5 & 3 
 \end{pmatrix} \begin{pmatrix} e^{-2t}  \\ -e^{-2t}  \end{pmatrix}  =  \begin{pmatrix} e^{-2t} - 3e^{-2t}  \\ 5e^{-2t} - 3e^{-2t} \end{pmatrix} &=  \begin{pmatrix} -2e^{-2t}  \\ 2e^{-2t} \end{pmatrix} = X_1'. \\
 \begin{pmatrix} 1 & 3 \\ 5 & 3 
 \end{pmatrix} X_1 = \begin{pmatrix} 1 & 3 \\ 5 & 3 
 \end{pmatrix} \begin{pmatrix} 3e^{6t}  \\ 5e^{6t}  \end{pmatrix} = \begin{pmatrix} 3e^{6t} + 15 e^{6t} \\ 15e^{6t} + 15 e^{6t}  \end{pmatrix} &= \begin{pmatrix}
 18e^{6t} \\ 30e^{6t}\end{pmatrix} = X_2'.
 \end{align*}
 Ahora, para ver si son l.i, basta con calcular el Wronskiano
 $$W(X_1,X_2)= \det \begin{pmatrix}
 e^{-2t} & 3e^{6t} \\
 -e^{-2t} & 5e^{6t}\\
 \end{pmatrix} = 8e^{4t} \neq 0$$
 lo cual confirma que sí son l.i.\\
Tenemos finalmente el teorema que nos permite encontrar la solución general de un sistema homogéneo. Afortunadamente, es exactamente igual que para ecuaciones homogéneas de orden superior.\\
\textbf{Teorema: } Considere el sistema homogéneo
$$X' = A(t)X$$
donde $A(t)$ es una matriz $n \times n$, cuyas entradas son funciones de $t$. Entonces, si $X_1, \dots , X_n$ forma un conjunto fundamental de soluciones, la solución general del sistema viene dada por
$$X(t) = c_1X_1(t)+ c_2X_2(t) + \dots + c_nX_n(t)$$
donde los $c_i$'s son los parámetros. \\
Este teorema nos dice exactamente lo mismo que el que estudiamos en la sección trasanterior: que el espacio solución de un sistema homogéneo es un espacio vectorial de dimensión $n$, solo que los elementos de este espacio son ahora funciones vectoriales (o sea, vectores cuyos componentes son funciones). También nos dice que para encontrar la solución general, basta encontrar $n$ soluciones linealmente independientes.\\
\textbf{Ejemplo: } Verifique como ejercicio que las funciones
$$X_1 = \begin{pmatrix}
\sen(t) - \cos(t) \\ -\sen(t) \\ 2\cos(t) \end{pmatrix} \ , X_2 =  \begin{pmatrix}
-\sen(t) - \cos(t) \\ \cos(t) \\ 2\sen(t) \end{pmatrix} \ ,  \ X_3 = \begin{pmatrix}
0 \\ e^t \\ 0 \end{pmatrix} $$
son ambas soluciones al sistema 
$$X' = \begin{pmatrix*}[r] 1 & 0 & 1 \\
1 & 1 & 0 \\
-2 & 0 & -1\end{pmatrix*}X.$$Por lo tanto, la matriz fundamental del sistema es 
$$\Phi(t) = \begin{pmatrix}  \sen(t) - \cos(t) & -\sen(t) - \cos(t) & 0  \\ -\sen(t) &  \cos(t) & e^t  \\ 2\cos(t) & 2\sen(t) & 0   \end{pmatrix}.$$
Podemos observar además que
$$W(X_1,X_2) = \det \Phi(t) = 2e^t \neq 0.$$
Como tenemos 3 soluciones l.i. de un sistema de tamaño 3, podemos aplicar el teorema para concluir que la solución general de la ecuación es
\begin{align*}X&= C_1X_1 + C_2X_2 + C_3X_3 \\
&= C_1\begin{pmatrix}
\sen(t) - \cos(t) \\ -\sen(t) \\ 2\cos(t) \end{pmatrix} + C_2\begin{pmatrix}
-\sen(t) - \cos(t) \\ \cos(t) \\ 2\sen(t) \end{pmatrix} + C_3 \begin{pmatrix}
0 \\ e^t \\ 0 \end{pmatrix} \end{align*}
O, de manera equivalente, utilizando la notación de sistema, tenemos que la solución general del sistema
$$\begin{cases}
x_1'(t) = x_1(t) + x_3(t) \\
x_2'(t) =x_1(t) + x_2(t) \\
x_3'(t) = -2x_1(t) - x_3(t)\\
\end{cases}$$
viene dada por
\begin{align*}
x_1(t) &= C_1(\sen(t)-\cos(t)) + C_2(-\sen(t) - \cos(t))\\
x_2(t) &= -C_1\sen(t) + C_2\cos(t) + C_3e^t \\
x_3(t) &= 2C_1\cos(t) + 2C_2\sen(t)
\end{align*}
\textbf{Nota: } Podrá observar que no estamos cometiendo el abuso donde los parámetros absorben signos y constantes. Como $C_1,C_2,C_3$ aparecen en las 3 soluciones, no nos conviene cambiarlas en una ecuación, puesto que alteraría las otras dos.\\
Al igual que en ecuaciones de orden superior, cuando nos encontremos con una ecuación \textit{no homogénea,} aplicaremos un proceso de solución similar, encontrando primero la solución complementaria (la que se obtiene de resolver el sistema como si fuese homogéneo), y luego con algún otro método, la solución particular.\\
\textbf{Teorema: Solución general de sistemas no homogéneos.} Considere el sistema de ecuaciones no homogéneo
\begin{equation}\label{eqn:15}
X' = A(t)X + F(t), \quad \text{ donde } F(t) \neq \vec{0}.
\end{equation}
La solución general del sistema \eqref{eqn:15} es
$$X = X_c + X_p$$
donde $X_n$ es la solución general del sistema homogéneo $X' = A(t)X$, y $X_p$ es una solución particular de \eqref{eqn:15}.\\
\textbf{Ejemplo: } Considere el sistema no homogéneo
$$X' = \begin{pmatrix} 1 & 3 \\ 5 & 3 \end{pmatrix}X + \begin{pmatrix} 12t - 11 \\  -3 \end{pmatrix}.$$
Podemos notar que la función vectorial $X_p = \begin{pmatrix} 3t - 4 \\ -5t + 6 \end{pmatrix}$ es solución particular de nuestro sistema: en efecto
\begin{align*}
\begin{pmatrix}1 & 3 \\ 5 & 3 \end{pmatrix} X_p + \begin{pmatrix} 12t - 11 \\  -3 \end{pmatrix} &= \begin{pmatrix}1 & 3 \\ 5 & 3 \end{pmatrix} \begin{pmatrix} 3t - 4 \\ -5t + 6 \end{pmatrix} + \begin{pmatrix} 12t - 11 \\  -3 \end{pmatrix}\\ &= \begin{pmatrix} -12t + 14 \\ -2 \end{pmatrix} +  \begin{pmatrix} 12t - 11 \\  -3 \end{pmatrix} \\
&= \begin{pmatrix} 3 \\  -5 \end{pmatrix}
= X_p'.
\end{align*} 
Ahora, si consideramos el sistema homogéneo
$$X' = \begin{pmatrix} 1 & 3 \\ 5 & 3 \end{pmatrix}X,$$
del cual, por un ejemplo anterior, conocemos dos soluciones l.i.
$$X_1 = \begin{pmatrix} e^{-2t}  \\ -e^{-2t}  \end{pmatrix} \ , \ X_2 = \begin{pmatrix} 3e^{6t}  \\ 5e^{6t}  \end{pmatrix},$$
podemos aplicar el teorema de solución general para homogénea para deducir que
$$X_c = C_1\begin{pmatrix} e^{-2t}  \\ -e^{-2t}  \end{pmatrix} + C_2 \begin{pmatrix} 3e^{6t}  \\ 5e^{6t}  \end{pmatrix}.$$
Por lo tanto, la solución general de nuestro sistema no homogéneo viene dada por
$$X=X_c + X_p = C_1\begin{pmatrix} e^{-2t}  \\ -e^{-2t}  \end{pmatrix} + C_2 \begin{pmatrix} 3e^{6t}  \\ 5e^{6t}  \end{pmatrix} + \begin{pmatrix} 3t - 4 \\ -5t + 6 \end{pmatrix}.$$
Tenemos entonces toda la teoría necesaria para obtener la solución general de sistemas lineales de primer orden. Lo que resta es encontrar los métodos para encontrar las soluciones fundamentales y particulares. \\
\textbf{Ejercicios: }
\begin{enumerate}
\item Escriba los siguientes sistemas en forma matricial
\vspace{10pt}
\begin{itemize}
\item 
$\begin{cases} x'(t) = 4x -5y\\ y'(t) = -4x + 9y 
\end{cases}$
\item 
$\begin{cases} x' = 1 +x +y +z\\ y'= 3y + 5z - 2y + t^2\\ z'= z + x + e^{\sen t}
\end{cases}$
\item $\begin{cases} x' = \ln t x - 2\cos(t)y + 1/t\\ y' = tx + ty + t^2
\end{cases}$
\end{itemize}
\vspace{10pt}
\item Reescriba los siguientes sistemas en forma matricial a forma de sistema.
\vspace{10pt}
\begin{itemize}
\vspace{5pt}
\item $X' = \begin{pmatrix} 1 & 0 & 1\\ -4 & -6 & 0 \\ -1& 4 &-2 \end{pmatrix}X$
\vspace{5pt}
\item $X' = \begin{pmatrix} t& t^2 &t^3 \\ 1 & e^t &-\sen(t) \\ 0  &-\ln t & - \sec(t)\end{pmatrix} X + e^{-3t}\begin{pmatrix}1 \\ \cos(t) \\ 0 \end{pmatrix}$
\end{itemize}
\vspace{10pt}
\item Verifique que para cada sistema dado, el vector dado es una solución.
\vspace{10pt}
\begin{itemize}
\item $X' = \begin{pmatrix} -1 & \frac{1}{4} \\ 1 & -1 \end{pmatrix} X$, con $X=  \begin{pmatrix} -e^{-3t/2} \\ 2e^{-3t/2} \end{pmatrix}$
\vspace{6pt}
\item $X' = \begin{pmatrix} 2 & 1 \\ -1 & 0 \end{pmatrix} X$, con $X=  \begin{pmatrix} 1 \\ 3 \end{pmatrix}e^t + \begin{pmatrix} 4 \\ -4 \end{pmatrix}te^t$
\end{itemize}
\item Demuestre que las siguiente tres funciones vectoriales son linealmente independientes
$$X_1 = \begin{pmatrix}  1+t \\-2+2t \\4+2t \end{pmatrix} \ , X_2 = \begin{pmatrix} 1\\ -2\\ 4 \end{pmatrix} \ , X_3 = \begin{pmatrix}  3+2t \\ -6 + 4t \\ 12+ 4t \end{pmatrix}$$
\end{enumerate}
A continuación estudiaremos métodos de solución para sistemas homogéneos (aquellos donde $F(t) =\vec{0}$).
\subsection{Método de sustitución.}
Algunos de los sistemas más sencillos se pueden resolver simplemente integrando y sustituyendo el resultado de alguna ecuación en otra.\\
\textbf{Ejemplo: } el sistema
$$\begin{cases}
x'(t) = 1+y^2(t) \\
y'(t) = \sec^2(t) \end{cases}$$
no es lineal, por lo que nuestros teoremas no aplican. Sin embargo, podemos integrar la segunda ecuación con respecto a $t$ (pues no depende de $x(t)$) para obtener que 
$$y(t) = \tan(t),$$
y sustituyendo esto en la primera ecuación, vemos que
$$x'(t) = 1+\tan^2(t) = \sec^2(t)$$
Lo cual implica que 
$x(t) = \int \sec^2(t)dt = \tan(t)$, por lo que una solución del sistema viene dada por
$$\begin{pmatrix} x(t) \\ y(t) \end{pmatrix} = \begin{pmatrix} \tan(t) \\ \tan(t) \end{pmatrix}. $$
\textbf{Ejemplo: }Considere ahora el sistema
$$\begin{cases}
x' = y \\
y' = x
\end{cases}$$
el cual sí es lineal y está en forma normal. Derivando la segunda ecuación, podemos ver que
$$y'' = x' = y,$$
pero ya sabemos que la solución general de la ecuación $y'' = y$ es
$$y = C_1e^t + C_2e^{-t}.$$
Finalmente, como $x = y'$, tenemos la solución general
$$\begin{pmatrix} x(t) \\ y(t) \end{pmatrix} = C_1\begin{pmatrix} e^t \\ e^t \end{pmatrix} + C_2\begin{pmatrix} e^{-t} \\ -e^{-t} \end{pmatrix} . $$
Estos primeros ejemplos son sencillos, no nos toparemos muy a menudo con sistemas que se puedan resolver así. Sin embargo, funcionan para ilustrarnos que las mismas técnicas que hemos desarrollado para ecuaciones ordinarias, pueden funcionar para resolver sistemas de ecuaciones, al usarlas con cierto grado de ingenio.
\pagebreak
\subsection{Eliminación gaussiana}
El método de eliminación gaussiana que aprendimos en álgebra lineal funciona también para los sistemas lineales. Podemos ver un ejemplo para un sistema $2\times2$.\\
\textbf{Ejemplo: }El sistema con variable independiente $t$:
$$
\begin{cases}
x' = -9y \\
y' = -4x
\end{cases}
$$
Podemos utilizar la notación de operadores diferenciales para convertir este sistema en
$$
\begin{cases}
Dx + 9y = 0 \\
4x+ Dy = 0 \\
\end{cases}
$$
El método de eliminación es análogo al estudiado en álgebra lineal. Primero, vamos a multiplicar la primera ecuación por $D$ y la segunda por $-9$ para obtener
$$
\begin{cases}
D^2x + 9Dy = 0 \\
-36x+ -9Dy = 0 \\
\end{cases}
$$
A partir de aquí, podemos sumar ambas ecuaciones, eliminando la variable $y$, y dejando una ecuación de segundo orden con variable $x(t)$,
$$D^2x - 36x = 0.$$
Ya sabemos cómo calcular la solución de esta ecuación,
$$x(t) = C_1e^{6t} + C_2e^{-6t}.$$
Seguidamente tenemos dos opciones: primero, sustituir esta función en la segunda ecuación e integrar (debemos ser cuidadosos pues aparecerán nuevas constantes de integración), la segunda opción es repetir el proceso de eliminación, esta vez para $x$. Vamos a preferir la segunda opción: multiplicando la primera ecuación ahora por $4$ y la segunda por $-D$, llegamos a
$$
\begin{cases}
4Dx + 36y = 0 \\
-4Dx+ -D^2y = 0 \\
\end{cases}
$$
Luego, sumando ambas ecuaciones llegamos a que
$$(36-D^2)y = 0,$$
cuya solución es
$$y(t) = C_3e^{6t} + C_4e^{-6t}.$$
Note que la solución es casi idéntica a la ecuación de $x(t)$, sin embargo los parámetros deben ser nuevos pues se trata no obstante de otra ecuación. Vemos entonces que hemos encontrado $x(t)$ y $y(t)$, sin embargo, no hemos llegado a la solución general, puesto que tenemos $4$ parámetros, y los teoremas que estudiamos en la sección anterior nos dicen que solo podemos tener $2$. Esto significa que debemos despejar $C_3$ y $C_4$ a partir de los otros dos (en realidad podemos despejar cualesquiera dos de los $C_i$'s en función de los otros dos). Podemos hacer esto de varias formas. Podemos por ejemplo, derivar $x$ para obtener
$$x'(t) = 6C_1e^{6t} - 6C_2e^{-6t},$$
y como la primera ecuación nos dice que $x'$ debe ser igual a $-9y$, simplemente compraramos las expresiones resultantes
$$6C_1e^{6t} - 6C_2e^{-6t} =-9C_3e^{6t} -9 C_4e^{-6t} $$
A partir de aquí podemos deducir que, comparando los coeficientes a cada lado, que
$C_3 = -2/3 C_1$ y que $C_4 = 2/3 C_2$. Por lo que podemos ver que 
$$y(t) = -\frac{2}{3}C_1e^{6t} + \frac{2}{3}C_2e^{-6t}.$$
La otra forma de hacer este despeje es similar, pero usando la segunda ecuación del sistema, ambos despejes arrojarán el mismo resultado. Finalmente, expresamos la solución general en forma vectorial,
$$\begin{pmatrix} x(t) \\ y(t) \end{pmatrix} = C_1\begin{pmatrix} e^{6t}  \\ -\frac{2}{3}e^{6t} \end{pmatrix} + C_2\begin{pmatrix}  e^{-6t} \\ \frac{2}{3} e^{-6t} \end{pmatrix}.$$
% \textbf{Ejemplo: }El sistema con variable independiente $t$
% $$\begin{cases}
% x'+y' = y-x \\
% 2x' + 3y' = -y\\
% \end{cases}$$
% Se puede reescribir como
% $$\begin{cases}
% x' + x +y' - y =0  \\
% 2x' + 3y' +y =0\\
% \end{cases} \Rightarrow \begin
% {cases}
% (D+1)x + (D-1)y = 0 \\
% 2Dx + (3D +1)y = 0
% \end{cases}$$
% donde hemos usado la notación de operador diferencial $D$. Podemos entonces trabajar este sistema usando el método de eliminación gaussiana (también conocido como método de Gauss-Jordan). En este caso, como solo tenemos 2 ecuaciones, no es necesario reducir la matriz del sistema, podemos simplemente multiplicar primera ecuación por $2D$ y la segunda por $-(D+1)$ para obtener
% $$\begin{cases}
% 2D(D+1)x + 2D(D-1)y = 0 \\
% -2D(D+1)x  -(D+1)(3D +1)y = 0
% \end{cases}$$
% Sumando ambas ecuaciones, podemos entonces despejar $y$ resolviendo la ecuación diferencial resultante
% \begin{alignat*}{2}
% &&2D(D-1)y - (D+1)(3D+1)y &= 0 \\
% \Rightarrow&& (2D^2 - 2D - 3D^2 -D - 3D - 1)y &= 0 \\
% \Rightarrow&& (-D^2 - 6D - 1)y &= 0
% \end{alignat*}
% Las raíces del polinomio asociado a esta ecuación son $-3 \pm 2\sqrt{2}$, por lo que
% $$y(t) = C_1 e^{(-3  +2\sqrt{2})t} + C_2e^{(-3  -2\sqrt{2})t}.$$
% Para encontrar $x(t)$ tenemos dos opciones: la primera es repetir el proceso de eliminación para cancelar la variable $y$ en ambas ecuaciones, la segunda es sustituir el valor de $y$ en alguna de las ecuaciones y resolver la ecuación restante, la cual tiene como incógnita nada más a $x(t)$. Vamos a aplicar la primera, multiplicando adecuadamente el sistema original, obtenemos
% $$\begin
% {cases}
% (D+1)(3D+1)x + (D-1)(3D+1)y = 0 \\
% -2D(D-1)x -(D-1) (3D +1)y = 0
% \end{cases},$$
% después de sumar debemos resolver 
% \begin{alignat*}{2}
% && (D+1)(3D+1) -2D(D-1)x &= 0 \\
% \Rightarrow&& (D^2 + 6D +1)x &=0
% \end{alignat*}
% de donde obtenemos rápidamente que
% $$x(t) =C_3 e^{(-3  +2\sqrt{2})t} + C_4e^{(-3  -2\sqrt{2})t} ,$$
% Es decir, $x(t)$ tiene la misma forma que $y(t)$, pero con parámetros distintos.
% Sin embargo, aún no hemos terminado, ya que sabemos que la solución general de esta ecuación solo puede tener 2 parámetros libres. Debemos despejar $C_3$ y $C_4$ a partir de los otros dos (en realidad podemos despejar cualesquiera dos de los $C_i$'s en función de los otros dos). Denotemos $\alpha = -3 + 2\sqrt{2}$ y $\beta = -3-2\sqrt{2}$. Entonces derivando, obtenemos
% \begin{align*}
% x' &= \alpha C_3 e^{\alpha t} +  \beta C_4 e^{\beta t} \\
% y' &=  \alpha C_1 e^{\alpha t} +  \beta C_2 e^{\beta t}.
% \end{align*}
% Ahora, como $x'+y' = y-x$, debe cumplirse que
% $$\alpha e^{\alpha t} (C_1 +  C_3) +  \beta e^{\beta t} (C_2+C_4) = e^{\alpha t} (C_1-C_3) + e^{\beta t} (C_2-C_4).$$
% Comparando a ambos lados, debe cumplirse que
% $$\begin{cases}
% \alpha(C_1+ C_3) = C_1-C_3 \\
% \beta(C_2 + C_4) = C_2-C_4
% \end{cases}$$
% Este sistema no es complicado de despejar. Si queremos despejar $C_3$ y $C_4$, obtenemos
% \begin{align*}
% C_3 &= \frac{1-\alpha}{1+\alpha} C_1 = \sqrt{2}C_1 \\
% C_4 &= \frac{1-\beta}{1+\beta} C_2 = -\sqrt{2}C_2
% \end{align*}
% Los valores $\sqrt{2}$ y $-\sqrt{2}$ se obtienen racionalizando. Tenemos entonces finalmente que la solución general del sistema es
% $$\begin{pmatrix} x(t) \\ y(t) \end{pmatrix} = C_1 \begin{pmatrix} \sqrt{2}e^{(-3  +2\sqrt{2})t} \\ e^{(-3  +2\sqrt{2})t} \end{pmatrix} + C_2 \begin{pmatrix} -\sqrt{2}e^{(-3  -2\sqrt{2})t} \\ e^{(-3  -2\sqrt{2})t} \end{pmatrix}.$$
También podemos aplicar este método para resolver sistemas no homogéneos. \\
\textbf{Ejemplo: } Considere el problema de valores iniciales $$
\begin{cases}
x' = x + y + e^t\\
y' -x = 2y\\
x(0) = 1\\
y(0) = 0\\
\end{cases}
$$
El cual se puede escribir usando notación de operador diferencial como
$$
\begin{cases}
(D-1)x - y = e^t\\
-x + (D-2)y = 0\\
\end{cases}
$$
Primero, aplicamos eliminación para eliminar $y$, esto equivale a multiplicar la primera ecuación por $(D-2)$ y la segunda por $1$. Luego de sumar, obtenemos
$$(D-1)(D-2)x  - x = (D-2)e^t$$
lo cual se simplifica como
$$(D^2 - 3D + 1)x = -e^t.$$
Esta ecuación se puede resolver usando anuladores o coeficientes indeterminados, su solución es
$$x(t) = C_1 e^{(3 - \sqrt{5}) \frac{t}{2}} + C_2 e^{(3 + \sqrt{5}) \frac{t}{2}}- e^t.$$
Seguidamente, para anular $y$, multiplicamos la primera ecuación por $1$ y la segunda por $(D-1)$ para obtener, luego de sumar, que
$$(D-1)(D-2)y - y = e^t \Rightarrow (D^2 -3D +1)y = e^t,$$ por lo que, de nuevo
$$y(t) = C_3 e^{(3 - \sqrt{5}) \frac{t}{2}} + C_4 e^{(3 + \sqrt{5}) \frac{t}{2}}- e^t.$$
Debemos entonces despejar $C_3$ y $C_4$ en función de $C_1$ y $C_2$. Denotemos ahora $\alpha = \frac{3-\sqrt{5}}{2}$ y $\beta = \frac{3+\sqrt{5}}{2}$. Derivando, vemos que
$$x'(t) = \alpha C_1 e^{\alpha t} + \beta C_2 e^{\beta t} - e^t$$
y como debe cumplirse que $x' = x+y+e^t$, debe cumplirse entonces que
$$ \alpha C_1 e^{\alpha t} + \beta C_2 e^{\beta t}-e^t = e^{\alpha t} (C_1+ C_3) + e^{\beta t}(C_2 + C_4) - e^t$$
por lo que, comparando términos y despejando el sistema resultante, obtenemos que
\begin{align*}C_3 &= C_1(\alpha -1 ) = \frac{1-\sqrt{5}}{2}C_1 \\
C_4 &= C_2(\beta -1) = \frac{1+\sqrt{5}}{2}C_2
\end{align*}
Por lo que la solución general del sistema es
\begin{align*}
x(t) &=  C_1 e^{(3 - \sqrt{5}) \frac{t}{2}} + C_2 e^{(3 + \sqrt{5}) \frac{t}{2}}- e^t \\
y(t) &= \frac{1-\sqrt{5}}{2}C_1 e^{(3 - \sqrt{5}) \frac{t}{2}} + \frac{1+\sqrt{5}}{2}C_2 e^{(3 + \sqrt{5}) \frac{t}{2}}- e^t
\end{align*}
Finalmente, como $x(0) =1$ y $y(0) = 0$, tenemos que
$$\begin{cases}
C_1 + C_2 - 1 = 1 \\
\frac{1-\sqrt{5}}{2}C_1 + \frac{1+\sqrt{5}}{2}C_2 - 1 = 0
\end{cases}$$
de donde obtenemos que $C_1 = -\frac{1}{\sqrt{5}}$, y que $C_2 = \frac{1}{\sqrt{5}}$. Finalmente, tenemos la solución del problema de valor inicial:
$$\begin{pmatrix} x(t) \\ y(t) \end{pmatrix} = \begin{pmatrix} -\frac{1}{\sqrt{5}}e^{(3 - \sqrt{5}) \frac{t}{2}} \\ \frac{\sqrt{5}-1}{10}e^{(3 - \sqrt{5}) \frac{t}{2}}  \end{pmatrix} + \begin{pmatrix} \frac{1}{\sqrt{5}}e^{(3 + \sqrt{5}) \frac{t}{2}} \\ \frac{\sqrt{5}+1}{10}e^{(3 + \sqrt{5}) \frac{t}{2}}  \end{pmatrix} - \begin{pmatrix} e^t \\ e^t \end{pmatrix}$$
Hagamos un último ejemplo, que tenga derivadas de orden superior.\\
\textbf{Ejemplo: }Encuentrar la solución general de
$$
\begin{cases}
x'' + y' + x = \sen(t) \\
x' + y'' = 1
\end{cases}
$$
Este sistema se puede escribir de la forma
$$
\begin{cases}
(D^2 +1)x + Dy = \sen(t) \\
Dx  + D^2y = 1
\end{cases}.
$$
Multiplicando la primera ecuación por $-D$, y sumándolas, se llega a
$$-D^3x = \sen(t) +1.$$
Integrando tres veces, vemos que
$$x = -\cos(t) -\frac{t^3}{6} + C\frac{t^2}{2} + Bt + A.$$
Ahora, para encontrar $y(t)$ podemos de nuevo repetir el proceso de eliminación, o sustituir $x'$ en la segunda ecuación y resolver lo que nos quede. Vamos a aplicar el segundo método, para que veamos que aparecen \textit{muchas} constantes de integración, las cuales tendremos que reducir, puesto que la solución general solo puede depender a lo sumo de $3$ parámetros. Derivando $x$, vemos que 
$$ x' = -\sen(t) + \frac{t^2}{2} + Ct + B.$$
Sustituyendo este valor en la segunda ecuación, enviándolo a restar, vemos que
$$y'' = 1 + \sen(t) - \frac{t^2}{2} - Ct - B $$
Por lo que, de nuevo, integrando dos veces, podemos deducir que
$$y = \frac{t^2}{2} + Dt + E - \sen(t) - \frac{t^4}{24} - Ft - G C\frac{t^2}{2} - CH - Bt - I,$$
donde $A,B,C,D,E,F,G,H,I$ son todas constantes de integración. Notemos que en $y$ podemos simplificar un poco, absorbiendo algunas constantes
$$y=- \frac{t^4}{24} + (1-GC)\frac{t^2}{2} + (D-B)t  - \sen(t)  - CE.$$
Es posible simplificar aún más los parámetros, (podemos reducir la solución hasta un mínimo de cuatro parámetros), sin embargo esto es tedioso y no nos será de mucho interés para este ejemplo. Es por esto que en general preferiremos repetir el proceso de eliminación sobre el método de sustitución. \pagebreak \\
\textbf{Ejercicios: }Encuentre la solución general de los siguientes sistemas :
\vspace{10pt}
\begin{enumerate}
\vspace{10pt}
\item
$
\begin{cases}
x' = 2y \\
y' = x-y
\end{cases}
$
\item
$
\begin{cases}
3x' + 2y' = x-y \\
x'-y' = x+2y
\end{cases}
$
\vspace{10pt}
\item 
$
\begin{cases}
x' = x+2y + e^{-t} \\
y' = 3y
\end{cases}
$
\vspace{10pt}
\item 
$
\begin{cases}
x'' + x' +y = e^t \\
x'+y' = 1
\end{cases}
$
\end{enumerate}
\vspace{10pt}
Resuelva los siguiente problemas de valor inicial
\vspace{10pt}
\begin{enumerate}
\item
$
X' = \begin{pmatrix}  8 & -1 \\ 4 & 12\end{pmatrix}X
$, con la condición $X\begin{pmatrix}  0 \\0\end{pmatrix} = \begin{pmatrix}  1 \\0\end{pmatrix}
$
\vspace{10pt}
\item 
$
X' = \begin{pmatrix}  1 & 2 \\ 3 & -4\end{pmatrix}X
$, con la condición $X\begin{pmatrix}  1 \\0\end{pmatrix} = \begin{pmatrix}  0 \\0\end{pmatrix}
\vspace{10pt}
$
\end{enumerate}
\subsection{Resolución por medio de valores propios.}
Recuerde que si $A$ es una matriz $n\times n$, decimos que un número $\lambda \in \mathbb{C}$ es un \textbf{valor propio} (o autovalor, eigenvalor) de $A$, si existe algún vector $v \neq 0$ tal que $Av = \lambda v$ (a $v$ se le llamará \textbf{vector propio} asociado a $\lambda$).\\ Considere ahora el sistema de ecuaciones
\begin{equation}\label{eqn:16}
X'(t) = AX(t),
\end{equation}
donde $A$ es una matriz con entradas constantes ($A$ no tiene funciones como entradas). Sea $\lambda$ un valor propio de $A$, con $\mathbf{v}$ su vector propio asociado. Entonces se cumple que la función $$X(t) = \begin{pmatrix} e^{\lambda t}v_1  \\ e^{\lambda t}v_2   \\ \vdots \\ e^{\lambda t}v_n \end{pmatrix} = e^{\lambda t} \mathbf{v}$$ es solución del sistema \eqref{eqn:16}, puesto que
$$X'(t) = \begin{pmatrix} \lambda e^{\lambda t}v_1  \\ \lambda e^{\lambda t}v_2   \\ \vdots \\ \lambda e^{\lambda t}v_n \end{pmatrix} = \lambda e^{\lambda t}\mathbf{v}, $$
mientras que 
$$AX(t) = Ae^{\lambda t}\mathbf{v} = e^{\lambda t} A\mathbf{v} = e^{\lambda t} \lambda \mathbf{v} = \lambda  e^{\lambda t} \mathbf{v}. $$
Note que $Ae^{\lambda t}\mathbf{v} = e^{\lambda t} A\mathbf{v}$, pues $e^{\lambda t}$ es un escalar. En resumen, para resolver el sistema \eqref{eqn:16}, solo necesitamos encontrar los valores y vectores propios de la matriz $A$. En general, pueden suceder cuatro cosas, las cuales ejemplificamos a continuación.\\
\textbf{Ejemplo (Caso 1. Valores propios reales distintos): } Considere el sistema de ecuaciones
$$\begin{cases}
x' = 3x - 2y \\
y' = -3x + 2y
\end{cases}$$
Podríamos aplicar eliminación para resolverlo, pero vamos a calcular los valores propios de la matriz del sistema
$$A = \begin{pmatrix} 3 & -2 \\ -3 & 2 \end{pmatrix}.$$
Utilizando el \textit{polinomio característico} de la matriz $A$, vemos que
$$det(A-xI) = \det \begin{pmatrix} 3-x & -2 \\ -3 & 2-x \end{pmatrix} = (3-x)(2-x) - 6 = x^2 - 5x.$$
Esto nos dice que los valores propios son las raíces de este polinomio, es decir, $0$ y $5$. Debemos entonces calcular un vector propio asociado a cada uno, primero resolvemos el sistema $(A-5I)v = 0$,
$$\begin{pmatrix} -2 & -2 \\ -3 & -3 \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}.$$
Este sistema tiene infinitas soluciones, pero solo buscamos una, y cualquier vector donde $a = -b$ bastará, por ejemplo $v_1 = (1,-1)^t$. Resolvemos ahora el sistema $(A-0I)v = 0$,
$$\begin{pmatrix} 3 & -2 \\ -3 & 2 \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}.$$
Para este caso necesitamos algún vector donde $b = 3a/2 $, entonces podemos tomar $v_2 = (1, \frac{3}{2})^t $. Tenemos entonces dos soluciones a la ecuación diferencial:
\begin{align*}
X_1(t) &= e^{5t}\begin{pmatrix} 1 \\ -1 \end{pmatrix}  =\begin{pmatrix}  e^{5t} \\ - e^{5t} \end{pmatrix} \\  X_2(t) &= e^{0t}\begin{pmatrix} 1 \\ \frac{3}{2} \end{pmatrix} = \begin{pmatrix} 1 \\ \frac{3}{2} \end{pmatrix} \end{align*}
Es fácil verificar, usando el criterio del Wronskiano, que estas soluciones son linealmente independientes. Por lo tanto, tenemos 2 soluciones l.i de un sistema $2 \times 2$. Por el teorema de solución general, concluimos que la solución general de este sistema es
$$X(t)=  C_1X_1 + C_2X_2 = C_1\begin{pmatrix}  e^{5t} \\ - e^{5t} \end{pmatrix} + C_2\begin{pmatrix} 1 \\ \frac{3}{2} \end{pmatrix}.$$
\textbf{Ejemplo: Caso 2. Raíces reales repetidas, con multiplicidad correcta }Considere el sistema 
$$X' = \begin{pmatrix} 5 & 4 &2 \\ 4 & 5 & 2 \\ 2 & 2 & 2 \end{pmatrix}X$$
Calculamos de los ceros del polinomio característico de $A$,
$$\det(A-xI) = \det \begin{pmatrix} 5-x & 4 &2 \\ 4 & 5-x & 2 \\ 2 & 2 & 2-x \end{pmatrix} = -x^3 + 12x^2 - 21x + 10 = (10-x)(x-1)^2,$$
(factorizamos usando división sintética). Los valores propios son entonces $10$ y $1$, pero note que $1$ aparece con multiplicidad $2$, por lo que debe ser tratado distinto. Comencemos resolviendo el sistema $(A-10I)v=0$
$$\begin{pmatrix} -5 & 4 &2 \\ 4 & -5 & 2 \\ 2 & 2 & -8 \end{pmatrix}\begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix},$$
podemos usar cualquier método (eliminación, sustitución) para ver que una solución posible es $v_1 = (2,2,1)^t$ (Importante: en general estos sistemas no se pueden resolver por calculadora, pues estas matrices tienen determinante $0$). Esto nos produce la solución del sistema
$$X_1(t) = \begin{pmatrix} 2e^{10t} \\ 2e^{10t} \\ e^{10t} \end{pmatrix}.$$
Para encontrar las otras soluciones, debemos ahora resolver el sistema $(A-I)v = 0$. Sin embargo, como $1$ es un autovalor de multiplicidad $2$, debemos encontrar dos soluciones $v_2,v_3$ linealmente independientes, en vez de una. Esto solo es posible si la dimensión del espacio solución es $2$ (lo cual sí se cumple), para cuando no se cumpla, tenemos el caso $3$. Una vez más, cabe recalcar que la escogencia de $v_2,v_3$ puede hacerse de muchas formas, puesto que el sistema $(A-I)v = 0$ tiene infinitas soluciones. Tenemos entonces 
$$\begin{pmatrix} 4 & 4 &2 \\ 4 & 4 & 2 \\ 2 & 2 & 1 \end{pmatrix} = \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}.$$
En este sistema, vemos que en realidad todas las filas son múltiplos de la tercera, es decir, ella nos da toda la información que necesitamos. Más específicamente, solo necesitamos dos vectores de la forma $v = (a,b,c)$ que cumplan $2a+2b + c=0$ y que sean l.i. Dos opciones son $v_2 = (-1,1,0)^t$ y $v_3 = (-1,0,2)^t$ (es fácil ver que son l.i pues ninguno es múltiplo del otro). Esto nos produce entonces las otras dos soluciones fundamentales del sistema
$$X_2 = \begin{pmatrix} -e^{t} \\ e^{t} \\ 0 \end{pmatrix} \ , \ X_3 = \begin{pmatrix} -e^{t} \\ 0 \\ 2e^t \end{pmatrix}.$$
El lector puede verificar que $X_1,X_2,X_3$ son linealmente independientes, por lo que la solución general viene dada por 
$$X(t) = C_1\begin{pmatrix} 2e^{10t} \\ 2e^{10t} \\ e^{10t} \end{pmatrix} + C_2\begin{pmatrix} -e^{t} \\ e^{t} \\ 0 \end{pmatrix} + C_3  \begin{pmatrix} -e^{t} \\ 0 \\ 2e^t \end{pmatrix}.$$
% Lo único que queda es resolver la condición inicial. Como nos dicen que $X(0,0,0)^t = (0,0,0)^t$, sustituyendo en la solución general debemos garantizar que se cumpla
% $$\begin{pmatrix} 0 \\ 0\\ 0 \end{pmatrix} = C_1 \begin{pmatrix} 2 \\ 2\\ 1 \end{pmatrix}  + C_2 \begin{pmatrix} -1 \\ 1\\ 0 \end{pmatrix}  + C_3\begin{pmatrix} -1 \\ 0\\ 2 \end{pmatrix} $$
% O en notación más familiar
% $$\begin{cases}
% 2C_1 - C_2 - C_3 = 0 \\
% 2C_1 + C_2 = 0 \\
% C_1 + 2C_3 = 0\\
% \end{cases}$$
% La solución de este sistema es $C_1=C_2=C_3=0$, por lo que la solución del problema de valores iniciales es simplemente
% $$X(t) = 0.$$
Tenemos en resumen un método para resolver sistemas del tipo \eqref{eqn:16}, cuando los valores propios son números reales: simplemente calculamos cada valor propio $\lambda$, y si su multiplicidad es $k$, debemos encontrar $k$ vectores l.i que satisfagan la ecuación $(A-\lambda I)v = 0$. Una vez encontrados dichos vectores $v$, se les asocia la solución $e^{\lambda t}v$ a cada uno. Este procedimiento genera entonces un total de $n$ soluciones l.i del sistema, lo cual nos conduce de inmediato a la solución general.\\
En caso que de un valor propio $\lambda$ tenga multiplicidad $k$, pero el espacio solución de $(A-\lambda I)v=0$ tenga dimensión menor a $k$ (esto significa que no podemos encontrar $k$ autovectores l.i asociados a $\lambda$), debemos variar un poco la solución, encontrando vectores propios generalizados. Veamos un ejemplo de esto. \pagebreak \\
\textbf{Ejemplo: Caso 3. Raíces reales repetidas, con multiplicidad incorrecta. } Resuelva el sistema $$X' = \begin{pmatrix} 1 & -1 \\ 1 & 3 \end{pmatrix}X.$$
El polinomio característico es $(x-2)^2$, por lo que el único valor propio es $2$, con multiplicidad $2$. Nos gustaría encontrar ahora $2$ soluciones l.i para el sistema 
$$(A-2I)v = \begin{pmatrix} -1 & -1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} a \\ b  \end{pmatrix} = 0.$$
Lamentablemente, el rango de esta matriz es $1$, lo cual nos hace imposible encontrar $2$ soluciones l.i. (ya que si el rango es $1$, la dimensión del espacio solución del sistema es $1$, o sea que tenemos como máximo una solución l.i). La solución l.i que sí podemos encontrar, es $v_0 = (-1,1)^t$. Para terminar de resolver el sistema, procedemos entonces a buscar \textbf{vectores propios generalizados}, esto es, en vez de resolver el sistema $(A-2I)v=0$, resolvemos $(A-2I)v = v_0$,
$$\begin{pmatrix} -1 & -1 \\ 1 & 1 \end{pmatrix}\begin{pmatrix} a \\ b  \end{pmatrix} = \begin{pmatrix} -1 \\ 1  \end{pmatrix},$$
el cual admite la solución $v_1 = (1,0)^t$. Entonces podemos asociar las soluciones a cada vector
\begin{align*} X_1(t) &=  e^{2t}v_0 =  \begin{pmatrix} -e^{2t} \\ e^{2t} \end{pmatrix} \end{align*}
Para encontrar $X_2(t)$ sin embargo, debemos utilizar la fórmula
$$X_2(t) = e^{2t} (tv_0 + v_1) = e^{2t}\left( \begin{pmatrix} -t \\ t \end{pmatrix} + \begin{pmatrix} 1 \\0 \end{pmatrix} \right) = \begin{pmatrix} (1-t)e^{2t} \\ te^{2t} \end{pmatrix}$$
La solución general se expresa entonces de la misma forma.
$$X(t) = C_1X_1 + C_2X_2.$$
Vamos ahora a explicar de manera general cómo se procede en éste método. Supóngase que tenemos un valor propio $\lambda$ con multiplicidad $k$, pero el espacio solución del sistema $(A-\lambda I)v$ no nos provee suficientes soluciones l.i. (siempre debe proveer una como mínimo). Entonces tomamos una solución $v_0$ de dicho sistema, y construimos vectores propios generalizados, resolviendo los sistemas 
\begin{align*}
(A-\lambda I)v &= v_0 , \text{ cuya solución llamamos } v_1 \\
(A-\lambda I)v &= v_1 , \text{ cuya solución llamamos } v_2 \\
\vdots
\end{align*}
hasta tener los $k$ vectores que necesitamos. Una vez construidos estos vectores, se construye la solución del sistema asociada a cada uno, de la forma
\begin{align*}
X_0(t) &= e^{\lambda t}v_0 \\
X_1(t) &= e^{\lambda t}(v_1 + tv_0) \\
X_2(t) &= e^{\lambda t} \left( v_2 + tv_1 + \frac{t^2}{2}v_0 \right) \\
X_3(t) &= e^{\lambda t}\left(v_3 + tv_2 + \frac{t^2}{2!}v_1 + \frac{t^3}{3!}v_0\right) \\
\vdots
\end{align*}
El patrón a seguir es el mismo que nos da la serie de Taylor de $e^x$ (esto no es ninguna casualidad, veremos en la siguiente sección qué pasó aquí). Finalmente, la solución general se expresa como siempre:
$$X(t) = C_0X_0+ \dots + C_{k-1}X_{k-1}.$$
A continuación veremos cómo proceder en caso de que algún valor propio no sea un número real. Recordemos que aunque los valores propios sean complejos, estamos trabajando con matrices $A$ que solo tengan como entradas números reales. Podemos usar el siguiente teorema.\\
\textbf{Teorema: }Sea $A$ una matriz $n \times n$ cuyas entradas sean números reales. Si $\lambda_1 = a+bi$ es un valor propio con vector propio asociado $v_1$, entonces el número $\lambda_2 = a-bi$ (el conjugado de $\lambda_1$) es también un valor propio de $A$, y su vector propio asociado es $\bar{v}$ (el vector que se obtiene al conjugar cada entrada de $v$).\\
\textbf{Ejemplo: }Considere el sistema
$$X'(t) = \begin{pmatrix} 3 & 9 \\ -4 & -3 \end{pmatrix} X.$$
El polinomio característico de esta matriz es $x^2 + 27$, por lo que los valores propios son $\pm 3 \sqrt{3}i$. Gracias al teorema anterior, solo tenemos que encontrar un autovector. Resolvamos el sistema $(A-3\sqrt{3}iI)v=0$.
$$\begin{pmatrix} 3-3\sqrt{3}i & 9 \\ -4 & -3 -3\sqrt{3}i\end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix},$$
Podemos aplicar el despeje $b = -\frac{1}{3}(1-\sqrt{3}i)a$ en la primera ecuación, por lo que una posible escogencia sería tomando $a=3$, para obtener $v_1 = (3 , -1+\sqrt{3}i)^t$. Esta escogencia nos asocia la primera solución del sistema
$$X(t) = e^{3\sqrt{3}it} \begin{pmatrix} 3 \\ -1 +\sqrt{3}i \end{pmatrix}.$$
Podemos entonces aplicar la fórmula de Euler para obtener
\begin{align*}
X(t) &= (\cos(3\sqrt{3}t) + i \sin (3\sqrt{3}t))\begin{pmatrix} 3 \\ -1 +\sqrt{3}i \end{pmatrix}\\ &= \begin{pmatrix} 3\cos(3\sqrt{3}t) + 3i \sin (3\sqrt{3}t) \\ -\cos(3\sqrt{3}t) - i \sin (3\sqrt{3}t) + \sqrt{3}i\cos(3\sqrt{3}t) -  \sqrt{3}\sin (3\sqrt{3}t) \end{pmatrix}
\end{align*}
A partir de aquí, podemos separar la parte real de la imaginaria, para poder escribir en la forma $X_1(t) + iX_2(t)$.
$$X(t) = \underbrace{\begin{pmatrix} 3\cos(3\sqrt{3}t) \\ -\cos(3\sqrt{3}t) - \sqrt{3} \sin (3\sqrt{3}t) \end{pmatrix}}_{X_1} + i \underbrace{\begin{pmatrix} 3\sen(3\sqrt{3}t) \\ -\sen(3\sqrt{3}t) - \sqrt{3} \cos (3\sqrt{3}t) \end{pmatrix}}_{X_2}.$$
Sin embargo, gracias al teorema anterior (y a una serie de manipulaciones algebraicas), podemos extraer la solución general de una sola vez, sin tener que pasar por el otro valor propio. De hecho, la solución general viene dada directamente por
\begin{align*}
X(t) &= C_1X_1(t) + C_2X_2(t)\\ &= C_1\begin{pmatrix} 3\cos(3\sqrt{3}t) \\ -\cos(3\sqrt{3}t) - \sqrt{3} \sin (3\sqrt{3}t) \end{pmatrix} + C_2\begin{pmatrix} 3\sen(3\sqrt{3}t) \\ -\sen(3\sqrt{3}t) - \sqrt{3} \cos (3\sqrt{3}t) \end{pmatrix}.
\end{align*}
Nótese que hemos eliminado todo vestigio de número complejo. Podemos resumir el método de solución para valores complejos con el siguiente corolario.\\
\textbf{Corolario: }Si $A$ es una matriz $2 \times 2$ con entradas reales, con valores propios complejos $a+bi$,$a-bi$, entonces la solución general del sistema $X'=AX$ es 
$$X= C_1 \operatorname{Re}(e^{bit}v) + C_2 \operatorname{Im}(e^{bit}v),$$
donde $v$ es un autovector asociado a $a+bi$. En otras palabras, basta con encontrar la solución asociada a uno de sus autovalores, y utilizando la identidad de Euler, separar las partes real e imaginarias de la solución. Este proceso nos da de inmediado la solución general. \\
\textbf{Ejercicios: }Resuelva el sistema $X'=AX$ para cada una de las siguientes matrices.
\vspace{10pt}
\begin{itemize}
\item $A= \begin{pmatrix} 1 & 2 \\ 3 & 2 \end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} 1 & 2 & 1 \\ 6 & -1  & 0 \\ -1 & -2 & -1\end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} -3 & 1 & 0 \\ 0 & -3  & 1 \\ 0 & 0 & -3 \end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} 2 & 2 & 2 \\ 0 & 2  & 0 \\ 0 & 1 & 3\end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} -1 & 1 & 0 \\ 1 & -1  & 1 \\ 4 & -4 & 2\end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} 3  & -13  \\ 5 & 1\end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} 2 & 2 & 2 \\ 0 & 2  & 0 \\ 0 & 1 & 3\end{pmatrix}$
\vspace{10pt}
\item $A= \begin{pmatrix} 4 & -3 & 0 \\ 3 & 4  & 0 \\ 1 & 2 & 2\end{pmatrix}$
\vspace{10pt}
\end{itemize}
\subsection{La función exponencial matricial.} Volvamos al capítulo 1 por un momento. Al resolver la ecuación 
$$y' = ay,$$
con $a \in \mathbb{R}$, podemos llegar casi inmediatamente a que la solución es $y = Ce^{ax}$. Sea ahora $A$ una matriz $n \times n$ de coeficientes constantes, y considere el sistema 
$$X' = AX.$$
En cierta forma, vamos a extender la función exponencial $e^x$ para poder calcular $e^A$ (el resultado de esta operación será una matriz del mismo tamaño que $A$). Cuando logremos hacer esto, podremos, de manera análoga con las ecuaciones de primer orden, afirmar que la solución al sistema es precisamente
$$X=e^{At}C,$$
donde $C=(C_1,\dots,C_n)^t$ es nuestro vector columna de parámetros (debemos multiplicar por la izquierda por cuestiones de tamaño). Para poder definir la operación $e^A$, tomamos prestada la serie de Taylor. \\
\textbf{Definición: }Para una matriz $A$ $n \times n$ con entradas constantes, definimos $e^A$ como
$$e^A = I + A + \frac{1}{2!}A^2 + \frac{1}{3!}A^3 + \dots = \sum_{k=0}^\infty \frac{1}{k!}A^k.$$
\textbf{Ejemplo: }La exponencial matricial es fácil de calcular cuando alguna potencia de nuestra matriz es la matriz nula. Por ejemplo, considere la matriz
$$A=\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}.$$
Note que 
$$A^2=\begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix},$$
por lo que 
$$e^A = I + A +0 + 0 + \dots =\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix} $$
\textbf{Nota: }La exponencial de una matriz $A$ \textbf{no} se obtiene exponenciando cada entrada de $A$.\\
Podemos además definir la exponencial matricial cuando multiplicamos todas las entradas de $A$ por la variable $t$, repitiendo la definición.
$$e^{At} = \sum_{k=0}^\infty \frac{t^k}{k!}A^k,$$
lo cual nos produce una función matricial. La derivada de esta función se calcula igual que con funciones de variable real,
$$\frac{d}{dt}e^{At} = Ae^{At}.$$
Es gracias a esta propiedad que vemos que en efecto, la solución general del sistema $X'=AX$ es precisamente la matriz $e^{At}C$, donde $C$ es un vector de parámetros. En otras palabras, la matriz fundamental del sistema $X'=AX$ es $ \Phi(t) = e^{At}$.\\
\textbf{Teorema: Propiedades de la exponencial matricial.} La función exponencial matricial satisface las siguientes propiedades:
\begin{itemize}
\item $e^{O}=I$, donde $O$ denota la matriz nula.
\item $e^{At}e^{As}=e^{A(t+s)}$, donde $t$ y $s$ son escalares.
\item Cuando $AB=BA$, entonces $e^Ae^B = e^{A+B}$. Esto puede ser falso si $A$ y $B$ no conmutan.
\item $(e^{At})^{-1} = e^{-tA}$, donde $t$ es un escalar.
\item Cuando $A$ es una matriz diagonal, podemos calcular $e^{A}$ simplemente exponenciando cada entrada. Es decir,
$$\exp \begin{pmatrix} a_{11} & 0 & \dots & 0 \\ 0& a_{22} & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & a_{nn}\end{pmatrix} = \begin{pmatrix} e^{a_{11}} & 0 & \dots & 0 \\ 0& e^{a_{22}} & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & e^{a_{nn}}\end{pmatrix}.$$
\end{itemize}
Estas propiedades nos ayudan a calcular más fácilmente algunas exponenciales. \\
\textbf{Ejemplo: } Si $a,b$ son números reales no nulos, calcule
$$\exp \begin{pmatrix} a & b \\ 0 & a \end{pmatrix}.$$
Para calcular esto, podemos separar la matriz de la siguente forma
$$\begin{pmatrix} a & b \\ 0 & a \end{pmatrix} = \begin{pmatrix} a & 0 \\ 0 & a \end{pmatrix} + \begin{pmatrix} 0 & b \\ 0 & 0 \end{pmatrix}.$$
Note que las dos matrices del lado derecho conmutan, por lo tanto, podemos exponenciar cada una
$$\exp \begin{pmatrix} a & 0 \\ 0 & a \end{pmatrix} =  \begin{pmatrix} e^a & 0 \\ 0 & e^a \end{pmatrix},  $$
podemos notar que, como la segunda matriz tiene cuadrado nulo, su exponencial matricial es fácil de calcular,
$$\exp \begin{pmatrix} 0 & b \\ 0 & 0 \end{pmatrix}= \begin{pmatrix} 1 & 0 \\ 0 &1 \end{pmatrix} + \begin{pmatrix} 0 & b \\ 0 & 0 \end{pmatrix}=\begin{pmatrix} 1 & b \\ 0 & 1 \end{pmatrix}.$$
Finalmente, tenemos que
\begin{align*}
\exp \begin{pmatrix} a & b \\ 0 & a \end{pmatrix} &=   \exp \left( \begin{pmatrix} a & 0 \\ 0 & a \end{pmatrix} + \begin{pmatrix} 0 & b \\ 0 & 0 \end{pmatrix} \right) \\
&= \exp\begin{pmatrix} a & 0 \\ 0 & a \end{pmatrix} \exp \begin{pmatrix} 0 & b \\ 0 & 0 \end{pmatrix}  \\
&= \begin{pmatrix} e^a & 0 \\ 0 & e^a \end{pmatrix} \begin{pmatrix} 1 & b \\ 0 & 1 \end{pmatrix} \\
&= \begin{pmatrix} e^a & be^a \\ 0 & e^a \end{pmatrix}
\end{align*}
Tenemos entonces las herramientas necesarias para resolver sistemas de ecuaciones por este medio.\\
\textbf{Ejemplo: }Encuentre la solución general del sistema
$$X' = \begin{pmatrix} -1 & 6 \\ 0 & -1 \end{pmatrix} X.$$
Tomando $$At = \begin{pmatrix} -t & 6t \\ 0 & -t \end{pmatrix}$$
y utilizando el ejemplo anterior, deducimos que
$$e^{At} = \begin{pmatrix} e^{-t} & 6te^{-t} \\ 0 & e^{-t} \end{pmatrix},$$
por lo que la solución al sistema es 
$$X(t) = e^{At}C = \begin{pmatrix} e^{-t} & 6te^{-t} \\ 0 & e^{-t} \end{pmatrix}\begin{pmatrix} C_1 \\ C_2 \end{pmatrix} = C_1\begin{pmatrix} e^{-t} \\ 0 \end{pmatrix} + C_2 \begin{pmatrix} 6t e^{-t} \\ e^{-t} \end{pmatrix}.$$
¡Es esta la razón por la que vemos tantas funciones exponenciales en la resolución de sistemas! En el fondo estamos calculando la exponencial de la matriz del sistema. \\
\textbf{Ejercicios:} Para cada matriz $A$, calcule $e^A$.
\begin{itemize}
\item $\begin{pmatrix} 0 & 1 \\ 1& 0 \end{pmatrix}$
\vspace{10pt}
\item $\begin{pmatrix} 0 & 0 & 0 \\ 3& 0 &0 \\ 5 & 1 & 0 \end{pmatrix}$
\vspace{10pt}
\end{itemize}
\textbf{Ejercicios: }Resuelva cada sistema de ecuaciones por medio de la exponencial matricial.
\begin{itemize}
\item $X' = \begin{pmatrix} 3 & 0 \\ -1& 3 \end{pmatrix}X$
\vspace{10pt}
\item $X' = \begin{pmatrix} 1 & 0 & 0 \\ 0& 2 &0 \\ 0 & 0 & 3 \end{pmatrix}X$
\vspace{10pt}
\item $X' = \begin{pmatrix} 0 & 2 & 3 \\ 0& 0 &-1 \\ 0 & 0 & 0 \end{pmatrix}X$
\vspace{10pt}
\end{itemize}
\subsection{Variación de parámetros} Hasta el momento, no hemos resuelto ningún sistema no homogéneo, es decir, de la forma
\begin{equation}\label{eqn:17}
X'(t) = A(t)X(t) + F(t)
\end{equation}
donde $F(t)$ no es nula. Recordemos que el procedimiento general para resolver sistemas no homogéneos es encontrando la solución complementaria de la homogénea $X_c$ y luego una solución particular $X_p$. La solución general vendría dada por $X_c + X_p$, como ya sabemos. Para encontrar $X_p$ utilizaremos variación de parámetros.\\
\textbf{Teorema: Método de variación de parámetros para sistemas} Para resolver el sistema \eqref{eqn:17}, se toma la matriz fundamental $\Phi(t)$, y se calcula la solución particular $X_p$ mediante la fórmula
$$X_p(t) = \Phi(t) \int \Phi^{-1}(t)F(t)dt,$$
donde $\Phi^{-1}(t)$ denota la inversa de la matriz fundamental, y la integral se calcula entrada por entrada.\\
\textbf{Ejemplo: } Resuelva el sistema
$$X' = \begin{pmatrix} -3 & 1 \\ 2 & -4 \end{pmatrix}X + \begin{pmatrix} 3t \\ e^{-t}\end{pmatrix}.$$
Primero tenemos que resolver 
$$X' = \begin{pmatrix} -3 & 1 \\ 2 & -4 \end{pmatrix}X,$$
lo cual hacemos por medio de autovalores. Los autovalores de esta matriz son $-2$ y $-5$, y sus autovectores asociados son $v_1= (1,1)^t$ y $v_2=(1,-2)$ (ejercicio). Entonces tenemos que
$$X_c = C_1\begin{pmatrix}e^{-2t} \\ e^{-2t} \end{pmatrix} + C_2 \begin{pmatrix} e^{-5t} \\ -2e^{-5t} \end{pmatrix}.$$
La matriz fundamental de este sistema es por lo tanto
$$\Phi(t) = \begin{pmatrix} e^{-2t} & e^{-5t} \\ e^{-2t} & -2e^{-5t} \end{pmatrix}.$$
Recordemos que la inversa de una matriz $2\times 2$ es muy fácil de calcular, por la fórmula 
$$\begin{pmatrix} a & b \\ c & d \end{pmatrix}^{-1} = \frac{1}{ad-bc}\begin{pmatrix} d & -b \\ -c & a \end{pmatrix}.$$
Esto nos ayuda a calcular
$$\Phi^{-1}(t) = \begin{pmatrix} \frac{2}{3}e^{2t} & \frac{1}{3}e^{2t} \\ \frac{1}{3}e^{5t} & -\frac{1}{3}e^{5t}\end{pmatrix}.$$
Entonces, solo queda aplicar la fórmula de variación de parámetros.
\begin{align*}
X_p &= \Phi(t) \int \Phi^{-1}(t)F(t)dt \\ &= \begin{pmatrix} e^{-2t} & e^{-5t} \\ e^{-2t} & -2e^{-5t} \end{pmatrix} \int \begin{pmatrix} \frac{2}{3}e^{2t} & \frac{1}{3}e^{2t} \\ \frac{1}{3}e^{5t} & -\frac{1}{3}e^{5t}\end{pmatrix} \begin{pmatrix} 3t \\ e^{-t}\end{pmatrix} dt \\
&= \begin{pmatrix} e^{-2t} & e^{-5t} \\ e^{-2t} & -2e^{-5t} \end{pmatrix}  \int  \begin{pmatrix} 2te^{2t} + \frac{1}{3}e^t \\ te^{5t}-\frac{1}{3}e^{4t}
\end{pmatrix}dt \ \\
&= \begin{pmatrix} e^{-2t} & e^{-5t} \\ e^{-2t} & -2e^{-5t} \end{pmatrix} \begin{pmatrix} te^{2t} - \frac{1}{2}e^{2t}+\frac{1}{3}e^t \\ \frac{1}{5}te^{5}-\frac{1}{25}e^{5t} - \frac{1}{12}e^{4t} \end{pmatrix} \\
&= \begin{pmatrix} \frac{6}{5}t - \frac{27}{50}+\frac{1}{4}e^{-t} \\ \frac{3}{5}t - \frac{21}{50} - \frac{1}{2}e^{-t} \end{pmatrix}.
\end{align*}
Recuerde que para evaluar la integral de un vector, simplemente integramos cada una de sus entradas por aparte. Entonces tenemos que la solución general de la ecuación es
$$X= X_c + X_p = C_1\begin{pmatrix}e^{-2t} \\ e^{-2t} \end{pmatrix} + C_2 \begin{pmatrix} e^{-5t} \\ -2e^{-5t} \end{pmatrix} +\begin{pmatrix} \frac{6}{5}t - \frac{27}{50}+\frac{1}{4}e^{-t} \\ \frac{3}{5}t - \frac{21}{50} - \frac{1}{2}e^{-t} \end{pmatrix}.$$
\textbf{Ejercicio: }Encuentre la solución general del sistema
$$X' = \begin{pmatrix} -4 & 2 \\ 2 & -1 \end{pmatrix} X + \begin{pmatrix} \frac{1}{t} \\ \frac{2}{t} \end{pmatrix}.$$
\subsection{Ecuaciones de orden superior y sistemas.} A lo largo de esta sección, hemos notado muchas similitudes con la sección de ecuaciones de orden superior: espacio de solución, criterio de Wronskiano, solución complementaria, solución particular. Practicamente todos los conceptos tienen su contraparte en el tema de EDOs de orden superior. La razón de esto es muy sencilla: \textbf{Toda ecuación diferencial lineal de orden superior puede convertirse en un sistema de ecuaciones lineales de primer orden.} La forma de hacer esto es muy sencilla, simplemente introducimos variables adicionales, una por cada derivada.\\
\textbf{Ejemplo: }Considere la ecuación diferencial
$$x(t)''' + 3x(t)'' + 3x(t)' + x(t) = 0.$$
Sabemos, por la teoría de EDOs lineales con coeficientes constantes, que la solución general es 
$$x= C_1e^{-t} + C_2te^{-t} + C_3t^2e^{-t}.$$
Vamos a convertirla en un sistema de orden 1. Defina las variables $x_1 = x$ , $x_2 = x'$ , $x_3 = x''$. Entonces la ecuación original se convierte en 
$$x_3 ' = -x_1 - 3x_2 - 3x_3.$$
Ahora, derivando las definiciones de las nuevas variables, obtenemos suficientes ecuaciones como para convertir la ecuación de orden superior en el sistema de ecuaciones
$$\begin{cases} x_1' = x_2 \\
x_2' = x_3 \\
x_3' =  -x_1 - 3x_2 - 3x_3
\end{cases}.$$
Tomando $X=(x_1,x_2,x_3)^t$, debemos resolver el sistema
$$X' = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ -1 & -3 & -3 \end{pmatrix}X.$$
El único valor propio de esta matriz es $-1$. Resolvemos el sistema
$$(A+I)v =  \begin{pmatrix} 1 & 1 & 0 \\ 0 & 1 & 1 \\ -1 & -3 & -2 \end{pmatrix}\begin{pmatrix} a \\ b \\c \end{pmatrix}.$$
Encontramos que el único autovector l.i de esta matriz es $v_0 = (1,-1,1)^t$. Entonces resolvemos el sistema $(A+I)v=v_0$, cuya solución es $v_1$, y luego el sistema $(A+I)v = v_1$ cuya solución es $v_2$. En resumen, los vectores propios generalizados son $v_1 = (1,0,-1)^t$ y $v_2 = (1,0,0)^t$. Podemos seguir la fórmula que estudiamos para este caso (página 103), para encontrar las soluciones
\begin{align*}
X_1 &= e^{-t}v_0 = \begin{pmatrix} e^{-t} \\ - e^{-t} \\  e^{-t} \end{pmatrix} \\
X_2 &= e^{-t}(v_1 + tv_0) = e^{-t}\begin{pmatrix}1+t \\ -t \\ -1+t \end{pmatrix} \\
X_3 &= e^{-t} (v_2 + tv_1 + \frac{t^2}{2}v_0) = e^{-t}\begin{pmatrix}1+t +\frac{t^2}{2}\\ -\frac{t^2}{2} \\ -t + \frac{t^2}{2} \end{pmatrix} 
\end{align*}
Por lo que la solución general del sistema es
$$\begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = K_1 \begin{pmatrix} e^{-t} \\ - e^{-t} \\  e^{-t} \end{pmatrix} + K_2e^{-t}\begin{pmatrix}1+t \\ -t \\ -1+t \end{pmatrix} +K_3e^{-t}\begin{pmatrix}1+t +\frac{t^2}{2}\\ -\frac{t^2}{2} \\ -t + \frac{t^2}{2} \end{pmatrix} .$$
Como $x_1 = x$, la solución de la ecuación original viene dada por la primera entrada de este vector,
$$x= K_1e^{-t} + K_2e^{-t}(1+t) + K_3e^{-t}(1+t+\frac{t^2}{2}).$$
Para llegar a la misma solución, debemos hacer un pequeño renombramiento de las constantes. Tome $C_1 = K_1+K_2+K_3$, $C_2 = K_2 + K_3$, y $C_3 = \frac{K_3}{2}$, para llegar a la solución que obtuvimos al principio.
$$x= C_1e^{-t} + C_2te^{-t} + C_3t^2e^{-t}.$$
Es claro sin embargo, que en la mayoría de los casos este método no es eficiente de aplicar. Es mucho más sencillo simplemente hallar los ceros de la ecuación característica.\\
\textbf{Ejercicio: }Resuelva la ecuación
$$x'' +11x' + 30x = e^t$$
cambiándola en un sistema de ecuaciones lineales.
\newpage
\section{La Transformada de Laplace}
En matemática, cuando tenemos un problema difícil de resolver, es usual encontrarnos con métodos de solución que consistan en \textit{transformar} nuestro problema en otro aparentemente distinto, que sí podamos solucionar, y luego \textit{destransformar} la solución de este nuevo problema, para obtener la solución de nuestro problema original. A lo largo del curso, de hecho, hemos aplicado este principio a las ecuaciones diferenciales: hemos visto que resolver una ecuación homogénea es casi lo mismo que factorizar un polinomio, o que resolver un sistema de ecuaciones es equivalente a encontrar valores propios (lo cual en el fondo también es factorizar un polinomio). En este último tema vamos a desarrollar una poderosa herramienta que nos permitirá resolver muchas más ecuaciones diferenciales, en especial, aquellas en donde participen funciones que \textit{no son continuas.} Primero, debemos definir la \textbf{transformada de Laplace}, un importante operador integral.\\
\textbf{Definición:} Sea $f:[0,+ \infty) \to \mathbb{R}$ una función integrable. La transformada de Laplace de $f(t)$ es una nueva función $L\{f(t)\}(s)$ de variable $s$, dada por la siguiente integral impropia
$$\LL\{f(t)\}(s) = \int_0^{\infty}e^{-st}f(t)dt.$$
\textbf{Nota: }Para algunos valores de $s$, la integral anterior podría no converger. En dado caso, no es posible definir $\LL\{f(t)\}(s)$. También denotaremos la transformada de $f$ por $\LL[f]$ cuando no tengamos ambigüedad.\\
\textbf{Ejemplo: } Usando la definición, calculamos la transformada $\LL\{f(t)\}(s)$ para $f(t) =1$, la función constante.
\begin{align*}
\LL\{1\} &= \int_0^{\infty}e^{-st}dt \\
&=\lim_{b \to \infty} \int_0^{b}e^{-st}dt\\
&= \lim_{b \to \infty} \left[ \frac{e^{-st}}{-s} \right]_{t=0}^{t=b}\\
&=\lim_{b \to \infty} \frac{1-e^{-sb}}{s} \\
&= \frac{1}{s}
\end{align*}
puesto que $e^{-sb}$ tiene a $0$ cuando $b$ tiende a $+\infty$, siempre y cuando $s>0$. Note que si $s$ es negativo, la integral diverge. \\ 
\textbf{Ejercicio: } Utilizando la definición, calcule $\LL \{t\}(s)$.\\
\textbf{Ejemplo: } Calculemos $\LL\{e^{-3t}\}(s)$.
\begin{align*}
\LL\{e^{-3t}\}(s)&= \int_0^{\infty}e^{-st}e^{-3t}dt\\
&= \lim_{b \to \infty} \int_0^{b}e^{-(s+3)t}dt \\
&= \lim_{b \to \infty} \left[-\frac{e^{-(s+3)t}}{s+3} \right]_0^{b} \\
&= \lim_{b \to \infty} \frac{1-e^{-(s+3)t}}{s+3} \\
&= \frac{1}{s+3}
\end{align*}
siempre y cuando $s>-3$, para que el término $e^{-(s+3)b}$ pueda ir para $0$ cuando $b$ va hacia $\infty$.\\
\textbf{Ejemplo:} Calculemos ahora $\LL[\sen(2t)]$. Sabemos primero que (integrando por partes)
$$I=\int e^{-st}\sen(2t)dt = \frac{-e^{-st} \sen(2t)}{s} + \frac{2}{s} \int e^{-st}\cos(2t)dt.$$
Haciendo la segunda integral, también por partes,
$$\int e^{-st}\cos(2t)dt = \frac{-e^{-st} \cos(2t)}{s} - \frac{2}{s} \int e^{-st}\sen(2t)dt.$$
Sustituyendo esto en la integral original, obtenemos
\begin{align*}
I &= \frac{-e^{-st} \sen(2t)}{s} + \frac{2}{s} \left( \frac{-e^{-st} \cos(2t)}{s} + \frac{2}{s}I \right)\\ 
&= \frac{-e^{-st} \sen(2t)}{s} + \frac{-2e^{-st} \cos(2t)}{s^2} - \frac{4}{s^2} I
\end{align*}
Ahora podemos evaluar en los límites de integración,
$$\LL \{ \sen(2t)\}(s) =  \frac{-e^{-st} \sen(2t)}{s} \bigg \rvert_0^\infty + \frac{-2e^{-st} \cos(2t)}{s^2}\bigg \rvert_0^\infty - \frac{4}{s^2} \LL \{ \sen(2t)\}(s)$$
Para no hacer demasiados pasos, entendamos que evaluar en el límite de integración igual a $\infty$, equivale a evaluar en $b$ y luego enviar $b \to \infty$. Con esto, vemos que el primer sumando de la última expresión es $0$, pues en $\infty$, la exponencial se anula y en $0$, el seno se anula. El segundo sumando sin embargo, se convierte en $\frac{2}{s^2}$, puesto que en $\infty$, la exponencial se anula, mientras que en $0$, se tiene que $-2e^{-s0}\cos(0)=-2$, y el $-$ se cancela con el $-$ que proviene de la resta de los límites de integración. Tenemos entonces que
$$\LL \{ \sen(2t)\}(s) = \frac{2}{s^2} - \frac{4}{s^2}\LL \{ \sen(2t)\}(s)$$
Finalmente al despejar, obtenemos que
$$\LL \{ \sen(2t)\}(s) = \frac{2}{s^2 +4}, \quad  \text{ para } s > 0$$
\textbf{Nota:} Recordemos que la integral de la transformada de Laplace tiene variable $t$, por lo que la $s$ se trata como una constante durante el proceso de integración.\\
\textbf{Teorema: Linealidad de la transformada de Laplace.} Si $f$,$g$ son funciones y $\lambda \in \C$ es un escalar, entonces
$$\LL \{f(t) + \lambda g(t) \}(s) = \LL \{ f(t)\}(s) + \lambda \LL \{g(t) \}(s).$$
En otras palabras: para calcular transformadas, podemos sacar escalares y separar las sumas.\\
\textbf{Ejercicios: }Utilizando la definición y propiedades, calcule las siguientes transformadas de Laplace:
\begin{enumerate}
\item $\LL \{ t^2+t+1\}(s)$
\item $\LL \{ 4e^{-5t} - 10 \sen(2t)\}(s)$
\item $\LL \{ \cos(t)\}(s)$
\item $\LL \{ e^{\omega t}\}(s)$, con $\omega \in \R$.
\end{enumerate}
En general, no necesitaremos calcular siempre la transformada. A partir de algunas transformadas básicas que podemos aprender y de sus propiedades, podemos calcular muchas transformadas sin necesidad de integrar.\\
\textbf{Algunas transformadas básicas:} Sea $\omega \in \R$
\begin{enumerate}
\item $\LL \{ 1\}(s) = \dfrac{1}{s}$
\vspace{8pt}
\item $\LL \{ e^{\omega t}\}(s) = \dfrac{1}{s-\omega}$
\item $\LL \{ t^n\}(s) = \dfrac{n!}{s^{n+1}}$. Para $n= 1,2,3,\dots$.
\vspace{8pt}
\item $\LL \{ \sen(\omega t)\}(s) = \dfrac{\omega}{s^2 + \omega^2}$
\vspace{8pt}
\item $\LL \{ \cos(\omega t)\}(s) = \dfrac{s}{s^2 + \omega^2}$
\vspace{8pt}
\item $\LL \{ \senh(\omega t)\}(s) = \dfrac{\omega}{s^2-\omega^2}$
\vspace{8pt}
\item $\LL \{ \cosh(\omega t)\}(s) = \dfrac{s}{s^2-\omega^2}$
\end{enumerate}
Es recomendable elaborar una ficha o una tabla donde vaya anotando las distintas transformadas de las funciones, además de las propiedades de la transformada misma.\\
Como hemos mencionado, no siempre se tiene que $\LL[f]$ existe. Por ejemplo, no es posible calcular $\LL[1/t]$, ni $\LL[e^{t^2}]$. Para que $\LL[f]$ exista, deben suceder dos cosas. \pagebreak \\
\textbf{Teorema: } Si $f(t)$ cumple las siguientes dos condiciones: 
\begin{enumerate}
\item Es continua a trozos en $[0,\infty)$. Es decir, que solo tenga un número finito de discontinuidades.
\item Es de \textit{orden exponencial.}
\end{enumerate}
Entonces $f(t)$ posee transformada de Laplace.\\
Debemos especificar qué significa que $f$ tenga \textit{orden exponencial.}\\
\textbf{Definición: } Se dice que una función $f$ es de \textbf{orden exponencial} si existen constantes $c,T > 0$ tales que para todo $t > T$, se cumpla
$$ |f(t)| \leq Me^{ct}.$$
En palabras más sencillas, una función es de orden exponencial si la gráfica de su magnitud es superada eventualmente por la de alguna función exponencial.\\
\textbf{Ejemplos:}
\begin{itemize}
\item Todos los polinomios $p(t)$ tienen orden exponencial.
\item Las funciones $\sin(kt)$ ,$\cos(kt)$ tienen orden exponencial. 
\item La función $e^{t^2}$ no tiene orden exponencial (demuéstrelo). A continuación una justificación gráfica de ésto.
\end{itemize}
\begin{figure}[h]
 \center
        \includegraphics[scale=0.60]{Recorte10.png}
        
        Gráfica de $e^{t^2}$ (verde) junto con las gráficas de $e^{ct}$ para $c= 1,2,\dots,10$ (naranja). Observe que eventualmente la gráfica verde le gana todas las demás.
\end{figure}
Una manera equivalente de expresar que una función $f$ es de orden exponencial es: si para algún $k$, se tiene que
$$\lim_{t \to \infty} \frac{f(t)}{e^{kt}} = 0.$$
\subsection{Propiedades de la transformada de Laplace.}
En esta sub-sección estudiaremos algunas propiedades que extienden nuestra capacidad de cálculo de transformadas.\\
\textbf{Teorema:} Sea $a > 0$ 
$$\LL \{f(at) \}(s) = \frac{1}{a}\LL \{f(t) \}\left(\frac{s}{a}\right) $$
\textbf{Prueba:} Solo hay que aplicar la definición.
\begin{align*}
\LL \{f(at) \}(s) &= \int_0^\infty e^{-st}f(at)dt ,\text{ tomamos $u= at$ } \\
&= \frac{1}{a} \int_0^\infty e^{-s \frac{u}{a}}f(u)du \\
&= \frac{1}{a}\LL \{ f(u) \} \left(\frac{s}{a}\right)
\end{align*}
Note que en el último paso nos quedó $u$ como variable de $f$. Esto no afecta para nada nuestro cálculo, pues ya sabemos que las variables de integración pueden tener cualquier nombre. En resumen, para calcular la transformada de $f(at)$, calculamos primero la transformada de $f(t)$, y cambiamos la $s$ por $s/a$.\\
\textbf{Ejemplo: } Sabemos que $\LL[e^t] = \frac{1}{s-1}$. Apliquemos el teorema anterior para calcular $\LL[e^{\omega t}]$,
\begin{align*}
\LL\{e^{\omega t}\}(s) &= \frac{1}{\omega} \LL\{e^{t}\}\left(\frac{s}{\omega}\right)\\
&= \frac{1}{\omega} \left( \frac{1}{\frac{s}{\omega}-1} \right) \\
&= \frac{1}{s-\omega}
\end{align*}
\textbf{Ejercicio: } Use este teorema para demostrar la fórmula de transformada de $\sen(\omega t)$ y $\cos (\omega t)$, a partir de la transformada de $\sen(t)$ y $\cos(t)$, respectivamente.\\
\textbf{Teorema: } Sea $\omega \in \R$, entonces
$$\LL\{e^{wt}f(t)\}(s)  = \LL\{f(t) \}(s-w)$$
\textbf{Prueba: } También por definición,
$$\LL\{e^{wt}f(t)\}(s)  = \int_0 ^\infty e^{\omega t}e^{-st}f(t)dt = \int_0 ^\infty e^{-(s-\omega)t}dt = \LL \{f(t)\} \
(s-\omega).$$
En otras palabras, para calcular la transformada de $e^{\omega t} f(t)$, primero calculamos la transformada de $f(t)$, y luego cambiamos la $s$ por $s-\omega$.\\
\textbf{Ejemplo: } Calcule $\LL\{ e^{5t} \sin{4t}\}(s)$.\\
Sabemos que $\LL[\sin 4t] = \frac{4}{s^2+16}$. Aplicando el teorema anterior, tenemos que
$$\LL\{ e^{5t} \sin{4t}\}(s) = \LL \{ \sin{4t} \}(s-5) = \frac{4}{(s-5)^2 + 16}.$$
\textbf{Teorema:} Para todo $n \in \mathbb{N}$, se cumple que
$$\LL \{ t^n f(t)\} = (-1)^n \frac{d^n}{ds^n} \LL \{ f(t) \}(s)$$
\textbf{Prueba: } Hay que usar la definición e inducción matemática. No nos interesa conocer la prueba en detalle.\\
En otras palabras, para calcular la transformada de $t^n f(t)$, primero calculamos la transformada de $f(t)$, luego la derivamos $n$ veces con respecto a $s$, y multiplicamos por $(-1)^n$.
\\
\textbf{Ejemplo: }Calcule $\LL \{ t \cos t \}(s)$.
\\ Sabemos que $\LL [\cos(t)] = \frac{s}{s^2 + 1}$. Entonces podemos aplicar el teorema anterior.
\begin{align*}
\LL \{ t \cos(t) \} &= -\frac{d}{ds} \left( \frac{s}{s^2+1} \right) \\
&= \frac{s^2-1}{(s^2 + 1)^2}
\end{align*}
\textbf{Ejercicio: }Calcule $\LL \{ t \sen(3t) \}$.\\
\textbf{Teorema: }
$$\LL \left[\frac{f(t)}{t} \right] = \int_s ^ \infty \LL \{f(t)\}(x)dx.$$
Es decir, para calcular la transformada de $f(t) /t$, primero calculamos la de $f(t)$, y luego integramos lo que quede desde $s$ hasta $\infty$ (necesitamos una variable de integración distinta de $s$).\\
\textbf{Ejemplo: } 
$$\LL \left \{\frac{\sen(t)}{t} \right \} = \int_s^\infty \frac{dx}{1+x^2} = \arctan(x)\big\rvert_s^{\infty} = \frac{\pi}{2} - \arctan(s).$$
\pagebreak

\textbf{Teorema: Transformada de una derivada.} Esta es una de las propiedades más importantes de la transformada de Laplace, es la que nos permitirá más adelante resovler EDO's. Suponga que $f$ es una función cuyas derivadas son todas de orden exponencial (esto solo lo agregamos para que su transformada exista), entonces
\begin{align*}
\LL\{f'(t)\}(s) &= s \LL \{f(t) \}(s) - f(0)\\
\LL\{f''(t)\}(s) &= s^2\LL \{f(t) \}(s) - sf(0) - f'(0).\\
\LL \{f'''(t) \}(s) &= s^3 \LL \{f(t) \}(s) - s^2 f(0) - s f'(0) -  f''(0)\\ 
\vdots  \\
\LL\{f^{(n)}(t)\}(s) &= s^n\LL \{f(t) \}(s) - \sum_{k=0}^{n-1} s^{n-k-1}f^{(k)}(0).
\end{align*}
\textbf{Demostración: } Vamos a demostrar el caso para la primera derivada ($n=1$). El caso general sigue por inducción, aunque la esencia de la demostración es la misma que para el caso base. Tenemos que calcular entonces
$$\LL\{ f'(t) \}(s) = \int_0 ^\infty e^{-st}f'(t)dt.$$
Vamos a aplicar integración por partes, utilizando $u = e^{-st}$ y $dv = f'(t)dt$.
\begin{align*}
\LL\{ f'(t) \}(s) &= f(t)e^{-st}\big\rvert_0^\infty + s\int_0^\infty e^{-st}f(t)dt.\\
&= \lim_{b \to \infty} \frac{f(b)}{e^{-sb}} - f(0) + s\LL\{ f(t)\}
\end{align*}
El límite tiende a 0, pues estamos asumiendo que $f$ es de orden exponencial, por lo que obtenemos que
$$\LL \{ f'(t)\}(s) = s \LL \{f(t) \}(s) - f(0)$$
\flushright{QED}
\justify
\textbf{Ejemplo: } Calcule $\LL \{ t^n \}$. \\
Note que, si $f(t) = t^n$, derivando $n$-veces, se puede ver que $f^{(n)}(t) = n!$, entonces por el teorema anterior, podemos ver entonces que
\begin{align*}
\LL\{ f^{(n)}(t) \}&= \LL\{n!\}(s)\\ 
&= s^n \LL \{ t^n \}(s) - s^{n-1}f(0) - s^{n-2}f'(0) - s^{n-3}f''(0) - \dots - sf^{(n-2)}(0) - f^{(n-1)}(0)
\end{align*}
Note que las primeras $n-1$ derivadas de $t^n$ son de la forma $Ct^k$, con $k>0$ (es decir todas tienen un factor de $t$). Esto hace que al evaluarlas en $0$ se anulen, lo cual simplifica la fórmula anterior,
$$\LL\{n!\}(s) = s^n \LL \{ t^n \}.$$
Finalmente, como las constantes pueden salir de la transformada, $\LL \{n! \} = n! \LL \{ 1 \} = n!/s$, al despejar $\LL\{ t^n \}$, se obtiene
\begin{align*}
\LL \{ t^n \} = \frac{n!}{s^{n+1}}
\end{align*}
Finalmente, como última propiedad de la transformada, vemos un corolario de este teorema.\\
\textbf{Teorema: Transformadada de Laplace de una integral} 
$$\LL \left[ \int_0^t f(u)du\right] = \frac{1}{s}\LL [f]$$
\textbf{Demostración: } la dejamos como ejercicio, utilice que la derivada de $\int_0^t f(u)du$ es $f(t)$, junto con el teorema anterior.\\
\textbf{Ejemplo: }Calculemos $\LL \{\int_0^t u\sen(u)du \}$.\\
Usando un teorema anterior, podemos calcular que $\LL \left\{t \sen(t)\right\}(s) = \frac{2s}{(s^2+1)^2}$. Gracias al teorema que acabamos de postular, podemos concluir que
$$\LL \left\{ \int_0^t u \sen(u) du \right \} = \frac{2}{(s^2+1)^2}.$$
En cierto modo, transformar una derivada equivale a \textit{multiplicar} por $s$ la transformada original (y restarle un polinomio $p(s)$), mientras que transformar una integral equivale a \textit{dividir} por $s$ la transformada original. Esta propiedad de convertir las operaciones propias del cálculo a operaciones algebraicas será clave a la hora de resolver EDOs.\\
\textbf{Ejercicio: }Calcule las siguientes transformadas de Laplace. Puede utilizar la definición y todos los teoremas que faciliten sus cálculos.
\begin{itemize}
\item $\LL \{e^t t \sen(t) \}$.
\item $\LL \{t^2 \cos(6t) \}$.
\item $\LL \{ t^2 e^{2t} \senh t\}$.
\item $\LL \{ y'(t)\}$, si $y(t) = \cos(kt)$.
\item  $\LL \{ y'(t)\}$, si $y(t) = t\sen(kt)$.
\item  $\LL \{ y'(t)\}$, si $y(t) = e^{-t}\sen(t)$.
\item $\LL \left\{ \int_0^t e^{-u} \cosh (u)du \right\}$.
\item $\LL \left\{ te^t \int_0 ^t \sen(2u)du \right\}$.
\end{itemize}
\pagebreak
\subsection{Funciones especiales y sus transformadas.}
En esta subsección estudiaremos algunas funciones que serán de gran utilidad a la hora de resolver ecuaciones diferenciales.\\
\textbf{Definición: }Sea $T>0$. Una función $f$ se dice ser \textbf{periódica de periodo} $T$ (o $T$-periódica) , si se cumple que para todo $x$
$$f(x+T) = f(x).$$
Por ejemplo, $\sen(x)$ y $\cos(x)$ son funciones $2\pi-$periódicas. Gráficamente, las funciones periódicas tienen la propiedad de que su gráfica se repite cada vez que recorre una distancia de $T$.

\begin{figure}[h]
 \center
        \includegraphics[scale=0.45]{recorte11.png}
        
        Gráfica de una función $1$-periódica en el intervalo $[0,4]$.
\end{figure}
Existe una fórmula que nos permite calcular la transformada de cualquier función $T$-periódica.\\
\textbf{Teorema: }Sea $f$ una función $T$-periódica. Entonces
$$\LL \{ f(t) \}(s) = \frac{1}{1-e^{sT}}\int_0^Te^{-st}f(t)dt.$$
Es decir, en vez de tener que integrar de $0$ a $\infty$, solo tenemos que integrar de $0$ a $T$ (o sea el área bajo un periodo de la curva), y dividir el resultado por $(1-e^{sT})$.\\
\textbf{Ejemplo: } Considere la función $g:[0,1] \to \R$ dada por 
$$g(t) = \begin{cases}
0 \text{ si } 0 \leq t \leq \frac{1}{2} \\
1 \text{ si } \frac{1}{2} \leq t \leq 1
\end{cases}$$
Ahora, extienda dicha función periódicamente a todo $\mathbb R$, de manera que se obtenga una nueva función $1$-periódica $f: [0,\infty) \to \R$ con la siguiente gráfica \pagebreak

\begin{figure}[h]
 \center
        \includegraphics[scale=0.50]{recorte12.png}
        
        Gráfica de $f(t)$.
\end{figure}
En otras palabras, $f$ es una repetición periódica de la función $g$.
Usando la fórmula anterior, podemos calcular $\LL \{ f(t) \} (s)$.
\begin{align*}
\LL \{ f(t) \} (s) &= \frac{1}{1-e^s}\int_0^1 e^{-st}f(t)dt \\
&= \frac{1}{1-e^s}\int_{\frac{1}{2}}^1 e^{-st}dt \\
&= \frac{1}{1-e^s} \left[-\frac{e^{-st}}{s} \right]_\frac{1}{2}^1 \\
&= \frac{e^{-\frac{s}{2}} - e^{-s}}{s(1-e^s)}.
\end{align*}
\textbf{Ejercicio: }Considere la función $g(t) = t$ definida en $[0,1]$. Extienda $g$ periódicamente a una función $1$-periódica $f(t)$ definida en $[0,\infty)$, seguidamente calcule $\LL \{f(t)\}(s)$. \textit{Sugerencia:} dibuje la gráfica de $f$.\\
La siguiente función es muy simple, pero será de gran importancia.\\
\textbf{Definición: }Sea $a \in \R$. Definimos la función de \textbf{Heaviside} (o escalón unitario), como la función $H_a : \R \to \R$ dada por \footnote{La función de Heaviside tiene muchas notaciones alternativas: $H_a(t), U(t-a) , \theta(t-a) , \mathcal{H}(t-a)$, todas tienen el mismos significado. Note además que con nuestra definición se tiene que $H_a(t) = H_0(t-a)$.}
$$H_a(t) = \begin{cases}
0 \text{ si } t \leq a \\
1 \text{ si } t > a
\end{cases}$$
Simplemente es una función que vale $0$ antes del tiempo $t=a$, y luego del tiempo $t=a$ vale $1$. Podemos ver esta función como una especie de \textit{interruptor} matemático, puesto que al multiplicarla por otra función $f$, tiene el efecto de anularla antes del tiempo $a$, y habilitarla luego del tiempo $a$.

\begin{figure}[h]
 \center
        \includegraphics[scale=0.50]{recorte13.png}
        
        Gráfica de $H_2(t) \cos(t)$.
\end{figure}
\pagebreak
Podemos entonces expresar funciones definidas a trozos utilizando esta función. \\
\textbf{Ejemplo: }Considere la siguiente función
\begin{align*}
f(t) = \begin{cases}
t^2  &\text{ si } 0 \leq t < 1\\
e^t &\text{ si }  1 \leq t < 5 \\
\cos(t) &\text{ si } 5 \leq t
\end{cases}
\end{align*}
Podemos expresar $f(t)$ como una sola función de la siguiente forma: para el primer tramo, con $t \in [0,1)$, podemos definir $f_1(t) = t^2 (H_0(t) - H_1(t))$. Note que la acción del término $(H_0(t) - H_1(t))$ hace que $f_1$ valga $t^2$ dentro del intervalo $[0,1)$, y $0$ afuera de él ; podemos pensar que $H_0(t)$ \textit{enciende} a $t^2$ a partir de $t=0$, mientras que $-H_1(t)$ \textit{apaga} (gracias a su signo negativo) la función después de $t=1$, ya que necesitamos cambiar el valor de la función global $f$ en los siguientes tramos. Continuando con este razonamiento, podemos definir $f_2(t) = e^t (H_1(t) - H_5(t))$, y $f_3(t) = H_5(t) \cos(t)$ (note que $f_3$ ya no necesita anularse). Juntado los tres tramos, podemos observar entonces que 
\begin{align*}
f(t) &= f_1(t) + f_2(t) +f_3(t) \\
&=  t^2 (H_0(t) - H_1(t)) + e^t (H_1(t) - H_5(t)) + H_5(t) \cos(t)
\end{align*}
Estudiemos ahora la transformada de Laplace de esta función.
\begin{align*}
\LL \{ H_a (t)\}(s) &= \int_0 ^\infty e^{-st}H_a(t)dt \\
&= \int_a^\infty e^{-st}dt \\
&= -\frac{e^{-st}}{s}\bigg\rvert_a^{\infty}\\
&= \frac{e^{-as}}{s}
\end{align*}
El siguiente teorema nos ayudará a calcular transformadas de funciones como la del ejemplo anterior.\\
\textbf{Teorema: }Sea $a > 0 $. Entonces
$$\LL \{ H_a(t)f(t-a) \} (s) = e^{-as}\LL \{ f(t) \}(s)$$
En otras palabras, para calcular la transformada de $H_a(t)f(t-a)$, primero debemos calcular la transformada de $f(t)$ y luego multiplicarla por $e^{-as}$. Note que si la función a transformar no tiene su argumento en la forma $t-a$, debemos hacer el ajuste. \\
\textbf{Ejemplo:} Calcule $\LL [H_2(t) e^{5(t-2)}]$.\\
Podemos aplicar el teorema directamente.
$$\LL \{H_2(t) e^{5(t-2)}\}(s) = e^{-2s}\LL \{ e^{5t}\}(s) = \frac{e^{-2s}}{s-5}$$
\textbf{Ejemplo: } Calcule $\LL \{ H_2(t) e^{5t}\}$.\\
Note que el argumento no está en la forma $t-2$, entonces debemos sumar y restar $2$. Observe que $e^{5t} = e^{5(t-2) +10}$, entonces podemos aplicar el teorema.
\begin{align*}
\LL \{ H_2(t) e^{5t} \} &= \LL \{H_2(t) e^{5(t-2) + 10} \} \\
&= e^{10}\LL \{ H_2(t) e^{5(t-2)}\}\\
&= \frac{e^{-2s+10}}{s-5}
\end{align*}
\textbf{Ejercicio:} Calcule la transformada de Laplace de la siguiente función
$$f(x) = \begin{cases}
t^2  &\text{ si } 0 \leq t < 1\\
e^t &\text{ si }  1 \leq t < 5 \\
\end{cases}$$
La siguiente función que estudiaremos es muy particular, en el sentido que no puede ser estrictamente clasificada como una función. Sin embargo, podremos tratarla como tal sin mayor problema a la hora de hacer cálculos.\\
\textbf{Definición: } Sea $a \in \R$. Se define la \textbf{delta de Dirac} como la ``función'' definida por
$$\delta_a(t) = \begin{cases}
0 \text{ si } t \neq a \\
\infty \text{ si } t = a
\end{cases}$$
Podemos pensar la delta de Dirac como una especie de \textit{impulso}. Una función que vale $0$ en todo punto, pero que en $a$ vale infinito. Esto le da a la función amplios usos en física, especialmente en la teoría de electricidad. Las funciones en $\R$ no pueden tomar el valor $\infty$, por esto es que la $\delta$ no se puede considerar como tal en sentido estricto. No profundizaremos más en esto, por lo que el estudiante interesado puede investigar en la web. Un propiedad interesante de la $\delta$ de Dirac es que para cualquier función $f(t)$, se cumple que
$$\int_0 ^ \infty f(t) \delta_a(t)dt = f(a)$$
Esto nos ayudará a calcular su transformada de Laplace.\\
\textbf{Teorema: } Sean $a \in \R$ y $f(t)$ una función. Entonces
$$\LL \{ f(t)\delta_a(t)\} = f(a)e^{-as}.$$
\textbf{Demostración: }Usaremos la propiedad que acabamos de mencionar

$$\LL \{ f(t)\delta_a(t)\} = \int_0 ^\infty e^{-st}f(t)\delta_a(t)dt = e^{-as}f(a) $$
\textbf{Corolario: } $\LL \{ \delta_a(t)\}= e^{-as}.$\\
\textbf{Ejercicio: } Calcule $\LL \{H_{2020}(t) \delta_{2021}(t) \}(s)$.\\
La última función especial que estudiaremos la función gamma $\Gamma$. Esta función es ampliamente usada en la probabilidad moderna, pues es un análogo continuo a la operación factorial (que es discreta).\\
\textbf{Definición: } Para $t >0$ se define la \textbf{función gamma} por
$$\Gamma(t) = \int_0 ^ \infty e^{-x}x^{t-1}dx.$$
Calculemos primero $\Gamma(1)$.
$$\Gamma(1) = \int_0 ^ \infty e^{-x}x^{1-1}dx =\int_0 ^ \infty e^{-x}dx = -e^{-x}\big\rvert_0^\infty = 1.  $$
La propiedad principal de $\Gamma$ es que
$$\Gamma(t+1) = t\Gamma(t).$$
Esto se puede demostrar integrando por partes, tomando $dv = e^{-x}$ y $u = x^{t}$.
$$\Gamma(t+1) =  \int_0 ^ \infty e^{-x}x^{t}dx = -x^te^{-x}\bigg\rvert_0^\infty + t \int_0^\infty e^{-x}x^{t-1}dx = t\Gamma(t)$$
Note que el primer sumando se anula completamente, pues se anula tanto en $\infty$ como en $0$. Combinando esta propiedad con el hecho que $\Gamma(1)=1$, podemos ver que
\begin{align*}
\Gamma(2) &= 1\Gamma(1) = 1\\
\Gamma(3) &= 2\Gamma(2) = 2 \cdot 1 \\
\Gamma(4) &= 3\Gamma(3) = 3 \cdot 2 \cdot 1 \\
\Gamma(5) &= 4\Gamma(4) = 4 \cdot 3 \cdot 2 \cdot 1\\
&\vdots \\
\Gamma(n&+1) = n!
\end{align*}
La gran ventaja que tiene $\Gamma$ sobre el factorial es que podemos evaluarla en el número que deseemos. No tiene mucho sentido en pensar en el número $(-1/2)!$ en el sentido clásico, sin embargo, sí podemos calcular $\Gamma(1/2)$.
\begin{align*}\Gamma \left(\frac{1}{2} \right) &= \int_0^\infty \frac{e^{-x}}{\sqrt{x}}dx  \text{ tomamos } u= \sqrt{x}\\
&= 2\int_0^\infty e^{-u^2}du\\ &= \sqrt{\pi}
\end{align*}
Esta última integral se conoce como la integral Gaussiana. Calcularla es un poco díficil ya que no podemos aplicar el TFC, por lo tanto es bueno conocerla de memoria.
$$\int_{-\infty}^{\infty} e^{-x^2}dx = 2\int_0^\infty e^{-x^2}dx =  \sqrt{\pi}$$
Tenemos entonces la ``identidad informal''
$$\left( -\frac{1}{2}\right)! = \Gamma\left( \frac{1}{2}\right) = \sqrt{\pi}$$
En esta sección hemos definido el valor $\Gamma(t)$ únicamente para $t>0$. La razón de esto es que si intentamos evaluar la función gamma en un número negativo, la integral que debemos calcular diverge. Es posible sin embargo, utilizando algunas técnicas avanzadas, extender la función $\Gamma(z)$ a (casi) cualquier número complejo $z \in \mathbb{C}$.\\
La función $\Gamma(t)$ nos ayuda calcular muchas transformadas más.\\
\textbf{Ejemplo: } Sea $r > -1$ cualquier número real. Entonces
\begin{alignat*}{2}
\LL \{ t^r \}(s) &= \int_0^\infty e^{-st}t^rdt \quad  &&\text{ tomamos } u=ts \rightarrow du = sdt  \\
&= \int_0 ^\infty e^{-u} \left( \frac{u}{s}\right)^r \frac{du}{s} \quad &&\text{ las $s$ pueden salir de la integral } \\
&= \frac{1}{s^{r+1}}\int_0 ^\infty e^{-u} u^r du \\
&= \frac{\Gamma(r+1)}{s^{r+1}}
\end{alignat*}
En resumen, tenemos una generalización de $\LL[t^n]$, para cualquier exponente mayor a $-1$.\\
\textbf{Ejercicio: }Calcule $\LL \{ \sqrt{t^5} \}$.\\
\textbf{Ejercicios: }
\begin{itemize}
\item Considere la función definida en $[0,2]$ dada por
\begin{align*}
f(t) = \begin{cases}
t &\text{ si } 0 \leq t < 1 \\
0  &\text{ si } 1 \leq t \leq 2 \\ 
\end{cases}
\end{align*}
Extienda $f(t)$ de manera $2$-periódica a todo $\mathbb R$, calcule la transformada de Laplace de la función resultante.
\vspace{8pt}
\item Repita el ejercicio anterior para la función definida en $[0,2\pi]$ (extiéndala de manera $2\pi$-periódica).
\begin{align*}f(t) = \begin{cases}
\sen(t)  &\text{ si } 0 \leq t < \pi \\
0  &\text{ si } \pi \leq t < 2\pi 
\end{cases}\end{align*}
\vspace{8pt}
\item Calcule la transformada de Laplace de la siguiente función definida a trozos
\begin{align*}f(t) = \begin{cases}
t^2 &\text{ si } 0 \leq t < 1 \\
1  &\text{ si } t \geq 1\\
\end{cases}\end{align*}
\textit{Sugerencia: }Reescriba $f$ sin usar definición a trozos (usando la función $H$).
\vspace{8pt}
\item Calcule la transformada de Laplace de la siguiente función definida a trozos
\begin{align*}f(t) = \begin{cases}
\sen t &\text{ si } 0 \leq t < \pi \\ 0  &\text{ si } \pi \leq t < 2\pi\\
1  &\text{ si } t \geq 2\pi\\
\end{cases}\end{align*}
\textit{Sugerencia: }Reescriba $f$ sin usar definición a trozos (usando la función $H$).
\vspace{8pt}
\item Calcule $\LL \{ \delta_1(t) - \delta_3(t)\}$.
\vspace{8pt}
\item Calcule $\LL \{ \delta_{\pi}(t)\sen(t)\}$.
\item Calcule $\LL \{ t^{3/2} \}$.
\item  Calcule $\LL \{ t^{5/2} \}$.
\end{itemize}
\subsection{Convolución de funciones.} En esta subsección definiremos una nueva operación con funciones integrables.\\
\textbf{Definición: }Considere dos funciones $f,g:[0,\infty) \to \R$. La \textbf{convolución} de $f$ y $g$, denotada por $f * g$, es una nueva función, definida por
$$(f*g)(t) = \int_0^t f(u)g(t-u)du.$$
\textbf{Ejemplo: } Sean $a,b \in \R$ cualesquiera. Entonces
\begin{align*}
e^{at}*e^{bt} &= \int_0^t e^{au}e^{b(t-u)}du  \\ 
&= e^{bt}\int_0^t e^{u(a-b)}du\\
&= e^{bt} \left[\frac{e^{u(a-b)}}{a-b} \right]_0^t\\ 
&= e^{bt}\left[\frac{e^{ta}e^{-tb}-1}{a-b} \right]\\
&= \frac{e^{at}-e^{bt}}{a-b}
\end{align*}
Afortunadamante, la convolución tiene la propiedad de \textbf{conmutatividad} es decir, siempre se tiene que
$$(f*g)(t) = (g*f)(t).$$
Para el siguiente ejemplo, y en general, para las \textit{convoluciones que involucren funciones trigonométricas}, usaremos las siguientes identidades no tan conocidas, el lector puede intentar demostrarlas.
 \begin{align*}
 2\sen A \sen B &=\cos(A-B) - \cos(A+B) \\
  2\cos A\cos B &=\cos(A-B) + \cos(A+B) \\
  2\sen A\cos B &=\sen(A-B) + \sen(A+B) \\
 \end{align*}
 \textbf{Ejemplo: }
 \begin{align*}
 \sen(t)*\cos(t) &= \int_0 ^t \sen(u)\cos(t-u)du\\
 &= \int_0^t \frac{\sen(u-(t-u)) + \sen(u + t -u)}{2}du \\
 &= \frac{1}{2} \int_0^t \sen(2u-t) + \sen(t) du \\
 &= \frac{1}{2} \left( -\frac{\cos(2u-t)}{2}\bigg\rvert_0^t  + u\sen(t)\bigg\rvert_0^t\right)\\
 &= \frac{t\sin t}{2}
 \end{align*}
 Pues la integral con término coseno se anula.\\
 Tenemos entonces una nueva operación con funciones (junto con las que ya conocemos: $+,-,\cdot,\circ$,etc.). La razón por la que definimos esta operación, es debido a que tiene una propiedad interesante con respecto a la transformada de Laplace.\\
 \textbf{Teorema: } Sean $f,g$ funciones. Entonces
 $$\LL \{(f*g)(t) \}(s)=\LL \{f(t) \}(s) \cdot \LL \{g(t) \}(s).$$
 En palabras: Para calcular la transformada de $f*g$, calculamos la de $f$, luego la de $g$, y multiplicamos el resultado. En otras palabras: la transformada de Laplace convierte convoluciones en multiplicaciones. Podemos usar este teorema para calcular transformadas de Laplace eficientemente.\\
 \textbf{Ejemplo: } Calcule $\LL \{ e^{t} * \sin(t) \}(s)$. 
 \\ En vez de calcular la convolución por medio de integrales, podemos utilizar el teorema
 \begin{align*}
 \LL \{ e^{t} * \sen(t) \}(s) &= (\LL \{ e^t \}(s))( \LL \{\sen(t) \}(s)) \\
 &= \frac{1}{s-1} \cdot \frac{1}{s^2 +1 } \\
 &= \frac{1}{(s^2+1)(s-1)} \\
 &= \frac{1}{s^3-s^2+s-1}
 \end{align*}
 \textbf{Ejercicio:} Calcule $\LL [e^{2t}\int_0^t  u^2e^{-u}du]$, y $\LL [\int_0^t \frac{1-e^{-u}}{\sqrt{u}}du] $.\\
 A partir de aquí debemos saber bien cómo calcular una transformada determinada, puesto que nos interesaremos ahora en la operación \textit{inversa} $\IL$. \pagebreak
 \subsection{La transformada inversa de Laplace.} Anteriormente, nos dábamos una función $f(t)$, y queríamos calcular $\LL[f]$. Ahora, dada una función $F(s)$, ¿Será que existe alguna $f(t)$ de forma que $\LL \{ f(t) \} (s) = F(s)$? Por ejemplo, para $F(s)= 1/s$ tenemos que $f(t)=1$. Cuando esto sucede, decimos que $f(t)$ es la \textbf{trasnformada inversa de} $F(s)$, y lo denotamos por
 $$\IL \{ F(s)\} =  f(t).$$
 \textbf{Ejemplos:}
 $$\IL \left \{ \frac{1}{s^2}\right \}= t \ , \ \IL \left \{ \frac{1}{s+3}\right \} = e^{-3t} \ ,  \ \IL \left \{ \frac{5}{s^2+25} \right \} = \sen(5t)$$
 \textbf{Nota: }Al igual que $\LL$, la transformada inversa $\IL$ también tiene la propiedad de linealidad.\\
 En el fondo ya somos capaces de calcular cualquier transformada inversa, incluso podemos aplicar todos los teoremas que ya hemos estudiado para el cálculo de transformadas inversas. Vamos a practicar la transformada inversa por medio de ejemplos. El cálculo de $\IL$ se basa en el conocimiento de $\LL$.\\
 \textbf{Ejemplo: } Calcule $\IL [ 1/s^5]$.\\
 Solución: Tenemos una potencia de $s$ en el denominador. La única función cuya transformada se parece a esto sería $t^4$, pero debemos multiplicar y dividir por un número adecuado.
 $$
 \IL \left \{ \frac{1}{s^5}\right\} = \frac{1}{4!} \IL \left \{ \frac{4!}{s^5}\right\}= \frac{t^4}{24}.
$$
\textbf{Ejemplo: } Calcule $\IL [ \frac{1}{s^2 + 7} ]$.\\
\textbf{Solución: }Similar al ejemplo anterior
$$\IL \left \{ \frac{1}{s^2 + 7}\right \} = \frac{1}{\sqrt{7}}\IL  \left \{ \frac{\sqrt{7}}{s^2 + 7} \right \} = \frac{\sen(\sqrt{7}t)}{\sqrt{7}}$$
Apliquemos la linealidad de otra manera.\\
\textbf{Ejemplo: }
$$\IL \left \{\frac{6-2s}{s^2 + 4} \right \} = 3\IL \left \{\frac{2}{s^2 + 4} \right \} - 2\IL \left \{\frac{s}{s^2 + 4} \right \} = 3\sen(2t) - 2\cos(2t).$$ 
Lo que hicimos en el primer paso fue separar la resta por linealidad, y usando que $6 = 3 \cdot 2$, sacamos el $3$ de la transformada (de nuevo, por linealidad). El siguiente ejemplo es muy importante.\\
\textbf{Ejemplo: Uso de fracciones parciales.} Vamos a calcular
$$\IL \left \{\frac{s^2 + 6s + 9}{(s-1)(s-2)(s+4)} \right \}.$$
En caso de que el denominador no estuviese factorizado, debemos hacerlo con los métodos que ya conocemos (inspección, completar cuadrado, división sintética). Debemos aplicar una descomposición en fracciones parciales para separar la fracción que no sabemos transformar, en una suma de fracciones que sí sepamos trasnformar (con denominador de la forma $as+b$ o $s^2 + \omega^2$). Tenemos entonces que
$$\frac{s^2 + 6s + 9}{(s-1)(s-2)(s+4)}  =  \frac{A}{s-1 } + \frac{B}{s-2}  + \frac{C}{s+4}.$$
El lector puede utilizar su método favorito para determinar que en este caso $A= -16/5$, $B = 25/6 $, y $C = 1/30$. Gracias a esto, tenemos entonces que
\begin{align*}
\IL \left \{\frac{s^2 + 6s + 9}{(s-1)(s-2)(s+4)} \right \} &= -\frac{16}{5} \IL \left \{ \frac{1}{s-1}\right \} + \frac{25}{6} \IL \left \{ \frac{1}{s-2}\right \} + \frac{1}{30} \IL \left \{ \frac{1}{s+4}\right \} \\
&= \frac{-16}{5}e^t + \frac{25}{6}e^{2t} + \frac{1}{30}e^{-4t}.
\end{align*}
\textbf{Ejercicio: }Calcule la transformada inversa de cada una de las siguientes funciones:
\begin{itemize}
\item $\dfrac{3}{s^2-16}$
\vspace{8pt}
\item $\dfrac{2s-8}{s^2-5s+6}$
\end{itemize}
Tenemos también una versión inversa de cada uno de los teoremas de la sección anterior.\\
\textbf{Teorema: }
$$\IL \{ F(s-a) \} = e^{at} \IL \{ F(s) \}.$$
Es decir, para encontrar la transformada inversa de una función trasladada por $-a$, podemos encontrar la inversa de la función sin trasladar, y multiplicar el resultado por $e^{at}$. Tenemos entonces, por ejemplo, que
$$\IL \left\{ \frac{3!}{(s+5)^4} \right \} = e^{-5t} \IL \left\{ \frac{3!}{s^4} \right \}=e^{-5t}t^3$$
o también que
$$\IL \left \{ \frac{s-1}{(s-1)^2 + 9} \right \} =e^t\IL \left \{ \frac{s}{s^2 + 9}\right \} = e^t \cos(3t)$$
Podemos combinar este resultado con el uso de fracciones parciales para destransformar una gran variedad de expresiones racionales. \\
\textbf{Ejemplo: } Calcule $\IL \left\{ \dfrac{2s+5}{(s-3)^2} \right\}$.\\
Solución: Aplicamos fracciones parciales
$$\frac{2s+5}{(s-3)^2} = \frac{A}{s-3}+ \frac{B}{(s-3)^2}.$$
De nuevo, seguimos el procedimiento usual de las fracciones parciales para despejar $A=2$ y $B=11$. Tenemos entonces que
$$\IL \left\{ \dfrac{2s+5}{(s-3)^2} \right\} = 2\IL \left\{ \dfrac{1}{(s-3)} \right\} + 11\IL \left\{ \dfrac{1}{(s-3)^2} \right\} = 2e^{3t} + 11e^{3t}t.$$ \\
\textbf{Ejercicio: }Calcule la transformada inversa de cada una de las siguientes funciones:
\begin{itemize}
\item $\dfrac{25}{s^3(s^2+4s+5)}$
\vspace{8pt}
\item $\dfrac{s}{s^4+2s^2+1}$
\vspace{8pt}
\item $\dfrac{s-5}{s^2-4s+5}$
\vspace{8pt}
\item $\dfrac{s/2 + 5/3}{(s+2)^2 + 2}$
\end{itemize}
Seguidamente, tenemos la versión inversa del teorema que nos permitía calcular $\LL \{ tf(t) \}$.\\
\textbf{Teorema: }
$$ \IL \{ F(s) \} = -\frac{1}{t}\IL \left\{ \frac{d}{ds} F(s) \right \}.$$
Podemos usar esta identidad para calcular transformadas inversas de funciones que incluyan $\ln$ y $\arctan$. \textbf{Nota: }Esta fórmula solo funciona si la transformada de la función resultante existe en primer lugar.\\
\textbf{Ejemplo: } Determinar $\IL \{ \ln\left(1+\frac{1}{s^2}\right) \}$.\\
\textbf{Solución: }Usamos la fórmula que acabamos de demostrar
\begin{align*}
\IL \left \{ \ln\left(1+\frac{1}{s^2}\right) \right  \} &= \IL \left \{ \ln\left(\frac{s^2 + 1}{s^2}\right) \right  \} \\
&= \IL \left \{ \ln(s^2+1) - \ln(s^2) \right  \}\\
&= -\frac{1}{t} \IL \left \{\frac{d}{ds} \ln(s^2+1)  \right \} + \frac{1}{t} \IL \left \{\frac{d}{ds} \ln(s^2)  \right \}  \\
&= -\frac{1}{t} \IL \left \{\frac{2s}{s^2+1} \right \} + \frac{1}{t} \IL \left \{\frac{2}{s} \right \}  \\
&= -\frac{2\cos(t)}{t} + \frac{2}{t} \\
&= \frac{2-2\cos(t)}{t}.
\end{align*}
Note que esta última función no posee asíntota en $t=0$, y es de orden exponencial, por lo tanto su transformada existe y podemos afirmar que 
$$\IL \left \{ \ln\left(1+\frac{1}{s^2}\right) \right  \} =  \frac{2-2\cos(t)}{t}.$$
\textbf{Ejercicio: } Calcule $\IL \{ \arctan(1/s) \}$
\\\textbf{Ejercicio: } ¿Podemos aplicar esta fórmula para calcular $\IL \{ \ln(s)\}$? Justifique su respuesta.\\
Podemos también utilizar la forma inversa del teorema de traslación que involucra la función de Heaviside $H_a(t)$.\\
\textbf{Teorema: }Si $\LL { f(t) } (s) = F(s)$, entonces
$$\IL \{ e^{-as} F(s) \} = f(t-a)H_a(t). $$
Por lo tanto, siempre que necesitemos destransformar alguna expresión que venga multiplicada por $e^{as}$, necesitaremos la ayuda de $H_a(t)$.\\
\textbf{Ejemplos: }
$$\IL \left \{ \frac{e^{-2s}}{s-4}\right \} = H_2(t) e^{4(t-2)}\ , \ \IL \left \{ \frac{se^{-\pi s /2}}{s^2+9}\right \} = H_{\frac{\pi}{2}}(t) \cos 3\left (s-\frac{\pi}{2}\right )$$
Recordemos una vez más que el argumento final de la transformada inversa debe trasladarse a $t-a$.\\
\textbf{Ejemplo:} Calculemos
$\IL \left \{ \dfrac{e^{-2s}}{s^2+4s + 5}\right \}$. Para ello, podemos completar cuadrados en el denominador: $s^2 + 4s + 5 = s^2 + 4s + 4 +1 = (s+2)^2 + 1$. Entonces
\begin{align*}
\IL \left \{ \dfrac{e^{-2s}}{s^2+4s + 5}\right \} &= \IL \left \{ \dfrac{e^{-2s}}{(s+2)^2 + 1}\right \} \\ &= H_2(t)\IL \left \{ \dfrac{1}{(s+2)^2 + 1}\right \}\bigg\rvert_{t-2}\\
&= H_2(t)e^{-2(t-2)}\IL \left \{ \dfrac{1}{s^2 + 1}\right \}\bigg\rvert_{t-2}\\
&= H_2(t)e^{-2(t-2)}\sin(t-2)  
\end{align*}
Note que también hemos usado el teorema de traslación para extraer el $e^{-2(t-2)}$ de las llaves.
\textbf{Ejercicio: }Calcule la transformada inversa de cada una de las siguientes funciones:
\begin{itemize}
\item $\dfrac{se^{-4s}}{(3s+2)(s-2)}$
\vspace{8pt}
\item $\dfrac{5e^{-6s} - 3e^{-11s}}{(s+2)(s^2+9)}$
\vspace{8pt}
\item $\dfrac{4s+e^{-s}}{s^2 + s - 2}$
\end{itemize}
Podemos aplicar la relación entre la transformada de Laplace y la convolución de funciones para calcular algunas transformadas inversas. \pagebreak\\
\textbf{Teorema: }
$$\IL \{ F(s) G(s)\} = (f*g)(t) = \int_0^t f(u)g(t-u)du,$$
donde $\LL \{f(t) \}(s) = F(s)$ y  $\LL \{g(t) \}(s) = G(s)$. Es decir, si queremos calcular la transformada inversa de un producto de 2 funciones, podemos calcular la transformada de cada función por aparte, y aplicar convolución de los resultados.Podemos usar este método de cálculo como una alternativa a usar fracciones parciales, con el riesgo de que la integral que nos resulte a la hora de calcular la convolución sea difícil.\\
\textbf{Ejemplo: }
\begin{align*}
\IL \left \{  \frac{5}{(s-4)(s+1)}\right \}&= \IL \left \{  \frac{5}{(s-4)} \cdot \frac{1}{(s+1)}\right \} \\
&= \IL \left \{  \frac{5}{(s-4)}\right \}* \IL \left \{  \frac{1}{(s+1)}\right \} \\
&= 5e^{4t}*e^{-t} \\
&= 5 \frac{e^{4t}-e^{-t}}{4--1} \\
&= e^{4t}-e^{-t}
\end{align*}
\textit{Nota: }La convolución de exponenciales ya la habíamos calculado en la sección previa. Podemos usar dicha fórmula para simplificar cálculos.\\
\textbf{Ejemplo: } Calculemos la transformada inversa de $\frac{8}{(s^2+4)^2}$.
\begin{align*}
\IL \left \{ \frac{8}{(s^2+4)^2} \right \} &= \IL \left \{ \frac{4}{(s^2+4)} \cdot \frac{2}{(s^2+4)} \right \} \\
&= \IL \left \{ \frac{4}{(s^2+4)} \right \} * \IL \left \{ \frac{2}{(s^2+4)} \right \} \\
&= 2\sen(2t) * \sen(2t) \\
&= \int_0^t 2\sen(2u) \sen(2t-2u)du
\end{align*}
Usaremos la identidad $ 2\sen A \sen B =\cos(A-B) - \cos(A+B)$
\begin{align*}
\phantom{\IL \left \{ \frac{8}{(s^2+4)^2} \right \}}&= \int_0^t \cos(4u-2t) - \cos(2t)du \\
&= \left[\frac{\sen(4u-2t)}{4} - u\cos(2t) \right]_0^t\\
&= \frac{\sen(2t)}{4} - t\cos(2t) + \frac{\sen(2t)}{4} \\
&=  \frac{\sen(2t) - 2t\cos(2t)}{2}
\end{align*}
Donde debemos recordar que $\sen(-t) = - \sen(t)$.\\
\textbf{Ejercicio: }Calcule la transformada inversa de cada una de las siguientes funciones:
\begin{itemize}
\item $\dfrac{27}{s^2 ( s^2 + 9)}$
\vspace{8pt}
\item $\dfrac{5}{(s-2)(s^2+1)}$
\vspace{8pt}
\item $\dfrac{1}{s^2(s^2+a^2)}$, con $a>0$.
\vspace{8pt}
\end{itemize}
Finalmente, terminemos con un ejemplo donde aparezca la función $\Gamma$.Para ello, recordemos que si $r > -1$, entonces $\LL \{ t^r \}(s) = \dfrac{\Gamma(r+1)}{s^{r+1}}$.\\
\textbf{Ejemplo: } Usando el teorema de traslación,
\begin{align*}
\IL \left \{\frac{1}{\sqrt{s+1}} \right \} &= e^{-t} \IL \left \{\frac{1}{\sqrt{s}} \right \} \\
&= \frac{e^{-t}}{\Gamma\left(\frac{1}{2}\right)} \IL \left \{\frac{\Gamma\left(\frac{1}{2}\right)}{s^{\frac{1}{2}}} \right \} \\
&= \frac{e^{-t}}{\Gamma\left(\frac{1}{2}\right)}t^{-\frac{1}{2}}\\
&= e^{-t}\sqrt{\frac{1}{t\pi}}
\end{align*}
\textbf{Ejercicio: }Calcule la transformada inversa de cada una de las siguientes funciones:
\begin{itemize}
\item $e^{-3s} (s-5)^{\frac{-3}{2}}$
\vspace{8pt}
\item $\dfrac{1}{(s+6)^3 \sqrt{s+6}}$
\vspace{8pt}
\end{itemize}
\newpage
\subsection{Resolución de ecuaciones diferenciales por medio de transformadas de Laplace. } Finalmente, vamos a aplicar todos los conocimientos que tenemos sobre $\LL$ y $\IL$ para resolver no solo EDOs, sino también ecuaciones integrales (donde intervienen integrales en vez de derivadas), y ecuaciones integro-diferenciales (combinación de derivadas e integrales). Vamos a refrescar el teorema clave para esta sección, el cual ya estudiamos anteriormente.\\
\textbf{Teorema: Transformada de una derivada.}
\begin{align*}
\LL\{f'(t)\}(s) &= s \LL \{f(t) \}(s) - f(0)\\
\LL\{f''(t)\}(s) &= s^2\LL \{f(t) \}(s) - sf(0) - f'(0).\\
\LL \{f'''(t) \}(s) &= s^3 \LL \{f(t) \}(s) - s^2 f(0) - s f'(0) -  f''(0)\\ 
\vdots  \\
\LL\{f^{(n)}(t)\}(s) &= s^n\LL \{f(t) \}(s) - \sum_{k=0}^{n-1} s^{n-k-1}f^{(k)}(0).
\end{align*}
Supongase que tenemos un problema de valor inicial
\begin{align*}
\begin{cases}
a_ny^{(n)}(t) + a_{n-1}y^{(n-1)}(t) + \dots + a_1y'(t)+ a_0y(t)= f(t) \\
y(t_0)=y_0 \\
y'(t_0)=y_1 \\
y''(t_0)=y_2 \\
\vdots \\
y^{(n-1)}(t_0)=y_{n-1}
\end{cases}
\end{align*}
Para resolver dicho problema, vamos a seguir el siguiente procedimiento
\begin{itemize}
\item\textit{Paso 1: }Aplicamos $\LL$ en ambos lados de la ecuación diferencial. Es en este paso donde necesitamos saber los valores de $y(t_0),y'(t_0),..,y^{(n-1)}(t_0)$. La nueva ecuación será una ecuación algebraica (sin presencia de derivadas), pero en variable $s$.
\item \textit{Paso 2: }En la ecuación mencionada en el paso 1, despejamos el valor $\LL\{y\}(s)$. En otras palabras, debemos dejar todo lo que dependa de $s$ en un solo lado de la ecuación.
\item \textit{Paso 3.} Aplicamos $\IL$ para obtener el valor de $y$.
\end{itemize}
En la resolución de EDOs por medio de transformada de Laplace, vamos a denotar $Y(s)$ en vez de $\LL \{ y(t) \} (s)$, por comodidad.
Comencemos con ejemplos sencillos.\\
\textbf{Ejemplo: }Resuelva el siguiente problema de valor inicial.
$$\begin{cases}
\frac{dy}{dt} + 3y = 13\sen(2t) \\
y(0) = 6.
\end{cases}$$
Aplicamos entonces $\LL$ a toda la ecuación, para obtener
$$\LL \left \{ \frac{dy}{dt} \right \} + 3 \LL \{y\} = 13 \LL \{ \sen(2t) \}.$$
Sabemos del teorema anterior que $\LL \{y'(t) \}(s) = s \LL \{y(t) \}(s) - y'(0) = sY(s) - 6.$ Calculando también la transformada del lado derecho, obtenemos la ecuación
$$sY(s)-6 + 3Y(s) = \frac{26}{s^2 + 4}.$$
Ahora queremos despejar $Y(s)$.
\begin{alignat*}{2}
&&Y(s)(s+3) &= 6 +  \frac{26}{s^2 + 4} \\
\Rightarrow && Y(s) &= \frac{6}{s+3} + \frac{26}{(s^2 + 4)(s+3)}  \\
\end{alignat*}
Finalmente, aplicamos la transformada inversa. Al lado izquierdo obtendremos $y$ de vuelta pues $y = \IL \{ Y(s) \}$.
$$y(t) = \IL \left \{\frac{6}{s+3}  \right \} + \IL \left \{ \frac{26}{(s^2 + 4)(s+3)}  \right \}.$$
Para calcular la segunda transformada inversa debemos usar fracciones parciales, puede verificar como ejercicio que se tiene la siguiente descomposición
$$\frac{26}{(s^2+4)(s+3)} = \frac{2}{s+3}-\frac{2(s-3)}{s^2+4} = \frac{2}{s+3} -  \frac{2s}{s^2+4} +\frac{6}{s^2+4}.$$
Por lo que tenemos finalmente que
\begin{align*}
y(t) &= \IL \left \{\frac{6}{s+3}  \right \}  +\IL \left \{\frac{2}{s+3}  \right \}  - \IL \left \{\frac{2s}{s^2+4} \right \}  + \IL \left \{\frac{6}{s^2+4} \right \} \\
&= 6e^{-3t} + 2e^{-3t} - 2\cos(2t) + 3\sin(2t)\\
&= 8e^{-3t} - 2\cos(2t) + 3\sin(2t).
\end{align*}
Si el lector gusta puede resolver la ecuación con la teoría que ya conoce (es una ecuación lineal) para verificar que la solución en efecto es $y(t)=8e^{-3t} - 2\cos(2t) + 3\sin(2t)$.\\
\textbf{Ejemplo} Resolvamos una ecuación de orden $2$.
$$\begin{cases}
y''-3y'+2y = e^{-4t}\\
y(0)=1\\
y'(0) = 5
\end{cases}$$
Siguiendo de nuevo el procedimiento al pie de la letra, aplicamos primero $\LL$ para obtener
\begin{align*}
\LL \{y'' \} - 3\LL \{y' \} + 2\LL \{y\} &= \LL \{ e^{-4t} \} \\
s^2Y(s) -sy(0) - y'(0) - 3(sY(s) - y(0)) + 2Y(s) &= \frac{1}{s+4} \\
s^2Y(s) - s - 5 - 3sY(s) + 3 + 2Y(s) &= \frac{1}{s+4}  \\
Y(s) (s^2 -3s+2) &=s+2+\frac{1}{s+4} \\
Y(s) (s^2 -3s+2) &= \frac{(s+2)(s+4) + 1}{s+4} \\
Y(s) &= \frac{(s+2)(s+4) + 1}{(s+4) (s^2 -3s+2) }
\end{align*}
Expandiendo el numerador, y factorizando el denominador, obtenemos que
$$Y(s) = \frac{s^2+6s+9}{(s-1)(s-2)(s+4)}.$$
Solo nos queda aplicar transformada inversa. Afortunadamente, esta transformada ya la calculamos al inicio de la sección anterior. De todas formas es un buen ejercicio calcularla de nuevo. Tenemos entonces la solución del problema dada por.
$$y(t) = \IL \left \{  \frac{s^2+6s+9}{(s-1)(s-2)(s+4)}\right \} = \frac{-16}{5}e^t + \frac{25}{6}e^{2t} + \frac{1}{30}e^{-4t}.$$
\textbf{Nota: }Observe que no estamos encontrando soluciones generales a ecuaciones. Este método solo aplica para problemas de valor inicial, ya que para transformar necesitamos conocimiento de al menos $y(0)$. \\
\textbf{Ejercicio: }Resuelva los siguientes problemas de valores iniciales utilizando una transformada de Laplace.
$$
\begin{cases}
y''+2y' + y = e^{-t}\\
y'(0) = y(0) = 0
\end{cases} \quad , \quad
\begin{cases}
y''-6y' + 9y = t^2e^{3t} \\
y(0) =2 \\
y'(0) = 17
\end{cases}
$$
Si bien es un método de resolución interesante, ya tenemos las herramientas suficientes para resolver las ecuaciones diferenciales de los ejemplos anteriores. Resolvamos ahora una ecuación diferencial que eluda todos nuestros métodos previos. A partir de aquí se asumirá que el lector ya puede calcular sin problemas $\LL$  y $\IL$ de distintas expresiones. \\
\textbf{Ejemplo: }Encuentre la solución de la ecuación $y' + y = f(t)$ sujeta a la condición inicial $y(0)=5$, y donde la función $f(t)$ es dada por
$$f(t) = \begin{cases}
 0 &\text{ si } 0 \leq t  < \pi \\
3\cos(t) &\text{ si } \pi \leq t  
\end{cases}$$
Tenemos que resolver una EDO donde el lado derecho es una función definida por partes. No tenemos ningún método para la solución de este tipo de problema. Debemos aplicar transformadas de Laplace. Ahora, recordemos que para poder transformar $f(t)$, necesitamos escribirla con ayuda de la \textit{función de Heaviside}
$$f(t) = 3H_{\pi}(t)\cos(t).$$
Podemos entonces transformar nuestro problema
\begin{align*}
sY(s) - y(0)  + Y(s) &= \LL \{ 3H_{\pi}\cos(t) \}(s) \\
Y(s)(s+1) - 5 &= 3 \LL \{H_{\pi}\cos(t-\pi +\pi)  \}(s) \\
Y(s)(s+1) - 5 &= -3 \LL \{H_{\pi}\cos(t-\pi)  \}(s)  \quad \text{ pues } \cos(A+\pi) = -\cos(A)\\
Y(s) (s+1) &= 5-3e^{-\pi s} \LL \{\cos(t) \}(s)\\
Y(s) (s+1) &= 5 - \frac{3se^{-\pi s}}{s^2+1} \\
Y(s) &= \frac{5}{s+1} - e^{-\pi s} \frac{3s}{(s^2+1)(s+1)}
\end{align*}
Recuerde que para poder aplicar el teorema de traslación necesitamos forzar para obtener $\cos(t-\pi)$.\\
Usando fracciones parciales podemos obtener la siguiente descomposición
$$\frac{3s}{(s^2+1)(s+1)} = \frac{3}{2}\left( -\frac{1}{s+1} + \frac{1}{s^2 + 1} + \frac{s}{s^2+1}\right).$$
Por lo que se tiene que
$$y(t) = \IL \left \{\frac{5}{s+1} - \frac{3}{2}\left( -\frac{e^{-\pi s}}{s+1} + \frac{e^{-\pi s}}{s^2 + 1} + \frac{se^{-\pi s}}{s^2+1}\right)\right\}.$$
Lo único que debemos hacer es calcular la transformada de cada término por separado. El cálculo queda de ejercicio. Tenemos que, individualmente
\begin{align*}
\IL \left \{\frac{e^{-\pi s}}{s+1} \right \} &= H_{\pi}(t)e^{-(t-\pi)}\\
\IL \left \{\frac{e^{-\pi s}}{s^2 + 1}  \right \} &= \sen(t-\pi)H_{\pi}(t) = -H_{\pi}(t)\sen(t)\\
\IL \left \{ \frac{se^{-\pi s}}{s^2+1}\right \} &= H_{\pi}\cos(t-\pi) = -H_{\pi}(t)\cos(t)
\end{align*}
Combinando entonces las transformadas, y siendo atententos con los coeficientes (cuidado con los signos), tenemos que
\begin{align*}
y(t) &= 5e^{-t} + \frac{3}{2} H_{\pi}(t)e^{-(t-\pi)} + \frac{3}{2}H_{\pi}(t)\sen(t) +\frac{3}{2}H_{\pi}(t)\cos(t)\\
&= 5e^{-t} + \frac{3}{2} \left(e^{-(t-\pi)} + \sen(t) + \cos(t) \right) H_{\pi}(t)
\end{align*}
Debemos presentar la solución en forma de función definida por partes, para concluir el problema.
$$y(t) = \begin{cases}
5e^{-t} &\text{ si } 0 \leq t < \pi \\
5e^{-t} + \frac{3}{2} \left(e^{-(t-\pi)} + \sen(t) + \cos(t) \right)  &\text{ si } \pi  \leq  t \\
\end{cases}$$
% $$g(t) = (2t-1)(H_0(t)-H_1(t)) + H_1(t).$$
% Puede verificar que la transformada de $g$ es
% $$\LL \{ g(t) \}(s) = \frac{2}{s^2} - \frac{1}{s} - e^{-s} \left(  \frac{2}{s^2} + \frac{1}{s}  \right) + \frac{e^{-s}}{s} = \frac{2-2s-e^{-s}}{s^2}$$
% por lo que, al transformar nuestra ecuación diferencial vamos a obtener la ecuación algebraica
% \begin{align*}
% s^3Y(s) - s^2y''(0) - sy'(0) - y(0) -4(sY(s) - y(0)) &= \frac{2-2s-e^{-s}}{s^2} \\
% s^3Y(s) - 2s+1 -4sY(s) - 4 &=  \frac{2-2s-e^{-s}}{s^2} \\
% Y(s) (s^3 - 4s) &=  \frac{2-2s-e^{-s}}{s^2} + 2s - 1 \\
% Y(s) = 
% \end{align*}

% $$f(t) = 3H_{\pi}(t)\cos(t).$$
% Podemos entonces transformar nuestro problema
% \begin{align*}
% sY(s) - y(0)  + Y(s) &= \LL \{ 3H_{\pi}\cos(t) \}(s) \\
% Y(s)(s+1) - 5 &= 3 \LL \{H_{\pi}\cos(t-\pi +\pi)  \}(s) \\
% Y(s)(s+1) - 5 &= -3 \LL \{H_{\pi}\cos(t-\pi)  \}(s)  \quad \text{ pues } \cos(A+\pi) = -\cos(A)\\
% Y(s) (s+1) &= 5-3e^{-\pi s} \LL \{\cos(t) \}(s= \\
% Y(s) (s+1) &= 5 - \frac{3se^{-\pi s}}{s^2+1} \\
% Y(s) &= \frac{5}{s+1} - e^{-\pi s} \frac{3s}{(s^2+1)(s+1)}
% \end{align*}
% Recuerde que para poder aplicar el teorema de traslación necesitamos forzar para obtener $\cos(t-\pi)$.\\
% Usando fracciones parciales podemos obtener la siguiente descomposición
% $$\frac{3s}{(s^2+1)(s+1)} = $$}\textb}\\
\textbf{Ejercicio: }
Encuentre la solución de la ecuación $y' +y = f(t)$ sujeta a la condición inicial $y(0) = 0$, y donde la función $f(t)$ es dada por
$$f(t) = \begin{cases}
 2t-1 &\text{ si } 0 \leq t  < 1 \\
1 &\text{ si } 1 \leq t  
\end{cases}$$
\textbf{Ejemplo: }Utilicemos la transformada de Laplace para resolver la ecuación \newline $y'' - 6y' + 9y = \delta_2(t) + f(t)$, donde
$$f(t) = \begin{cases}
0 &\text{ si } 0 \leq t < 2 \\
e^{3t}  &\text{ si } 2 \leq t   \\
\end{cases}$$
sujeta a las condiciones $y(0)=y'(0) = 0$.
Primero calculamos la transformada de la función del lado derecho.
$$\LL \{\delta_2(t) + f(t) \} = \LL \{\delta_2(t) + H_2(t)e^{3t} \} = e^{-2s} + \frac{e^{-2s+6}}{s-3}.$$
Aplicando $\LL$ a todo el sistema obtenemos
\begin{align*}
s^2Y(s) -sy(0) - y'(0) -6sY(s) + 6y(0) + 9Y(s) &= e^{-2s} +  \frac{e^{-2s+6}}{s-3}\\
s^2Y(s) - 6sY(s) +9Y(s) &= e^{-2s}+ \frac{e^{-2s+6}}{s-3}  \\
Y(s) = \frac{e^{-2s}}{(s-3)^2}+ \frac{e^{-2s+6}}{(s-3)^3}
\end{align*}
Finalmente obtenemos, calculando la transformada inversa, que
$$y(t) = \IL \left \{ \frac{e^{-2s}}{(s-3)^2}+ \frac{e^{-2s+6}}{(s-3)^3}\right \} = H_2(t) \left( e^{(3t-6)}(t-2)+\frac{e^{3t}(t-2)^2}{2}\right)$$
Por lo que la solución del problema viene dada por
$$y(t) = \begin{cases}
0 &\text{ si } 0 \leq t  < 2 \\
e^{(3t-6)}(t-2)+\frac{e^{3t}(t-2)^2}{2} &\text{ si } 2 \leq t  
\end{cases}$$
\textbf{Ejercicios: }Utilice la transformada de Laplace para resolver los siguientes problemas de valor inicial.
\begin{itemize}
\item $y'' + 4y = H_{2\pi}(t) \sen(t)$, con $y(0) = 1 , y'(0) = 0$.
\vspace{8pt}
\item $y'' - 2y' = e^t \senh(t)$, con $y(0) = 0 , y'(0) = 0$.
\vspace{8pt}
\end{itemize}
La siguiente aplicación de la transformada de Laplace que estudiaremos es en la resolución de ecuaciones integro-diferenciales, en donde la variable dependiente $y(t)$ aparece no sólo derivada, sino también \textit{integrada.}
\newpage
\subsection{Ecuaciones integrales e integro-diferenciales.} Vamos a utilizar el mismo algoritmo de \textit{transformar-resolver-destransformar} para resolver ecuaciones en donde interviene la integral de nuestra variable $y(t)$. Considere la siguiente ecuación
$$y(t) = 3t^2 - e^{-t} - \int_0^ty(u)e^{t-u}du.$$
Para poder encontrar la solución $y(t)$, debemos recurrir a la transformada de Laplace. Note que la integral que aparece corresponde con $y * e^t$, por lo que reescribimos
$$y = 3t^2 - e^{-t} - y*e^{t}.$$
Ahora podemos transformar ambos lados de la ecuación. Aplicando la propiedad de la convolución,
$$Y(s) = \frac{6}{s^3} - \frac{1}{s+1}-\frac{Y(s)}{s-1}.$$
Despejando $Y(s)$  se obtiene
\begin{align*}
Y(s)(s-1) + Y(s) &= \frac{6}{s^2} - \frac{6}{s^3} - \frac{s-1}{s+1} \\
Y(s) &= \frac{6}{s^3} - \frac{6}{s^4} - \frac{s-1}{s(s+1)}
\end{align*}
Aplicando transformada inversa, obtenemos que
$$y(t) = \IL\left \{  \frac{6}{s^3} - \frac{6}{s^4} - \frac{s-1}{s(s+1)}\right \} = 3t^2 - t^3 + 1-2e^{-t}.$$
\textbf{Nota: }Para esta transformada fue necesario aplicar fracciones parciales, los detalles quedan como ejercicio.\\
El método que acabamos de emplear funcion para resolver cualquier ecuación integral de la forma
$$y(t) = \varphi(t) + \int_0^t f(u)h(t-u)du.$$
De hecho estas ecuaciones se conocen como \textbf{ecuaciones integrales de Volterra}.\\
\textbf{Ejercicio: } Resuelva la siguiente ecuación integral
$$y(t) = e^t \left(1+\int_0^te^{-u}y(u)\right).$$
Podemos también resolver ecuaciones integro-diferenciales. Una vez más, usaremos el mismo algoritmo \textit{transformar-resolver-destransformar}.\\
\textbf{Ejemplo: }Resuelva el problema de valor inicial
$$y''(t) + 2y(t) + \int_0^t (t-u)y(u)du =\delta_0(t)$$
sujeto a $y'(0)=y(0)=0.$
Notemos que podemos escribir el problema en la forma
$$y''+2y + y*t = \delta_0(t).$$
Aplicando $\LL$ y recordando que $\LL \{ \delta_0(t) \} = 1$, se tiene entonces
\begin{alignat*}{2}
&&s^2Y(s) +2Y(s) + \frac{Y(s)}{s^2} &= 1 \\
\Rightarrow&& Y(s) (s^4 + 2s^2 + 1) &= s^2\\
\Rightarrow&& Y(s)= \frac{s^2}{s^4 + 2s^2 + 1}& 
\end{alignat*}
Tenemos que
$$y(t) = \IL \left \{ \frac{s^2}{s^4 + 2s^2 + 1} \right \} = \IL \left \{ \frac{s^2}{(s^2+1)^2} \right \} = \cos(t) * \cos(t) = \frac{\sin t+ t\cos t}{2}$$
\textbf{Ejercicio: }Resuelva el problema de valores iniciales
$$x'(t) + x(t) -\int_0^t (1+t-u)x(u)du =  \begin{cases}
t-1 &\text{ si } 0 \leq t  < 2 \\
t  &\text{ si } 2 \leq t  
\end{cases}$$
sujeto a la condición inicial $x'(0)=0$.
\subsection{Sistemas y la transformada de Laplace} Podemos utilizar la transformada de Laplace para resolver sistemas de ecuaciónes diferenciales.\\
\textbf{Ejemplo: } Resuelva el sistema
$$\begin{cases}
x''(t) - y(t) &= \sen(t)\\
y''(t) + x'(t) &= \cos(t)\\
\end{cases}$$
con condiciones iniciales $x(0) = 1 , x'(0)=0$, $y(0)=-1 , y'(0) = -1$.\\
Denotemos $X(s) = \LL \{ x(t) \}(s)$ y $Y(s) = \LL \{ y(t) \}(s)$. Aplicando $\LL$ a todo el sistema, obtenemos
$$\begin{cases}
s^2X(s)- s - Y(s) &= \dfrac{1}{s^2+1} \vspace{8pt}\\
s^2Y(s)+s + sX(s) &=\dfrac{s}{s^2+1}\\
\end{cases}$$
que se puede reescribir como
$$\begin{cases}
s^2X(s)- Y(s) &= \dfrac{1}{s^2+1} + s \vspace{8pt}\\
sX(s) + s^2Y(s) &=\dfrac{s}{s^2+1} -s\\
\end{cases}.$$
Podemos aplicar eliminación gaussiana (la clásica) para resolver esta ecuación (note que no hay derivadas). Multiplicamos la primera ecuación por $s^2$, y sumamos las dos ecuaciones para poder despejar $X(s)$.
\begin{align*}
s^4X(s) + sX(s) &= \frac{s^2}{s^2+1} + s^3 - s + \frac{s}{s^2+1} \\
s(s^3+1)X(s) &= \frac{s^2(s^3+1)}{s^2+1}\\
X(s) = \frac{s}{s^2+1}
\end{align*}
Por lo que $x(t) = \cos(t)$. Podemos proceder ahora de muchas formas: aplicando la otra eliminación, sustituyendo $X(s)$ en el sistema transformado, o simplemente sustituir $x(t)$ en el sistema original. Como $y''(t) = \cos(t) - x'(t) = \cos(t) + \sen(t)$, integrando 2 veces obtenemos que
$$y(t) = -\cos(t) - \sen(t) + At + B$$
Pero como $y(0) = -1$ y $y'(0) = -1$, podemos determinar fácilmente que $A=B=0$, por lo que la solución del sistema de ecuaciones sería
\begin{align*}
x(t) &= \cos(t) \\
y(t) &= -\sen(t) - \cos(t)
\end{align*}
\textbf{Ejercicio: } Utilice la transformada de Laplace para resolver el siguiente problema de valores iniciales
$$\begin{cases}
x'(t) &= -2x(t) - 2y(t) \\
y'(t)+ y(t) &= -2y(t) 
\end{cases}$$
Con condiciones iniciales $x(0) = y(0) = 1$.\\

\end{document}