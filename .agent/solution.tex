\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\usepackage[margin=1.2in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{lmodern}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage[parfill]{parskip}

%--- Theorem Environments ---
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]

%--- Macros ---
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Pn}{\mathcal{P}_n}
\newcommand{\PnR}{\mathcal{P}_n^{\mathbb{R}}}
\newcommand{\boxplusn}{\boxplus_n}

%--- Header ---
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{The Finite Free Stam Inequality}
\fancyhead[R]{\thepage}

\title{\textbf{The Finite Free Stam Inequality}}
\author{}
\date{}

%==============================================================================
\begin{document}
%==============================================================================

\maketitle

\begin{abstract}
\noindent
The classical Stam inequality states that Fisher information is superadditive
in its reciprocal: $1/I(X{+}Y) \ge 1/I(X) + 1/I(Y)$ for independent random
variables.
We prove the analogue for real-rooted polynomials, where addition is replaced
by the finite free additive convolution~$\boxplusn$ and Fisher information by a
quantity~$\Phi_n$ measuring the electrostatic repulsion of roots.
The proof combines an algebraic inequality---the Score-Gradient Inequality,
established via two applications of Cauchy--Schwarz---with a flow-based
Gr\"onwall argument.
\end{abstract}

\tableofcontents

%==============================================================================
\section{Introduction}\label{sec:intro}
%==============================================================================

In probability theory, the addition of independent random variables increases
disorder. The \textbf{Stam inequality} makes this precise: if $X$ and $Y$ are
independent with Fisher information $I(X)$ and $I(Y)$, then
\[
  \frac{1}{I(X+Y)} \;\ge\; \frac{1}{I(X)} + \frac{1}{I(Y)}.
\]

This paper proves the polynomial analogue, where each probabilistic concept is
replaced by an algebraic one:

\begin{center}
\begin{tabular}{lcl}
\textbf{Probability} & $\longleftrightarrow$ & \textbf{Polynomials} \\
Random variable $X$ & $\longleftrightarrow$ & Polynomial $p(x)$ \\
Distribution of $X$ & $\longleftrightarrow$ & Roots $\lambda_1,\dots,\lambda_n$ \\
Addition $X+Y$ & $\longleftrightarrow$ & Finite free convolution $p \boxplusn q$ \\
Fisher information $I(X)$ & $\longleftrightarrow$ & $\Phi_n(p)$
\end{tabular}
\end{center}

\begin{theorem*}[Finite Free Stam Inequality]
For monic, degree-$n$ polynomials $p,q$ with all real roots and positive
variance,
\[
  \frac{1}{\Phi_n(p \boxplusn q)}
  \;\ge\;
  \frac{1}{\Phi_n(p)} + \frac{1}{\Phi_n(q)}.
\]
\end{theorem*}

The proof proceeds in four stages.
We first set up the algebraic framework: root statistics, the
convolution~$\boxplusn$, and the Fisher information~$\Phi_n$
(\S\ref{sec:poly}--\ref{sec:fisher}).
We then establish the key algebraic input, the Score-Gradient Inequality
(\S\ref{sec:sgi}).
Next, we embed~$\boxplusn$ into a continuous flow and derive an integral
identity (\S\ref{sec:flow}).
Finally, we close the argument via a Gr\"onwall-type integration
(\S\ref{sec:stam}).

\medskip
\noindent\textbf{Convention.}
All polynomials are assumed to have \emph{distinct} real roots unless stated
otherwise. The final inequality extends to all of~$\PnR$ by continuity, since
polynomials with distinct roots are dense in~$\PnR$.

%==============================================================================
\section{Polynomials and Convolution}\label{sec:poly}
%==============================================================================

Let~$\Pn$ denote the space of monic polynomials of degree~$n$ with real
coefficients, and let $\PnR \subset \Pn$ be the subset with all real roots.
For $p \in \PnR$ write
\[
  p(x) = \prod_{i=1}^n (x - \lambda_i),
  \qquad \lambda_1 \le \cdots \le \lambda_n.
\]

\begin{definition}[Root Statistics]
The mean and variance of the root distribution are
\[
  \mu(p) = \frac{1}{n}\sum_{i=1}^n \lambda_i,
  \qquad
  \sigma^2(p) = \frac{1}{n}\sum_{i=1}^n (\lambda_i - \mu)^2.
\]
\end{definition}

\begin{lemma}[Variance Formula]\label{lem:var}
If $p(x) = x^n + a_1 x^{n-1} + a_2 x^{n-2} + \cdots$, then
$\;\sigma^2(p) = \dfrac{(n-1)\,a_1^2}{n^2} - \dfrac{2\,a_2}{n}$.
\end{lemma}

\begin{proof}
By Vieta's formulas, $\sum \lambda_i = -a_1$ and
$\sum_{i<j}\lambda_i\lambda_j = a_2$, so
$\sum \lambda_i^2 = a_1^2 - 2a_2$.
Substituting into $\sigma^2 = \frac{1}{n}\sum \lambda_i^2 - \mu^2$ gives the
result.
\end{proof}

\subsection{The Finite Free Additive Convolution}

Let $A$ and $B$ be real symmetric matrices with characteristic polynomials $p$
and $q$. Averaging the characteristic polynomial of $A + QBQ^T$ over all
orthogonal rotations $Q$ yields a basis-independent ``sum.''

\begin{definition}[Symmetric Additive Convolution]
\[
  p \boxplusn q
  \;\coloneqq\;
  \int_{O(n)} \det\bigl(xI - (A + QBQ^T)\bigr)\,d\mu_{\mathrm{Haar}}(Q),
\]
where $\mu_{\mathrm{Haar}}$ is the unique bi-invariant probability measure on
the orthogonal group $O(n)$.
\end{definition}

A theorem of Marcus, Spielman, and Srivastava converts this matrix integral
into a differential operator.

\begin{theorem}[MSS {\cite{MSS15}}]\label{thm:mss}
If $q(x) = \sum_{k=0}^n b_k\,x^{n-k}$, then
\[
  (p \boxplusn q)(x) = T_q\,p(x),
  \qquad
  T_q \coloneqq \sum_{k=0}^n \frac{(n-k)!}{n!}\,b_k\,\partial_x^k.
\]
\end{theorem}

Convolution with $q$ thus acts as a diffusion on $p$, with weights determined
by the root distribution of $q$.

\begin{theorem}[Preservation of Real Roots]\label{thm:preserve}
If $p,q \in \PnR$, then $p \boxplusn q \in \PnR$.
\end{theorem}

\begin{lemma}[Variance Additivity]\label{lem:var-add}
$\sigma^2(p \boxplusn q) = \sigma^2(p) + \sigma^2(q)$.
\end{lemma}

\begin{proof}
The convolution formula for the coefficients of $r = p \boxplusn q$ reads
$c_k = \sum_{i+j=k}\frac{(n-i)!\,(n-j)!}{n!\,(n-k)!}\,a_i\,b_j$.
Computing $c_1$ and $c_2$:
\[
  c_1 = a_1 + b_1,
  \qquad
  c_2 = a_2 + \tfrac{n-1}{n}\,a_1 b_1 + b_2.
\]
Substituting into the variance formula (Lemma~\ref{lem:var}) and expanding
$(a_1+b_1)^2$:
\[
  \sigma^2(r)
  = \underbrace{\tfrac{(n{-}1)a_1^2}{n^2}-\tfrac{2a_2}{n}}_{\sigma^2(p)}
  + \underbrace{\tfrac{(n{-}1)b_1^2}{n^2}-\tfrac{2b_2}{n}}_{\sigma^2(q)}
  + \tfrac{2(n{-}1)a_1 b_1}{n^2}
  - \tfrac{2(n{-}1)a_1 b_1}{n^2}.
\]
The cross-terms cancel exactly.
\end{proof}

%==============================================================================
\section{Scores and Fisher Information}\label{sec:fisher}
%==============================================================================

We treat the roots $\lambda_1,\dots,\lambda_n$ as charged particles on a line
that repel with force inversely proportional to distance.

\begin{definition}[Score and Fisher Information]
The \emph{score} at root $\lambda_i$ is the total repulsive force it
experiences:
\[
  V_i = \sum_{j \neq i} \frac{1}{\lambda_i - \lambda_j}.
\]
The \emph{finite free Fisher information} is the total squared force:
\[
  \Phi_n(p) = \sum_{i=1}^n V_i^2.
\]
\end{definition}

High~$\Phi_n$ corresponds to tightly clustered roots; low~$\Phi_n$ to
well-separated roots.

\begin{lemma}[Score via Derivatives]\label{lem:score-deriv}
$V_i = \dfrac{p''(\lambda_i)}{2\,p'(\lambda_i)}$.
\end{lemma}

\begin{proof}
Since $p(x) = \prod_j(x-\lambda_j)$, we have
$p'(\lambda_i) = \prod_{j \neq i}(\lambda_i - \lambda_j)$.
Differentiating $p'(x) = \sum_i \prod_{j\neq i}(x-\lambda_j)$ once more and
evaluating at~$\lambda_i$:
\[
  p''(\lambda_i)
  = 2\sum_{k \neq i}\prod_{\substack{j \neq i \\ j \neq k}}(\lambda_i-\lambda_j)
  = 2\,p'(\lambda_i)\sum_{k \neq i}\frac{1}{\lambda_i-\lambda_k}
  = 2\,p'(\lambda_i)\,V_i. \qedhere
\]
\end{proof}

\begin{lemma}[Score-Root Identity]\label{lem:identity}
$\displaystyle\sum_{i=1}^n (\lambda_i - \mu)\,V_i
= \frac{n(n-1)}{2}$.
\end{lemma}

\begin{proof}
First, $\sum_i V_i = \sum_{i\neq j}\frac{1}{\lambda_i-\lambda_j} = 0$ by
antisymmetry. Next,
\[
  \sum_{i=1}^n \lambda_i V_i
  = \sum_{i \neq j}\frac{\lambda_i}{\lambda_i-\lambda_j}
  = \sum_{i<j}\!\Bigl(\frac{\lambda_i}{\lambda_i-\lambda_j}
    + \frac{\lambda_j}{\lambda_j-\lambda_i}\Bigr)
  = \sum_{i<j} 1
  = \binom{n}{2}.
\]
Since $\sum V_i = 0$, we conclude
$\sum(\lambda_i-\mu)\,V_i = \sum\lambda_i V_i = \frac{n(n-1)}{2}$.
\end{proof}

\begin{lemma}[Fisher--Variance Inequality]\label{lem:fv}
$\Phi_n(p)\cdot\sigma^2(p) \;\ge\; \dfrac{n(n-1)^2}{4}$.
\end{lemma}

\begin{proof}
Apply Cauchy--Schwarz to Lemma~\ref{lem:identity}:
\[
  \frac{n^2(n-1)^2}{4}
  = \Bigl(\sum_i(\lambda_i-\mu)\,V_i\Bigr)^{\!2}
  \le \Bigl(\sum_i(\lambda_i-\mu)^2\Bigr)\Bigl(\sum_i V_i^2\Bigr)
  = n\,\sigma^2(p)\cdot\Phi_n(p). \qedhere
\]
\end{proof}

%==============================================================================
\section{The Score-Gradient Inequality}\label{sec:sgi}
%==============================================================================

We now establish the key algebraic estimate that powers the full Stam
inequality.

\begin{lemma}[Score Decomposition]\label{lem:score-decomp}
$\displaystyle\Phi_n(p)
= \sum_{i<j}\frac{V_i - V_j}{\lambda_i - \lambda_j}$.
\end{lemma}

\begin{proof}
\[
  \sum_i V_i^2
  = \sum_i V_i\!\sum_{j\neq i}\frac{1}{\lambda_i-\lambda_j}
  = \sum_{i \neq j}\frac{V_i}{\lambda_i-\lambda_j}
  = \sum_{i<j}\frac{V_i - V_j}{\lambda_i-\lambda_j}. \qedhere
\]
\end{proof}

\begin{definition}[Score-Gradient Energy]
$\displaystyle\mathcal{S}(p)
= \sum_{i<j}\frac{(V_i - V_j)^2}{(\lambda_i - \lambda_j)^2}$.
\end{definition}

\begin{theorem}[Score-Gradient Inequality]\label{thm:sgi}
For $p \in \PnR$ of degree $n \ge 2$ with distinct roots,
\[
  \mathcal{S}(p)\cdot\sigma^2(p)
  \;\ge\;
  \frac{n-1}{2}\,\Phi_n(p),
\]
with equality if and only if $V_i = c(\lambda_i - \mu)$ for some constant~$c$.
\end{theorem}

\begin{proof}
Write $T = n\,\sigma^2(p)$, $U = \Phi_n(p)$, $S = \mathcal{S}(p)$. We must
show $S\,T \ge \frac{n(n-1)}{2}\,U$.

\medskip
\noindent\textbf{Step~1 (Cauchy--Schwarz on the Score-Root Identity).}
By Lemma~\ref{lem:identity}:
\begin{equation}\label{eq:cs1}
  \frac{n^2(n-1)^2}{4}
  = \Bigl(\sum_i(\lambda_i-\mu)\,V_i\Bigr)^{\!2}
  \le T\,U.
\end{equation}

\noindent\textbf{Step~2 (Cauchy--Schwarz on the Score Decomposition).}
By Lemma~\ref{lem:score-decomp}:
\begin{equation}\label{eq:cs2}
  U^2
  = \Bigl(\sum_{i<j}\frac{V_i-V_j}{\lambda_i-\lambda_j}\Bigr)^{\!2}
  \le S\cdot\binom{n}{2}
  = \frac{n(n-1)}{2}\,S.
\end{equation}

\noindent\textbf{Step~3 (Combination).}
From~\eqref{eq:cs2}: $S \ge \frac{2U^2}{n(n-1)}$. Multiply by $T$ and
apply~\eqref{eq:cs1}:
\[
  S\,T
  \;\ge\;
  \frac{2U^2\,T}{n(n-1)}
  = \frac{2U}{n(n-1)}\cdot TU
  \;\ge\;
  \frac{2U}{n(n-1)}\cdot\frac{n^2(n-1)^2}{4}
  = \frac{n(n-1)}{2}\,U.
\]

\medskip
\noindent\textbf{Equality.}
Both Cauchy--Schwarz applications must be tight.
Inequality~\eqref{eq:cs1} requires $V_i = c(\lambda_i-\mu)$.
Inequality~\eqref{eq:cs2} requires $\frac{V_i-V_j}{\lambda_i-\lambda_j}$ to
be constant over all pairs.
These conditions are equivalent: $V_i = c(\lambda_i-\mu)$ implies
$\frac{V_i-V_j}{\lambda_i-\lambda_j} = c$. Conversely,
$\frac{V_i-V_j}{\lambda_i-\lambda_j} = k$ for all $i<j$ forces
$V_i - k\lambda_i$ to be constant; since $\sum V_i = 0$, this gives
$V_i = k(\lambda_i-\mu)$.
\end{proof}

\begin{remark}
The equality condition $V_i = c(\lambda_i - \mu)$ characterizes (up to affine
transformation) the zeros of the Hermite polynomials: if $x_1,\dots,x_n$ are
the zeros of the physicist's Hermite polynomial~$H_n$, the ODE
$H_n''-2xH_n'+2nH_n=0$ evaluated at a zero~$x_k$ gives $V_k = x_k$.
\end{remark}

%==============================================================================
\section{The Convolution Flow}\label{sec:flow}
%==============================================================================

We study how $\Phi_n$ evolves under convolution, first infinitesimally, then
along a continuous flow.

\subsection{Perturbation Analysis}

Let $q_\epsilon$ be a centered polynomial with
$\sigma^2(q_\epsilon) = \epsilon^2$. We analyze $p \boxplusn q_\epsilon$ for
small~$\epsilon$.

\begin{lemma}[Shift of Roots]\label{lem:root-shift}
The roots $\mu_i$ of $p \boxplusn q_\epsilon$ satisfy
$\;\mu_i = \lambda_i + \dfrac{\epsilon^2}{n-1}\,V_i + O(\epsilon^3)$.
\end{lemma}

\begin{proof}
Since $q_\epsilon$ is centered with variance~$\epsilon^2$, its coefficients
satisfy $b_0=1$, $b_1=0$, $b_2=-n\epsilon^2/2$ (by Lemma~\ref{lem:var}).
The operator $T_{q_\epsilon}$ acts as
\[
  T_{q_\epsilon}\,p(x)
  = p(x) - \frac{\epsilon^2}{2(n-1)}\,p''(x) + O(\epsilon^3).
\]
Setting $\mu_i = \lambda_i + \delta_i$ with $\delta_i = O(\epsilon^2)$ and
expanding $T_{q_\epsilon}\,p(\mu_i)=0$:
\[
  0 = \underbrace{p(\lambda_i)}_{=\,0}
    + \delta_i\,p'(\lambda_i)
    - \frac{\epsilon^2}{2(n-1)}\,p''(\lambda_i)
    + O(\epsilon^3).
\]
Solving and applying Lemma~\ref{lem:score-deriv}:
$\delta_i
= \frac{\epsilon^2}{2(n-1)}\cdot\frac{p''(\lambda_i)}{p'(\lambda_i)}
  + O(\epsilon^3)
= \frac{\epsilon^2}{n-1}\,V_i + O(\epsilon^3)$.
\end{proof}

Roots move in the direction of the repulsive force~$V_i$: isolated roots
barely shift, while clustered roots are pushed apart.

\begin{lemma}[Change in Fisher Information]\label{lem:change-phi}
$\;\Phi_n(p \boxplusn q_\epsilon)
= \Phi_n(p) - \dfrac{2\epsilon^2}{n-1}\,\mathcal{S}(p) + O(\epsilon^3)$.
\end{lemma}

\begin{proof}
From Lemma~\ref{lem:root-shift}, the perturbed scores are
\[
  V_i^{(\epsilon)}
  = \sum_{j \neq i}\frac{1}{\mu_i-\mu_j}
  = \sum_{j \neq i}\frac{1}{(\lambda_i-\lambda_j)
    \bigl(1+\frac{\epsilon^2}{n-1}\frac{V_i-V_j}{\lambda_i-\lambda_j}
    +O(\epsilon^3)\bigr)}
  = V_i - \frac{\epsilon^2}{n-1}\sum_{j \neq i}
    \frac{V_i-V_j}{(\lambda_i-\lambda_j)^2}
  + O(\epsilon^3).
\]
Squaring and summing:
\[
  \Phi_n(p_\epsilon)
  = \sum_i V_i^2
  - \frac{2\epsilon^2}{n-1}\sum_{i \neq j}
    \frac{V_i(V_i-V_j)}{(\lambda_i-\lambda_j)^2}
  + O(\epsilon^3).
\]
Pairing $(i,j)$ with $(j,i)$:
$\sum_{i \neq j}\frac{V_i(V_i-V_j)}{(\lambda_i-\lambda_j)^2}
= \sum_{i<j}\frac{(V_i-V_j)^2}{(\lambda_i-\lambda_j)^2}
= \mathcal{S}(p)$.
\end{proof}

Since $\mathcal{S}(p) \ge 0$, the Fisher information is non-increasing under
convolution.

\subsection{The Continuous Flow}

To prove the full Stam inequality we embed the convolution into a one-parameter
flow.

\begin{definition}[Fractional Convolution Flow]
Let $b = \sigma^2(q)>0$.
Using the normalized coefficients
$\kappa_k(p) = \frac{(n-k)!}{n!}\,a_k$, the convolution formula becomes a
Cauchy product: $K_{p\boxplusn q}(z) = K_p(z)\,K_q(z)$, where
$K_p(z) = \sum_k \kappa_k(p)\,z^k$.
Define
\[
  K_{q_t}(z) \coloneqq K_q(z)^{\,t}, \quad t \in [0,1],
\]
truncated at degree~$n$.
Then $q_0 = x^n$, $q_1 = q$, $\sigma^2(q_t)=tb$, and the semigroup property
$q_s \boxplusn q_t = q_{s+t}$ holds at the operator level.
The \emph{flow polynomial} is $p_t \coloneqq p \boxplusn q_t$, so that
\begin{equation}\label{eq:var-flow}
  \sigma^2(p_t) = \sigma^2(p) + t\,b.
\end{equation}
\end{definition}

\begin{lemma}[Dissipation]\label{lem:dissip}
$\;\dfrac{d}{dt}\Phi_n(p_t)
= -\dfrac{2b}{n-1}\,\mathcal{S}(p_t)$.
\end{lemma}

\begin{proof}
By the semigroup property, $p_{t+h} = p_t \boxplusn q_h$ with
$\sigma^2(q_h)=hb$.
Lemma~\ref{lem:change-phi} gives
$\Phi_n(p_{t+h}) = \Phi_n(p_t) - \frac{2hb}{n-1}\,\mathcal{S}(p_t)+O(h^2)$.
Dividing by~$h$ and letting $h\to 0$ yields the result.
\end{proof}

\begin{theorem}[Integral Identity]\label{thm:integral}
\[
  \frac{1}{\Phi_n(p \boxplusn q)} - \frac{1}{\Phi_n(p)}
  = \frac{2b}{n-1}\int_0^1
    \frac{\mathcal{S}(p_t)}{\Phi_n(p_t)^2}\,dt.
\]
\end{theorem}

\begin{proof}
Set $f(t) = 1/\Phi_n(p_t)$. By the chain rule and Lemma~\ref{lem:dissip}:
\[
  f'(t)
  = -\frac{\dot\Phi_n(p_t)}{\Phi_n(p_t)^2}
  = \frac{2b}{n-1}\cdot\frac{\mathcal{S}(p_t)}{\Phi_n(p_t)^2}
  \;\ge\; 0.
\]
Integrating from $0$ to $1$ and noting $f(0) = 1/\Phi_n(p)$,
$f(1) = 1/\Phi_n(p\boxplusn q)$ gives the result.
\end{proof}

%==============================================================================
\section{The Stam Inequality}\label{sec:stam}
%==============================================================================

\begin{theorem}[Finite Free Stam Inequality]\label{thm:stam}
For $p,q \in \PnR$ with positive variances,
\[
  \frac{1}{\Phi_n(p \boxplusn q)}
  \;\ge\;
  \frac{1}{\Phi_n(p)} + \frac{1}{\Phi_n(q)}.
\]
\end{theorem}

\begin{proof}
Write $a = \sigma^2(p)$, $b = \sigma^2(q)$, and $f(t) = 1/\Phi_n(p_t)$.

\medskip
\noindent\textbf{Step~1: Differential inequality.}
From Theorem~\ref{thm:integral},
$f'(t)=\frac{2b}{n-1}\cdot\frac{\mathcal{S}(p_t)}{\Phi_n(p_t)^2}$.
The Score-Gradient Inequality (Theorem~\ref{thm:sgi}) applied to $p_t$ gives
$\mathcal{S}(p_t) \ge \frac{(n-1)\,\Phi_n(p_t)}{2\,\sigma^2(p_t)}$.
Substituting:
\[
  f'(t)
  \;\ge\;
  \frac{b}{\sigma^2(p_t)}\,f(t)
  = \frac{b}{a+tb}\,f(t).
\]

\medskip
\noindent\textbf{Step~2: Gr\"onwall integration.}
Since $f(t) > 0$, divide by $f(t)$:
\[
  \frac{d}{dt}\ln f(t)
  \;\ge\;
  \frac{b}{a+tb}
  = \frac{d}{dt}\ln(a+tb).
\]
Integrate from $0$ to $1$:
$\ln\frac{f(1)}{f(0)} \ge \ln\frac{a+b}{a}$, hence
\begin{equation}\label{eq:fwd}
  \frac{1}{\Phi_n(p \boxplusn q)}
  \;\ge\;
  \frac{a+b}{a}\cdot\frac{1}{\Phi_n(p)}.
  \tag{Forward}
\end{equation}

\medskip
\noindent\textbf{Step~3: Reverse bound by symmetry.}
Since $p \boxplusn q = q \boxplusn p$, the identical argument with $p$ and $q$
swapped yields
\begin{equation}\label{eq:rev}
  \frac{1}{\Phi_n(p \boxplusn q)}
  \;\ge\;
  \frac{a+b}{b}\cdot\frac{1}{\Phi_n(q)}.
  \tag{Reverse}
\end{equation}

\medskip
\noindent\textbf{Step~4: Weighted combination.}
Set $w_1 = \frac{a}{a+b}$ and $w_2 = \frac{b}{a+b}$, so that $w_1+w_2=1$.
Multiply~\eqref{eq:fwd} by $w_1$ and~\eqref{eq:rev} by $w_2$:
\begin{align*}
  w_1\cdot\frac{1}{\Phi_n(p\boxplusn q)}
  &\;\ge\;
  \frac{a}{a+b}\cdot\frac{a+b}{a}\cdot\frac{1}{\Phi_n(p)}
  = \frac{1}{\Phi_n(p)}, \\[2pt]
  w_2\cdot\frac{1}{\Phi_n(p\boxplusn q)}
  &\;\ge\;
  \frac{b}{a+b}\cdot\frac{a+b}{b}\cdot\frac{1}{\Phi_n(q)}
  = \frac{1}{\Phi_n(q)}.
\end{align*}
Adding:
$\;\frac{1}{\Phi_n(p\boxplusn q)}
\ge \frac{1}{\Phi_n(p)} + \frac{1}{\Phi_n(q)}$.
\end{proof}

\begin{remark}
The weight $w_1 = a/(a+b)$ is the unique choice making the factor
$w_1\cdot(a+b)/a$ equal to~$1$. This is precisely where variance additivity
($\sigma^2(p\boxplusn q)=a+b$) is essential: without it, the cancellation in
Step~4 would fail.
\end{remark}

\begin{remark}
The inequality is strict for generic $p$ and $q$.
Full equality requires both Gr\"onwall bounds to be simultaneously tight along
the entire flow, i.e.\ $V_i(p_t) = c(t)(\lambda_i(t)-\mu(t))$ for all
$t \in [0,1]$, which forces both $p$ and $q$ to have roots at the (affinely
rescaled) zeros of the Hermite polynomial~$H_n$.
\end{remark}

%==============================================================================
\section{Concluding Remarks}\label{sec:conclusion}
%==============================================================================

The proof rests on four ingredients, each with a clear role:

\begin{center}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{ll}
\toprule
\textbf{Ingredient} & \textbf{Role in the proof} \\
\midrule
$\mathcal{S}(p) \ge 0$ & Monotonicity of $1/\Phi_n$ along the flow \\
Score-Gradient Inequality & Quantitative ODE: $f' \ge (b/(a{+}tb))\,f$ \\
Gr\"onwall integration & Forward and reverse bounds \\
Commutativity + variance additivity & Weighted combination \\
\bottomrule
\end{tabular}
\end{center}

\medskip
Two weaker results also follow immediately.
The \emph{weak Stam inequality},
$1/\Phi_n(p\boxplusn q) \ge 1/\Phi_n(p)$,
uses only $\mathcal{S}\ge 0$ (the integral identity has a non-negative
integrand) and requires none of the Gr\"onwall machinery.
Averaging this bound with its symmetric counterpart
$1/\Phi_n(q\boxplusn p) \ge 1/\Phi_n(q)$ gives the
\emph{half-Stam inequality}:
$2/\Phi_n(p\boxplusn q) \ge 1/\Phi_n(p) + 1/\Phi_n(q)$.

%==============================================================================
\begin{thebibliography}{9}

\bibitem{MSS15} A.~Marcus, D.~Spielman, N.~Srivastava,
\emph{Interlacing families II: Mixed characteristic polynomials and the
Kadison--Singer problem},
Ann.\ Math.\ \textbf{182} (2015), 327--350.

\bibitem{Stam59} A.~J.~Stam,
\emph{Some inequalities satisfied by the quantities of information of Fisher
and Shannon},
Inform.\ Control \textbf{2} (1959), 101--112.

\end{thebibliography}

\end{document}
